2024-07-16 12:12:40,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:40,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:40,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:40,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:41,196:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-07-16 12:12:45,646:INFO:PyCaret ClassificationExperiment
2024-07-16 12:12:45,646:INFO:Logging name: clf-default-name
2024-07-16 12:12:45,646:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-16 12:12:45,647:INFO:version 3.0.0
2024-07-16 12:12:45,647:INFO:Initializing setup()
2024-07-16 12:12:45,647:INFO:self.USI: 5c25
2024-07-16 12:12:45,647:INFO:self._variable_keys: {'y_test', 'y', 'fold_shuffle_param', 'y_train', 'log_plots_param', 'html_param', 'data', 'exp_name_log', 'logging_param', 'gpu_n_jobs_param', 'X_test', 'idx', 'exp_id', 'fold_generator', 'X', 'is_multiclass', 'seed', '_available_plots', 'fold_groups_param', 'gpu_param', 'X_train', '_ml_usecase', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'memory', 'target_param', 'USI'}
2024-07-16 12:12:45,647:INFO:Checking environment
2024-07-16 12:12:45,647:INFO:python_version: 3.11.4
2024-07-16 12:12:45,647:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2024-07-16 12:12:45,647:INFO:machine: AMD64
2024-07-16 12:12:45,647:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-16 12:12:45,650:INFO:Memory: svmem(total=68659781632, available=51369074688, percent=25.2, used=17290706944, free=51369074688)
2024-07-16 12:12:45,650:INFO:Physical Core: 16
2024-07-16 12:12:45,650:INFO:Logical Core: 32
2024-07-16 12:12:45,652:INFO:Checking libraries
2024-07-16 12:12:45,652:INFO:System:
2024-07-16 12:12:45,652:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2024-07-16 12:12:45,652:INFO:executable: c:\Users\JAL\AppData\Local\Programs\Python\Python311\python.exe
2024-07-16 12:12:45,652:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-16 12:12:45,652:INFO:PyCaret required dependencies:
2024-07-16 12:12:45,702:INFO:                 pip: 24.1.2
2024-07-16 12:12:45,702:INFO:          setuptools: 70.3.0
2024-07-16 12:12:45,702:INFO:             pycaret: 3.0.0
2024-07-16 12:12:45,702:INFO:             IPython: 8.15.0
2024-07-16 12:12:45,702:INFO:          ipywidgets: 8.1.3
2024-07-16 12:12:45,702:INFO:                tqdm: 4.66.4
2024-07-16 12:12:45,702:INFO:               numpy: 1.24.4
2024-07-16 12:12:45,702:INFO:              pandas: 2.2.2
2024-07-16 12:12:45,702:INFO:              jinja2: 3.1.4
2024-07-16 12:12:45,702:INFO:               scipy: 1.11.4
2024-07-16 12:12:45,702:INFO:              joblib: 1.3.2
2024-07-16 12:12:45,702:INFO:             sklearn: 1.3.0
2024-07-16 12:12:45,702:INFO:                pyod: 2.0.1
2024-07-16 12:12:45,702:INFO:            imblearn: 0.12.3
2024-07-16 12:12:45,702:INFO:   category_encoders: 2.6.3
2024-07-16 12:12:45,702:INFO:            lightgbm: 4.3.0
2024-07-16 12:12:45,702:INFO:               numba: 0.60.0
2024-07-16 12:12:45,702:INFO:            requests: 2.32.3
2024-07-16 12:12:45,702:INFO:          matplotlib: 3.7.5
2024-07-16 12:12:45,702:INFO:          scikitplot: 0.3.7
2024-07-16 12:12:45,702:INFO:         yellowbrick: 1.5
2024-07-16 12:12:45,702:INFO:              plotly: 5.22.0
2024-07-16 12:12:45,702:INFO:             kaleido: 0.2.1
2024-07-16 12:12:45,702:INFO:         statsmodels: 0.14.2
2024-07-16 12:12:45,702:INFO:              sktime: 0.26.0
2024-07-16 12:12:45,702:INFO:               tbats: 1.1.3
2024-07-16 12:12:45,702:INFO:            pmdarima: 2.0.4
2024-07-16 12:12:45,702:INFO:              psutil: 5.9.5
2024-07-16 12:12:45,702:INFO:PyCaret optional dependencies:
2024-07-16 12:12:45,772:INFO:                shap: Not installed
2024-07-16 12:12:45,772:INFO:           interpret: Not installed
2024-07-16 12:12:45,772:INFO:                umap: Not installed
2024-07-16 12:12:45,772:INFO:    pandas_profiling: Not installed
2024-07-16 12:12:45,772:INFO:  explainerdashboard: Not installed
2024-07-16 12:12:45,772:INFO:             autoviz: Not installed
2024-07-16 12:12:45,772:INFO:           fairlearn: Not installed
2024-07-16 12:12:45,772:INFO:             xgboost: 2.0.3
2024-07-16 12:12:45,772:INFO:            catboost: 1.2.5
2024-07-16 12:12:45,772:INFO:              kmodes: Not installed
2024-07-16 12:12:45,772:INFO:             mlxtend: Not installed
2024-07-16 12:12:45,772:INFO:       statsforecast: 1.4.0
2024-07-16 12:12:45,772:INFO:        tune_sklearn: Not installed
2024-07-16 12:12:45,772:INFO:                 ray: 2.10.0
2024-07-16 12:12:45,772:INFO:            hyperopt: 0.2.7
2024-07-16 12:12:45,772:INFO:              optuna: Not installed
2024-07-16 12:12:45,772:INFO:               skopt: Not installed
2024-07-16 12:12:45,772:INFO:              mlflow: Not installed
2024-07-16 12:12:45,772:INFO:              gradio: Not installed
2024-07-16 12:12:45,772:INFO:             fastapi: Not installed
2024-07-16 12:12:45,772:INFO:             uvicorn: Not installed
2024-07-16 12:12:45,772:INFO:              m2cgen: Not installed
2024-07-16 12:12:45,772:INFO:           evidently: Not installed
2024-07-16 12:12:45,772:INFO:               fugue: Not installed
2024-07-16 12:12:45,772:INFO:           streamlit: 1.31.0
2024-07-16 12:12:45,772:INFO:             prophet: Not installed
2024-07-16 12:12:45,772:INFO:None
2024-07-16 12:12:45,772:INFO:Set up GPU usage.
2024-07-16 12:12:45,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:45,772:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2024-07-16 12:12:45,772:INFO:Set up data.
2024-07-16 12:12:45,774:INFO:Set up train/test split.
2024-07-16 12:12:45,774:INFO:Set up index.
2024-07-16 12:12:45,774:INFO:Set up folding strategy.
2024-07-16 12:12:45,774:INFO:Assigning column types.
2024-07-16 12:12:45,774:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-16 12:12:45,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:45,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:12:45,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:45,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:45,811:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:12:45,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:45,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:45,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:45,833:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:12:46,252:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:12:46,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:12:46,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,552:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:12:46,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,572:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:12:46,680:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:12:46,682:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-16 12:12:46,682:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,712:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:12:46,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,722:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,732:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:12:46,853:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:12:46,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,882:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:12:46,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:46,902:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:12:47,022:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:12:47,022:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-16 12:12:47,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,092:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,095:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:12:47,202:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:12:47,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,272:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:12:47,382:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:12:47,392:INFO:Preparing preprocessing pipeline...
2024-07-16 12:12:47,392:INFO:Set up simple imputation.
2024-07-16 12:12:47,413:INFO:Finished creating preprocessing pipeline.
2024-07-16 12:12:47,413:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-16 12:12:47,413:INFO:Creating final display dataframe.
2024-07-16 12:12:47,452:INFO:Setup _display_container:                     Description             Value
0                    Session id              7755
1                        Target       PlacedOrNot
2                   Target type            Binary
3           Original data shape         (2224, 3)
4        Transformed data shape         (2224, 3)
5   Transformed train set shape         (1668, 3)
6    Transformed test set shape          (556, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              5c25
2024-07-16 12:12:47,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,517:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,518:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:12:47,622:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:12:47,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:12:47,671:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:12:47,782:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:12:47,782:INFO:setup() successfully completed in 2.52s...............
2024-07-16 12:12:47,782:INFO:Initializing compare_models()
2024-07-16 12:12:47,782:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-16 12:12:47,782:INFO:Checking exceptions
2024-07-16 12:12:47,782:INFO:Preparing display monitor
2024-07-16 12:12:47,802:INFO:Initializing Logistic Regression
2024-07-16 12:12:47,802:INFO:Total runtime is 0.0 minutes
2024-07-16 12:12:47,802:INFO:SubProcess create_model() called ==================================
2024-07-16 12:12:47,802:INFO:Initializing create_model()
2024-07-16 12:12:47,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:12:47,802:INFO:Checking exceptions
2024-07-16 12:12:47,802:INFO:Importing libraries
2024-07-16 12:12:47,802:INFO:Copying training dataset
2024-07-16 12:12:47,813:INFO:Defining folds
2024-07-16 12:12:47,814:INFO:Declaring metric variables
2024-07-16 12:12:47,816:INFO:Importing untrained model
2024-07-16 12:12:47,818:INFO:Logistic Regression Imported successfully
2024-07-16 12:12:47,822:INFO:Starting cross validation
2024-07-16 12:12:47,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:12:49,664:INFO:Calculating mean and std
2024-07-16 12:12:49,665:INFO:Creating metrics dataframe
2024-07-16 12:12:49,810:INFO:Uploading results into container
2024-07-16 12:12:49,810:INFO:Uploading model into container now
2024-07-16 12:12:49,810:INFO:_master_model_container: 1
2024-07-16 12:12:49,812:INFO:_display_container: 2
2024-07-16 12:12:49,812:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7755, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-16 12:12:49,812:INFO:create_model() successfully completed......................................
2024-07-16 12:12:49,888:INFO:SubProcess create_model() end ==================================
2024-07-16 12:12:49,888:INFO:Creating metrics dataframe
2024-07-16 12:12:49,893:INFO:Initializing K Neighbors Classifier
2024-07-16 12:12:49,893:INFO:Total runtime is 0.034844001134236656 minutes
2024-07-16 12:12:49,895:INFO:SubProcess create_model() called ==================================
2024-07-16 12:12:49,896:INFO:Initializing create_model()
2024-07-16 12:12:49,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:12:49,896:INFO:Checking exceptions
2024-07-16 12:12:49,896:INFO:Importing libraries
2024-07-16 12:12:49,896:INFO:Copying training dataset
2024-07-16 12:12:49,897:INFO:Defining folds
2024-07-16 12:12:49,897:INFO:Declaring metric variables
2024-07-16 12:12:49,898:INFO:Importing untrained model
2024-07-16 12:12:49,902:INFO:K Neighbors Classifier Imported successfully
2024-07-16 12:12:49,902:INFO:Starting cross validation
2024-07-16 12:12:49,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:12:52,106:INFO:Calculating mean and std
2024-07-16 12:12:52,107:INFO:Creating metrics dataframe
2024-07-16 12:12:52,252:INFO:Uploading results into container
2024-07-16 12:12:52,252:INFO:Uploading model into container now
2024-07-16 12:12:52,252:INFO:_master_model_container: 2
2024-07-16 12:12:52,252:INFO:_display_container: 2
2024-07-16 12:12:52,255:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-16 12:12:52,255:INFO:create_model() successfully completed......................................
2024-07-16 12:12:52,324:INFO:SubProcess create_model() end ==================================
2024-07-16 12:12:52,324:INFO:Creating metrics dataframe
2024-07-16 12:12:52,327:INFO:Initializing Naive Bayes
2024-07-16 12:12:52,327:INFO:Total runtime is 0.07540763219197591 minutes
2024-07-16 12:12:52,327:INFO:SubProcess create_model() called ==================================
2024-07-16 12:12:52,327:INFO:Initializing create_model()
2024-07-16 12:12:52,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:12:52,327:INFO:Checking exceptions
2024-07-16 12:12:52,327:INFO:Importing libraries
2024-07-16 12:12:52,327:INFO:Copying training dataset
2024-07-16 12:12:52,327:INFO:Defining folds
2024-07-16 12:12:52,327:INFO:Declaring metric variables
2024-07-16 12:12:52,332:INFO:Importing untrained model
2024-07-16 12:12:52,332:INFO:Naive Bayes Imported successfully
2024-07-16 12:12:52,332:INFO:Starting cross validation
2024-07-16 12:12:52,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:12:54,082:INFO:Calculating mean and std
2024-07-16 12:12:54,082:INFO:Creating metrics dataframe
2024-07-16 12:12:54,242:INFO:Uploading results into container
2024-07-16 12:12:54,242:INFO:Uploading model into container now
2024-07-16 12:12:54,242:INFO:_master_model_container: 3
2024-07-16 12:12:54,242:INFO:_display_container: 2
2024-07-16 12:12:54,242:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-16 12:12:54,242:INFO:create_model() successfully completed......................................
2024-07-16 12:12:54,305:INFO:SubProcess create_model() end ==================================
2024-07-16 12:12:54,312:INFO:Creating metrics dataframe
2024-07-16 12:12:54,316:INFO:Initializing Decision Tree Classifier
2024-07-16 12:12:54,316:INFO:Total runtime is 0.10856442054112753 minutes
2024-07-16 12:12:54,317:INFO:SubProcess create_model() called ==================================
2024-07-16 12:12:54,317:INFO:Initializing create_model()
2024-07-16 12:12:54,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:12:54,317:INFO:Checking exceptions
2024-07-16 12:12:54,317:INFO:Importing libraries
2024-07-16 12:12:54,317:INFO:Copying training dataset
2024-07-16 12:12:54,317:INFO:Defining folds
2024-07-16 12:12:54,317:INFO:Declaring metric variables
2024-07-16 12:12:54,322:INFO:Importing untrained model
2024-07-16 12:12:54,322:INFO:Decision Tree Classifier Imported successfully
2024-07-16 12:12:54,322:INFO:Starting cross validation
2024-07-16 12:12:54,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:12:56,072:INFO:Calculating mean and std
2024-07-16 12:12:56,072:INFO:Creating metrics dataframe
2024-07-16 12:12:56,214:INFO:Uploading results into container
2024-07-16 12:12:56,214:INFO:Uploading model into container now
2024-07-16 12:12:56,214:INFO:_master_model_container: 4
2024-07-16 12:12:56,214:INFO:_display_container: 2
2024-07-16 12:12:56,214:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7755, splitter='best')
2024-07-16 12:12:56,214:INFO:create_model() successfully completed......................................
2024-07-16 12:12:56,284:INFO:SubProcess create_model() end ==================================
2024-07-16 12:12:56,284:INFO:Creating metrics dataframe
2024-07-16 12:12:56,289:INFO:Initializing SVM - Linear Kernel
2024-07-16 12:12:56,289:INFO:Total runtime is 0.1414549191792806 minutes
2024-07-16 12:12:56,292:INFO:SubProcess create_model() called ==================================
2024-07-16 12:12:56,292:INFO:Initializing create_model()
2024-07-16 12:12:56,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:12:56,292:INFO:Checking exceptions
2024-07-16 12:12:56,292:INFO:Importing libraries
2024-07-16 12:12:56,292:INFO:Copying training dataset
2024-07-16 12:12:56,293:INFO:Defining folds
2024-07-16 12:12:56,293:INFO:Declaring metric variables
2024-07-16 12:12:56,295:INFO:Importing untrained model
2024-07-16 12:12:56,295:INFO:SVM - Linear Kernel Imported successfully
2024-07-16 12:12:56,295:INFO:Starting cross validation
2024-07-16 12:12:56,302:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:12:56,354:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:56,533:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:56,712:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:56,882:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:57,052:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:57,222:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:57,392:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:57,569:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:57,742:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:57,919:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:58,067:INFO:Calculating mean and std
2024-07-16 12:12:58,068:INFO:Creating metrics dataframe
2024-07-16 12:12:58,211:INFO:Uploading results into container
2024-07-16 12:12:58,212:INFO:Uploading model into container now
2024-07-16 12:12:58,212:INFO:_master_model_container: 5
2024-07-16 12:12:58,212:INFO:_display_container: 2
2024-07-16 12:12:58,212:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7755, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-16 12:12:58,212:INFO:create_model() successfully completed......................................
2024-07-16 12:12:58,282:INFO:SubProcess create_model() end ==================================
2024-07-16 12:12:58,282:INFO:Creating metrics dataframe
2024-07-16 12:12:58,286:INFO:Initializing Ridge Classifier
2024-07-16 12:12:58,286:INFO:Total runtime is 0.17473604679107665 minutes
2024-07-16 12:12:58,288:INFO:SubProcess create_model() called ==================================
2024-07-16 12:12:58,288:INFO:Initializing create_model()
2024-07-16 12:12:58,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:12:58,288:INFO:Checking exceptions
2024-07-16 12:12:58,289:INFO:Importing libraries
2024-07-16 12:12:58,289:INFO:Copying training dataset
2024-07-16 12:12:58,290:INFO:Defining folds
2024-07-16 12:12:58,290:INFO:Declaring metric variables
2024-07-16 12:12:58,293:INFO:Importing untrained model
2024-07-16 12:12:58,294:INFO:Ridge Classifier Imported successfully
2024-07-16 12:12:58,298:INFO:Starting cross validation
2024-07-16 12:12:58,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:12:58,320:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:58,494:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:58,660:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:58,833:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:59,016:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:59,200:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:59,375:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:59,551:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:59,723:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:12:59,898:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:13:00,054:INFO:Calculating mean and std
2024-07-16 12:13:00,055:INFO:Creating metrics dataframe
2024-07-16 12:13:00,198:INFO:Uploading results into container
2024-07-16 12:13:00,199:INFO:Uploading model into container now
2024-07-16 12:13:00,199:INFO:_master_model_container: 6
2024-07-16 12:13:00,199:INFO:_display_container: 2
2024-07-16 12:13:00,199:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7755, solver='auto',
                tol=0.0001)
2024-07-16 12:13:00,199:INFO:create_model() successfully completed......................................
2024-07-16 12:13:00,267:INFO:SubProcess create_model() end ==================================
2024-07-16 12:13:00,267:INFO:Creating metrics dataframe
2024-07-16 12:13:00,272:INFO:Initializing Random Forest Classifier
2024-07-16 12:13:00,273:INFO:Total runtime is 0.20784643491109211 minutes
2024-07-16 12:13:00,275:INFO:SubProcess create_model() called ==================================
2024-07-16 12:13:00,275:INFO:Initializing create_model()
2024-07-16 12:13:00,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:13:00,275:INFO:Checking exceptions
2024-07-16 12:13:00,275:INFO:Importing libraries
2024-07-16 12:13:00,275:INFO:Copying training dataset
2024-07-16 12:13:00,277:INFO:Defining folds
2024-07-16 12:13:00,277:INFO:Declaring metric variables
2024-07-16 12:13:00,279:INFO:Importing untrained model
2024-07-16 12:13:00,290:INFO:Random Forest Classifier Imported successfully
2024-07-16 12:13:00,293:INFO:Starting cross validation
2024-07-16 12:13:00,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:13:04,160:INFO:Calculating mean and std
2024-07-16 12:13:04,161:INFO:Creating metrics dataframe
2024-07-16 12:13:04,320:INFO:Uploading results into container
2024-07-16 12:13:04,321:INFO:Uploading model into container now
2024-07-16 12:13:04,321:INFO:_master_model_container: 7
2024-07-16 12:13:04,321:INFO:_display_container: 2
2024-07-16 12:13:04,322:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7755, verbose=0, warm_start=False)
2024-07-16 12:13:04,322:INFO:create_model() successfully completed......................................
2024-07-16 12:13:04,382:INFO:SubProcess create_model() end ==================================
2024-07-16 12:13:04,382:INFO:Creating metrics dataframe
2024-07-16 12:13:04,387:INFO:Initializing Quadratic Discriminant Analysis
2024-07-16 12:13:04,387:INFO:Total runtime is 0.276408314704895 minutes
2024-07-16 12:13:04,389:INFO:SubProcess create_model() called ==================================
2024-07-16 12:13:04,390:INFO:Initializing create_model()
2024-07-16 12:13:04,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:13:04,390:INFO:Checking exceptions
2024-07-16 12:13:04,390:INFO:Importing libraries
2024-07-16 12:13:04,390:INFO:Copying training dataset
2024-07-16 12:13:04,391:INFO:Defining folds
2024-07-16 12:13:04,391:INFO:Declaring metric variables
2024-07-16 12:13:04,392:INFO:Importing untrained model
2024-07-16 12:13:04,394:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-16 12:13:04,398:INFO:Starting cross validation
2024-07-16 12:13:04,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:13:06,215:INFO:Calculating mean and std
2024-07-16 12:13:06,216:INFO:Creating metrics dataframe
2024-07-16 12:13:06,377:INFO:Uploading results into container
2024-07-16 12:13:06,378:INFO:Uploading model into container now
2024-07-16 12:13:06,378:INFO:_master_model_container: 8
2024-07-16 12:13:06,378:INFO:_display_container: 2
2024-07-16 12:13:06,379:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-16 12:13:06,379:INFO:create_model() successfully completed......................................
2024-07-16 12:13:06,438:INFO:SubProcess create_model() end ==================================
2024-07-16 12:13:06,438:INFO:Creating metrics dataframe
2024-07-16 12:13:06,445:INFO:Initializing Ada Boost Classifier
2024-07-16 12:13:06,445:INFO:Total runtime is 0.3107130805651347 minutes
2024-07-16 12:13:06,447:INFO:SubProcess create_model() called ==================================
2024-07-16 12:13:06,447:INFO:Initializing create_model()
2024-07-16 12:13:06,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:13:06,447:INFO:Checking exceptions
2024-07-16 12:13:06,447:INFO:Importing libraries
2024-07-16 12:13:06,447:INFO:Copying training dataset
2024-07-16 12:13:06,449:INFO:Defining folds
2024-07-16 12:13:06,449:INFO:Declaring metric variables
2024-07-16 12:13:06,451:INFO:Importing untrained model
2024-07-16 12:13:06,453:INFO:Ada Boost Classifier Imported successfully
2024-07-16 12:13:06,457:INFO:Starting cross validation
2024-07-16 12:13:06,457:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:13:09,142:INFO:Calculating mean and std
2024-07-16 12:13:09,143:INFO:Creating metrics dataframe
2024-07-16 12:13:09,297:INFO:Uploading results into container
2024-07-16 12:13:09,298:INFO:Uploading model into container now
2024-07-16 12:13:09,298:INFO:_master_model_container: 9
2024-07-16 12:13:09,298:INFO:_display_container: 2
2024-07-16 12:13:09,298:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7755)
2024-07-16 12:13:09,298:INFO:create_model() successfully completed......................................
2024-07-16 12:13:09,360:INFO:SubProcess create_model() end ==================================
2024-07-16 12:13:09,360:INFO:Creating metrics dataframe
2024-07-16 12:13:09,366:INFO:Initializing Gradient Boosting Classifier
2024-07-16 12:13:09,366:INFO:Total runtime is 0.3593947649002075 minutes
2024-07-16 12:13:09,368:INFO:SubProcess create_model() called ==================================
2024-07-16 12:13:09,368:INFO:Initializing create_model()
2024-07-16 12:13:09,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:13:09,368:INFO:Checking exceptions
2024-07-16 12:13:09,368:INFO:Importing libraries
2024-07-16 12:13:09,368:INFO:Copying training dataset
2024-07-16 12:13:09,370:INFO:Defining folds
2024-07-16 12:13:09,370:INFO:Declaring metric variables
2024-07-16 12:13:09,372:INFO:Importing untrained model
2024-07-16 12:13:09,374:INFO:Gradient Boosting Classifier Imported successfully
2024-07-16 12:13:09,377:INFO:Starting cross validation
2024-07-16 12:13:09,378:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:13:12,091:INFO:Calculating mean and std
2024-07-16 12:13:12,092:INFO:Creating metrics dataframe
2024-07-16 12:13:12,242:INFO:Uploading results into container
2024-07-16 12:13:12,242:INFO:Uploading model into container now
2024-07-16 12:13:12,243:INFO:_master_model_container: 10
2024-07-16 12:13:12,243:INFO:_display_container: 2
2024-07-16 12:13:12,243:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7755, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-16 12:13:12,243:INFO:create_model() successfully completed......................................
2024-07-16 12:13:12,304:INFO:SubProcess create_model() end ==================================
2024-07-16 12:13:12,304:INFO:Creating metrics dataframe
2024-07-16 12:13:12,310:INFO:Initializing Linear Discriminant Analysis
2024-07-16 12:13:12,310:INFO:Total runtime is 0.4084699114163716 minutes
2024-07-16 12:13:12,312:INFO:SubProcess create_model() called ==================================
2024-07-16 12:13:12,312:INFO:Initializing create_model()
2024-07-16 12:13:12,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:13:12,312:INFO:Checking exceptions
2024-07-16 12:13:12,313:INFO:Importing libraries
2024-07-16 12:13:12,313:INFO:Copying training dataset
2024-07-16 12:13:12,314:INFO:Defining folds
2024-07-16 12:13:12,314:INFO:Declaring metric variables
2024-07-16 12:13:12,316:INFO:Importing untrained model
2024-07-16 12:13:12,318:INFO:Linear Discriminant Analysis Imported successfully
2024-07-16 12:13:12,322:INFO:Starting cross validation
2024-07-16 12:13:12,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:13:14,156:INFO:Calculating mean and std
2024-07-16 12:13:14,156:INFO:Creating metrics dataframe
2024-07-16 12:13:14,308:INFO:Uploading results into container
2024-07-16 12:13:14,309:INFO:Uploading model into container now
2024-07-16 12:13:14,309:INFO:_master_model_container: 11
2024-07-16 12:13:14,309:INFO:_display_container: 2
2024-07-16 12:13:14,309:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-16 12:13:14,309:INFO:create_model() successfully completed......................................
2024-07-16 12:13:14,370:INFO:SubProcess create_model() end ==================================
2024-07-16 12:13:14,371:INFO:Creating metrics dataframe
2024-07-16 12:13:14,376:INFO:Initializing Extra Trees Classifier
2024-07-16 12:13:14,376:INFO:Total runtime is 0.44289318323135374 minutes
2024-07-16 12:13:14,378:INFO:SubProcess create_model() called ==================================
2024-07-16 12:13:14,378:INFO:Initializing create_model()
2024-07-16 12:13:14,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:13:14,378:INFO:Checking exceptions
2024-07-16 12:13:14,378:INFO:Importing libraries
2024-07-16 12:13:14,378:INFO:Copying training dataset
2024-07-16 12:13:14,380:INFO:Defining folds
2024-07-16 12:13:14,380:INFO:Declaring metric variables
2024-07-16 12:13:14,382:INFO:Importing untrained model
2024-07-16 12:13:14,384:INFO:Extra Trees Classifier Imported successfully
2024-07-16 12:13:14,387:INFO:Starting cross validation
2024-07-16 12:13:14,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:13:17,824:INFO:Calculating mean and std
2024-07-16 12:13:17,825:INFO:Creating metrics dataframe
2024-07-16 12:13:17,993:INFO:Uploading results into container
2024-07-16 12:13:17,994:INFO:Uploading model into container now
2024-07-16 12:13:17,994:INFO:_master_model_container: 12
2024-07-16 12:13:17,994:INFO:_display_container: 2
2024-07-16 12:13:17,994:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7755, verbose=0, warm_start=False)
2024-07-16 12:13:17,994:INFO:create_model() successfully completed......................................
2024-07-16 12:13:18,057:INFO:SubProcess create_model() end ==================================
2024-07-16 12:13:18,057:INFO:Creating metrics dataframe
2024-07-16 12:13:18,064:INFO:Initializing Extreme Gradient Boosting
2024-07-16 12:13:18,064:INFO:Total runtime is 0.5043593525886535 minutes
2024-07-16 12:13:18,066:INFO:SubProcess create_model() called ==================================
2024-07-16 12:13:18,066:INFO:Initializing create_model()
2024-07-16 12:13:18,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:13:18,066:INFO:Checking exceptions
2024-07-16 12:13:18,066:INFO:Importing libraries
2024-07-16 12:13:18,066:INFO:Copying training dataset
2024-07-16 12:13:18,068:INFO:Defining folds
2024-07-16 12:13:18,068:INFO:Declaring metric variables
2024-07-16 12:13:18,070:INFO:Importing untrained model
2024-07-16 12:13:18,072:INFO:Extreme Gradient Boosting Imported successfully
2024-07-16 12:13:18,075:INFO:Starting cross validation
2024-07-16 12:13:18,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:13:18,563:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:18] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:18,929:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:18] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:19,288:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:19] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:19,650:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:19] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:20,006:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:20] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:20,381:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:20] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:20,743:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:20] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:21,113:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:21] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:21,487:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:21] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:21,863:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:13:21] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:13:22,102:INFO:Calculating mean and std
2024-07-16 12:13:22,103:INFO:Creating metrics dataframe
2024-07-16 12:13:22,267:INFO:Uploading results into container
2024-07-16 12:13:22,267:INFO:Uploading model into container now
2024-07-16 12:13:22,267:INFO:_master_model_container: 13
2024-07-16 12:13:22,268:INFO:_display_container: 2
2024-07-16 12:13:22,268:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-16 12:13:22,268:INFO:create_model() successfully completed......................................
2024-07-16 12:13:22,330:INFO:SubProcess create_model() end ==================================
2024-07-16 12:13:22,330:INFO:Creating metrics dataframe
2024-07-16 12:13:22,336:INFO:Initializing Light Gradient Boosting Machine
2024-07-16 12:13:22,336:INFO:Total runtime is 0.5755669116973876 minutes
2024-07-16 12:13:22,338:INFO:SubProcess create_model() called ==================================
2024-07-16 12:13:22,338:INFO:Initializing create_model()
2024-07-16 12:13:22,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:13:22,338:INFO:Checking exceptions
2024-07-16 12:13:22,338:INFO:Importing libraries
2024-07-16 12:13:22,338:INFO:Copying training dataset
2024-07-16 12:13:22,340:INFO:Defining folds
2024-07-16 12:13:22,340:INFO:Declaring metric variables
2024-07-16 12:13:22,342:INFO:Importing untrained model
2024-07-16 12:13:22,345:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-16 12:13:22,349:INFO:Starting cross validation
2024-07-16 12:13:22,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:13:22,364:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:13:22,364:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:22,364:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:22,364:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:13:22,440:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:22,440:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:22,450:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:22,452:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:22,453:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000454 secs. 0 sparse feature groups
2024-07-16 12:13:22,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:13:22,453:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:13:22,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:22,945:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:13:22,945:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:22,945:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:22,945:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:13:23,028:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:23,029:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:23,039:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:23,040:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:23,040:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000378 secs. 0 sparse feature groups
2024-07-16 12:13:23,040:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:13:23,040:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:13:23,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,535:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:13:23,535:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:23,535:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:23,535:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:13:23,616:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:23,616:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:23,626:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:23,628:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:23,629:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000440 secs. 0 sparse feature groups
2024-07-16 12:13:23,629:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:13:23,629:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:13:23,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:23,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,098:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:13:24,098:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:24,098:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:24,098:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:13:24,172:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:24,173:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:24,181:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:24,184:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:24,184:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000383 secs. 0 sparse feature groups
2024-07-16 12:13:24,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:13:24,185:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:13:24,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,657:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:13:24,657:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:24,657:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:24,658:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:13:24,730:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:24,730:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:24,739:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:24,740:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:24,742:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000413 secs. 0 sparse feature groups
2024-07-16 12:13:24,742:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:13:24,742:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:13:24,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,224:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:13:25,224:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:25,224:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:25,224:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:13:25,302:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:25,302:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:25,310:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:25,312:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:25,313:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000427 secs. 0 sparse feature groups
2024-07-16 12:13:25,313:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:13:25,313:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:13:25,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,785:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:13:25,785:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:25,785:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:25,785:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:13:25,858:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:25,858:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:25,868:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:25,869:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:25,870:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000391 secs. 0 sparse feature groups
2024-07-16 12:13:25,870:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:13:25,870:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:13:25,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:25,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,361:INFO:[LightGBM] [Info] Number of positive: 837, number of negative: 664
2024-07-16 12:13:26,361:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:26,361:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:26,361:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:13:26,440:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:26,440:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:26,451:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:26,452:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:26,454:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000537 secs. 0 sparse feature groups
2024-07-16 12:13:26,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557628 -> initscore=0.231542
2024-07-16 12:13:26,454:INFO:[LightGBM] [Info] Start training from score 0.231542
2024-07-16 12:13:26,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:26,926:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 664
2024-07-16 12:13:26,926:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:26,926:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:26,926:INFO:[LightGBM] [Info] Number of data points in the train set: 1502, number of used features: 2
2024-07-16 12:13:27,000:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:27,000:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:27,009:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:27,010:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:27,011:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000427 secs. 0 sparse feature groups
2024-07-16 12:13:27,012:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557923 -> initscore=0.232736
2024-07-16 12:13:27,012:INFO:[LightGBM] [Info] Start training from score 0.232736
2024-07-16 12:13:27,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,477:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 664
2024-07-16 12:13:27,477:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:13:27,477:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:13:27,477:INFO:[LightGBM] [Info] Number of data points in the train set: 1502, number of used features: 2
2024-07-16 12:13:27,551:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:13:27,551:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:13:27,560:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:13:27,562:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:13:27,563:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000398 secs. 0 sparse feature groups
2024-07-16 12:13:27,563:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557923 -> initscore=0.232736
2024-07-16 12:13:27,563:INFO:[LightGBM] [Info] Start training from score 0.232736
2024-07-16 12:13:27,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:27,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:13:28,036:INFO:Calculating mean and std
2024-07-16 12:13:28,037:INFO:Creating metrics dataframe
2024-07-16 12:13:28,197:INFO:Uploading results into container
2024-07-16 12:13:28,197:INFO:Uploading model into container now
2024-07-16 12:13:28,197:INFO:_master_model_container: 14
2024-07-16 12:13:28,198:INFO:_display_container: 2
2024-07-16 12:13:28,198:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=7755, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-16 12:13:28,198:INFO:create_model() successfully completed......................................
2024-07-16 12:13:28,256:INFO:SubProcess create_model() end ==================================
2024-07-16 12:13:28,256:INFO:Creating metrics dataframe
2024-07-16 12:13:28,263:INFO:Initializing CatBoost Classifier
2024-07-16 12:13:28,263:INFO:Total runtime is 0.6743544538815816 minutes
2024-07-16 12:13:28,265:INFO:SubProcess create_model() called ==================================
2024-07-16 12:13:28,265:INFO:Initializing create_model()
2024-07-16 12:13:28,265:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D4A280390>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:13:28,265:INFO:Checking exceptions
2024-07-16 12:13:28,265:INFO:Importing libraries
2024-07-16 12:13:28,265:INFO:Copying training dataset
2024-07-16 12:13:28,267:INFO:Defining folds
2024-07-16 12:13:28,267:INFO:Declaring metric variables
2024-07-16 12:13:28,269:INFO:Importing untrained model
2024-07-16 12:13:28,270:INFO:CatBoost Classifier Imported successfully
2024-07-16 12:13:28,275:INFO:Starting cross validation
2024-07-16 12:13:28,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:16:59,418:INFO:Calculating mean and std
2024-07-16 12:16:59,419:INFO:Creating metrics dataframe
2024-07-16 12:16:59,587:INFO:Uploading results into container
2024-07-16 12:16:59,587:INFO:Uploading model into container now
2024-07-16 12:16:59,587:INFO:_master_model_container: 15
2024-07-16 12:16:59,587:INFO:_display_container: 2
2024-07-16 12:16:59,587:INFO:<catboost.core.CatBoostClassifier object at 0x0000022D4A283C90>
2024-07-16 12:16:59,587:INFO:create_model() successfully completed......................................
2024-07-16 12:16:59,661:INFO:SubProcess create_model() end ==================================
2024-07-16 12:16:59,662:INFO:Creating metrics dataframe
2024-07-16 12:16:59,682:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-16 12:16:59,687:INFO:Initializing create_model()
2024-07-16 12:16:59,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A282D90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7755, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:16:59,687:INFO:Checking exceptions
2024-07-16 12:16:59,687:INFO:Importing libraries
2024-07-16 12:16:59,687:INFO:Copying training dataset
2024-07-16 12:16:59,689:INFO:Defining folds
2024-07-16 12:16:59,689:INFO:Declaring metric variables
2024-07-16 12:16:59,689:INFO:Importing untrained model
2024-07-16 12:16:59,689:INFO:Declaring custom model
2024-07-16 12:16:59,689:INFO:Random Forest Classifier Imported successfully
2024-07-16 12:16:59,690:INFO:Cross validation set to False
2024-07-16 12:16:59,690:INFO:Fitting Model
2024-07-16 12:17:00,026:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7755, verbose=0, warm_start=False)
2024-07-16 12:17:00,026:INFO:create_model() successfully completed......................................
2024-07-16 12:17:00,101:INFO:_master_model_container: 15
2024-07-16 12:17:00,101:INFO:_display_container: 2
2024-07-16 12:17:00,101:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7755, verbose=0, warm_start=False)
2024-07-16 12:17:00,101:INFO:compare_models() successfully completed......................................
2024-07-16 12:25:03,015:INFO:PyCaret ClassificationExperiment
2024-07-16 12:25:03,015:INFO:Logging name: clf-default-name
2024-07-16 12:25:03,015:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-16 12:25:03,015:INFO:version 3.0.0
2024-07-16 12:25:03,015:INFO:Initializing setup()
2024-07-16 12:25:03,015:INFO:self.USI: 309f
2024-07-16 12:25:03,015:INFO:self._variable_keys: {'y_test', 'y', 'fold_shuffle_param', 'y_train', 'log_plots_param', 'html_param', 'data', 'exp_name_log', 'logging_param', 'gpu_n_jobs_param', 'X_test', 'idx', 'exp_id', 'fold_generator', 'X', 'is_multiclass', 'seed', '_available_plots', 'fold_groups_param', 'gpu_param', 'X_train', '_ml_usecase', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'memory', 'target_param', 'USI'}
2024-07-16 12:25:03,016:INFO:Checking environment
2024-07-16 12:25:03,016:INFO:python_version: 3.11.4
2024-07-16 12:25:03,016:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2024-07-16 12:25:03,016:INFO:machine: AMD64
2024-07-16 12:25:03,016:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-16 12:25:03,020:INFO:Memory: svmem(total=68659781632, available=50569592832, percent=26.3, used=18090188800, free=50569592832)
2024-07-16 12:25:03,020:INFO:Physical Core: 16
2024-07-16 12:25:03,020:INFO:Logical Core: 32
2024-07-16 12:25:03,020:INFO:Checking libraries
2024-07-16 12:25:03,021:INFO:System:
2024-07-16 12:25:03,021:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2024-07-16 12:25:03,021:INFO:executable: c:\Users\JAL\AppData\Local\Programs\Python\Python311\python.exe
2024-07-16 12:25:03,021:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-16 12:25:03,021:INFO:PyCaret required dependencies:
2024-07-16 12:25:03,021:INFO:                 pip: 24.1.2
2024-07-16 12:25:03,021:INFO:          setuptools: 70.3.0
2024-07-16 12:25:03,021:INFO:             pycaret: 3.0.0
2024-07-16 12:25:03,021:INFO:             IPython: 8.15.0
2024-07-16 12:25:03,021:INFO:          ipywidgets: 8.1.3
2024-07-16 12:25:03,021:INFO:                tqdm: 4.66.4
2024-07-16 12:25:03,021:INFO:               numpy: 1.24.4
2024-07-16 12:25:03,021:INFO:              pandas: 2.2.2
2024-07-16 12:25:03,021:INFO:              jinja2: 3.1.4
2024-07-16 12:25:03,021:INFO:               scipy: 1.11.4
2024-07-16 12:25:03,021:INFO:              joblib: 1.3.2
2024-07-16 12:25:03,021:INFO:             sklearn: 1.3.0
2024-07-16 12:25:03,021:INFO:                pyod: 2.0.1
2024-07-16 12:25:03,021:INFO:            imblearn: 0.12.3
2024-07-16 12:25:03,021:INFO:   category_encoders: 2.6.3
2024-07-16 12:25:03,021:INFO:            lightgbm: 4.3.0
2024-07-16 12:25:03,021:INFO:               numba: 0.60.0
2024-07-16 12:25:03,021:INFO:            requests: 2.32.3
2024-07-16 12:25:03,021:INFO:          matplotlib: 3.7.5
2024-07-16 12:25:03,021:INFO:          scikitplot: 0.3.7
2024-07-16 12:25:03,021:INFO:         yellowbrick: 1.5
2024-07-16 12:25:03,021:INFO:              plotly: 5.22.0
2024-07-16 12:25:03,021:INFO:             kaleido: 0.2.1
2024-07-16 12:25:03,021:INFO:         statsmodels: 0.14.2
2024-07-16 12:25:03,021:INFO:              sktime: 0.26.0
2024-07-16 12:25:03,021:INFO:               tbats: 1.1.3
2024-07-16 12:25:03,021:INFO:            pmdarima: 2.0.4
2024-07-16 12:25:03,021:INFO:              psutil: 5.9.5
2024-07-16 12:25:03,021:INFO:PyCaret optional dependencies:
2024-07-16 12:25:03,021:INFO:                shap: Not installed
2024-07-16 12:25:03,021:INFO:           interpret: Not installed
2024-07-16 12:25:03,021:INFO:                umap: Not installed
2024-07-16 12:25:03,021:INFO:    pandas_profiling: Not installed
2024-07-16 12:25:03,021:INFO:  explainerdashboard: Not installed
2024-07-16 12:25:03,021:INFO:             autoviz: Not installed
2024-07-16 12:25:03,021:INFO:           fairlearn: Not installed
2024-07-16 12:25:03,021:INFO:             xgboost: 2.0.3
2024-07-16 12:25:03,021:INFO:            catboost: 1.2.5
2024-07-16 12:25:03,021:INFO:              kmodes: Not installed
2024-07-16 12:25:03,022:INFO:             mlxtend: Not installed
2024-07-16 12:25:03,022:INFO:       statsforecast: 1.4.0
2024-07-16 12:25:03,022:INFO:        tune_sklearn: Not installed
2024-07-16 12:25:03,022:INFO:                 ray: 2.10.0
2024-07-16 12:25:03,022:INFO:            hyperopt: 0.2.7
2024-07-16 12:25:03,022:INFO:              optuna: Not installed
2024-07-16 12:25:03,022:INFO:               skopt: Not installed
2024-07-16 12:25:03,022:INFO:              mlflow: Not installed
2024-07-16 12:25:03,022:INFO:              gradio: Not installed
2024-07-16 12:25:03,022:INFO:             fastapi: Not installed
2024-07-16 12:25:03,022:INFO:             uvicorn: Not installed
2024-07-16 12:25:03,022:INFO:              m2cgen: Not installed
2024-07-16 12:25:03,022:INFO:           evidently: Not installed
2024-07-16 12:25:03,022:INFO:               fugue: Not installed
2024-07-16 12:25:03,022:INFO:           streamlit: 1.31.0
2024-07-16 12:25:03,022:INFO:             prophet: Not installed
2024-07-16 12:25:03,022:INFO:None
2024-07-16 12:25:03,022:INFO:Set up GPU usage.
2024-07-16 12:25:03,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,022:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2024-07-16 12:25:03,022:INFO:Set up data.
2024-07-16 12:25:03,024:INFO:Set up train/test split.
2024-07-16 12:25:03,026:INFO:Set up index.
2024-07-16 12:25:03,026:INFO:Set up folding strategy.
2024-07-16 12:25:03,026:INFO:Assigning column types.
2024-07-16 12:25:03,027:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-16 12:25:03,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:25:03,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,051:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:25:03,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,070:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,070:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,070:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:25:03,201:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:25:03,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:25:03,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,234:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:25:03,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,251:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:25:03,360:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:25:03,360:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-16 12:25:03,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,396:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:25:03,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,417:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:25:03,518:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:25:03,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,540:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:25:03,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,568:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:25:03,667:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:25:03,668:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-16 12:25:03,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,698:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,717:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:25:03,819:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:25:03,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:03,869:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:25:03,969:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:25:03,970:INFO:Preparing preprocessing pipeline...
2024-07-16 12:25:03,970:INFO:Set up simple imputation.
2024-07-16 12:25:03,980:INFO:Finished creating preprocessing pipeline.
2024-07-16 12:25:03,980:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-16 12:25:03,980:INFO:Creating final display dataframe.
2024-07-16 12:25:04,020:INFO:Setup _display_container:                     Description             Value
0                    Session id              4992
1                        Target       PlacedOrNot
2                   Target type            Binary
3           Original data shape         (2224, 3)
4        Transformed data shape         (2224, 3)
5   Transformed train set shape         (1668, 3)
6    Transformed test set shape          (556, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              309f
2024-07-16 12:25:04,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,077:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,077:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:25:04,183:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:25:04,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:25:04,240:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:25:04,344:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:25:04,345:INFO:setup() successfully completed in 1.49s...............
2024-07-16 12:25:04,345:INFO:Initializing compare_models()
2024-07-16 12:25:04,345:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-16 12:25:04,345:INFO:Checking exceptions
2024-07-16 12:25:04,347:INFO:Preparing display monitor
2024-07-16 12:25:04,360:INFO:Initializing Logistic Regression
2024-07-16 12:25:04,360:INFO:Total runtime is 0.0 minutes
2024-07-16 12:25:04,360:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:04,360:INFO:Initializing create_model()
2024-07-16 12:25:04,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:04,360:INFO:Checking exceptions
2024-07-16 12:25:04,360:INFO:Importing libraries
2024-07-16 12:25:04,360:INFO:Copying training dataset
2024-07-16 12:25:04,367:INFO:Defining folds
2024-07-16 12:25:04,367:INFO:Declaring metric variables
2024-07-16 12:25:04,369:INFO:Importing untrained model
2024-07-16 12:25:04,372:INFO:Logistic Regression Imported successfully
2024-07-16 12:25:04,375:INFO:Starting cross validation
2024-07-16 12:25:04,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:06,276:INFO:Calculating mean and std
2024-07-16 12:25:06,276:INFO:Creating metrics dataframe
2024-07-16 12:25:06,440:INFO:Uploading results into container
2024-07-16 12:25:06,440:INFO:Uploading model into container now
2024-07-16 12:25:06,440:INFO:_master_model_container: 1
2024-07-16 12:25:06,440:INFO:_display_container: 2
2024-07-16 12:25:06,440:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4992, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-16 12:25:06,440:INFO:create_model() successfully completed......................................
2024-07-16 12:25:06,522:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:06,522:INFO:Creating metrics dataframe
2024-07-16 12:25:06,526:INFO:Initializing K Neighbors Classifier
2024-07-16 12:25:06,526:INFO:Total runtime is 0.03610062599182129 minutes
2024-07-16 12:25:06,528:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:06,528:INFO:Initializing create_model()
2024-07-16 12:25:06,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:06,528:INFO:Checking exceptions
2024-07-16 12:25:06,528:INFO:Importing libraries
2024-07-16 12:25:06,528:INFO:Copying training dataset
2024-07-16 12:25:06,530:INFO:Defining folds
2024-07-16 12:25:06,530:INFO:Declaring metric variables
2024-07-16 12:25:06,531:INFO:Importing untrained model
2024-07-16 12:25:06,533:INFO:K Neighbors Classifier Imported successfully
2024-07-16 12:25:06,533:INFO:Starting cross validation
2024-07-16 12:25:06,533:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:08,848:INFO:Calculating mean and std
2024-07-16 12:25:08,849:INFO:Creating metrics dataframe
2024-07-16 12:25:09,011:INFO:Uploading results into container
2024-07-16 12:25:09,011:INFO:Uploading model into container now
2024-07-16 12:25:09,011:INFO:_master_model_container: 2
2024-07-16 12:25:09,011:INFO:_display_container: 2
2024-07-16 12:25:09,011:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-16 12:25:09,011:INFO:create_model() successfully completed......................................
2024-07-16 12:25:09,089:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:09,089:INFO:Creating metrics dataframe
2024-07-16 12:25:09,092:INFO:Initializing Naive Bayes
2024-07-16 12:25:09,092:INFO:Total runtime is 0.07885631322860717 minutes
2024-07-16 12:25:09,092:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:09,092:INFO:Initializing create_model()
2024-07-16 12:25:09,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:09,092:INFO:Checking exceptions
2024-07-16 12:25:09,092:INFO:Importing libraries
2024-07-16 12:25:09,092:INFO:Copying training dataset
2024-07-16 12:25:09,092:INFO:Defining folds
2024-07-16 12:25:09,092:INFO:Declaring metric variables
2024-07-16 12:25:09,092:INFO:Importing untrained model
2024-07-16 12:25:09,100:INFO:Naive Bayes Imported successfully
2024-07-16 12:25:09,100:INFO:Starting cross validation
2024-07-16 12:25:09,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:10,929:INFO:Calculating mean and std
2024-07-16 12:25:10,931:INFO:Creating metrics dataframe
2024-07-16 12:25:11,089:INFO:Uploading results into container
2024-07-16 12:25:11,089:INFO:Uploading model into container now
2024-07-16 12:25:11,089:INFO:_master_model_container: 3
2024-07-16 12:25:11,090:INFO:_display_container: 2
2024-07-16 12:25:11,090:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-16 12:25:11,090:INFO:create_model() successfully completed......................................
2024-07-16 12:25:11,165:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:11,165:INFO:Creating metrics dataframe
2024-07-16 12:25:11,169:INFO:Initializing Decision Tree Classifier
2024-07-16 12:25:11,169:INFO:Total runtime is 0.11347401539484658 minutes
2024-07-16 12:25:11,170:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:11,170:INFO:Initializing create_model()
2024-07-16 12:25:11,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:11,172:INFO:Checking exceptions
2024-07-16 12:25:11,172:INFO:Importing libraries
2024-07-16 12:25:11,172:INFO:Copying training dataset
2024-07-16 12:25:11,174:INFO:Defining folds
2024-07-16 12:25:11,174:INFO:Declaring metric variables
2024-07-16 12:25:11,175:INFO:Importing untrained model
2024-07-16 12:25:11,177:INFO:Decision Tree Classifier Imported successfully
2024-07-16 12:25:11,181:INFO:Starting cross validation
2024-07-16 12:25:11,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:13,020:INFO:Calculating mean and std
2024-07-16 12:25:13,020:INFO:Creating metrics dataframe
2024-07-16 12:25:13,179:INFO:Uploading results into container
2024-07-16 12:25:13,179:INFO:Uploading model into container now
2024-07-16 12:25:13,179:INFO:_master_model_container: 4
2024-07-16 12:25:13,179:INFO:_display_container: 2
2024-07-16 12:25:13,179:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4992, splitter='best')
2024-07-16 12:25:13,179:INFO:create_model() successfully completed......................................
2024-07-16 12:25:13,260:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:13,260:INFO:Creating metrics dataframe
2024-07-16 12:25:13,265:INFO:Initializing SVM - Linear Kernel
2024-07-16 12:25:13,265:INFO:Total runtime is 0.14841394027074176 minutes
2024-07-16 12:25:13,267:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:13,267:INFO:Initializing create_model()
2024-07-16 12:25:13,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:13,267:INFO:Checking exceptions
2024-07-16 12:25:13,267:INFO:Importing libraries
2024-07-16 12:25:13,267:INFO:Copying training dataset
2024-07-16 12:25:13,269:INFO:Defining folds
2024-07-16 12:25:13,269:INFO:Declaring metric variables
2024-07-16 12:25:13,271:INFO:Importing untrained model
2024-07-16 12:25:13,273:INFO:SVM - Linear Kernel Imported successfully
2024-07-16 12:25:13,277:INFO:Starting cross validation
2024-07-16 12:25:13,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:13,304:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:13,490:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:13,680:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:13,866:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:14,051:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:14,235:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:14,423:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:14,603:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:14,790:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:14,976:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:15,142:INFO:Calculating mean and std
2024-07-16 12:25:15,143:INFO:Creating metrics dataframe
2024-07-16 12:25:15,312:INFO:Uploading results into container
2024-07-16 12:25:15,312:INFO:Uploading model into container now
2024-07-16 12:25:15,312:INFO:_master_model_container: 5
2024-07-16 12:25:15,312:INFO:_display_container: 2
2024-07-16 12:25:15,313:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4992, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-16 12:25:15,313:INFO:create_model() successfully completed......................................
2024-07-16 12:25:15,379:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:15,379:INFO:Creating metrics dataframe
2024-07-16 12:25:15,383:INFO:Initializing Ridge Classifier
2024-07-16 12:25:15,383:INFO:Total runtime is 0.18370516300201414 minutes
2024-07-16 12:25:15,386:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:15,386:INFO:Initializing create_model()
2024-07-16 12:25:15,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:15,386:INFO:Checking exceptions
2024-07-16 12:25:15,386:INFO:Importing libraries
2024-07-16 12:25:15,386:INFO:Copying training dataset
2024-07-16 12:25:15,388:INFO:Defining folds
2024-07-16 12:25:15,388:INFO:Declaring metric variables
2024-07-16 12:25:15,389:INFO:Importing untrained model
2024-07-16 12:25:15,391:INFO:Ridge Classifier Imported successfully
2024-07-16 12:25:15,395:INFO:Starting cross validation
2024-07-16 12:25:15,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:15,417:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:15,599:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:15,782:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:15,977:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:16,175:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:16,355:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:16,536:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:16,718:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:16,898:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:17,078:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:25:17,243:INFO:Calculating mean and std
2024-07-16 12:25:17,244:INFO:Creating metrics dataframe
2024-07-16 12:25:17,411:INFO:Uploading results into container
2024-07-16 12:25:17,412:INFO:Uploading model into container now
2024-07-16 12:25:17,412:INFO:_master_model_container: 6
2024-07-16 12:25:17,413:INFO:_display_container: 2
2024-07-16 12:25:17,413:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4992, solver='auto',
                tol=0.0001)
2024-07-16 12:25:17,413:INFO:create_model() successfully completed......................................
2024-07-16 12:25:17,490:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:17,490:INFO:Creating metrics dataframe
2024-07-16 12:25:17,496:INFO:Initializing Random Forest Classifier
2024-07-16 12:25:17,496:INFO:Total runtime is 0.2189288814862569 minutes
2024-07-16 12:25:17,497:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:17,498:INFO:Initializing create_model()
2024-07-16 12:25:17,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:17,498:INFO:Checking exceptions
2024-07-16 12:25:17,498:INFO:Importing libraries
2024-07-16 12:25:17,498:INFO:Copying training dataset
2024-07-16 12:25:17,500:INFO:Defining folds
2024-07-16 12:25:17,500:INFO:Declaring metric variables
2024-07-16 12:25:17,502:INFO:Importing untrained model
2024-07-16 12:25:17,503:INFO:Random Forest Classifier Imported successfully
2024-07-16 12:25:17,507:INFO:Starting cross validation
2024-07-16 12:25:17,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:21,538:INFO:Calculating mean and std
2024-07-16 12:25:21,538:INFO:Creating metrics dataframe
2024-07-16 12:25:21,703:INFO:Uploading results into container
2024-07-16 12:25:21,704:INFO:Uploading model into container now
2024-07-16 12:25:21,704:INFO:_master_model_container: 7
2024-07-16 12:25:21,705:INFO:_display_container: 2
2024-07-16 12:25:21,705:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4992, verbose=0, warm_start=False)
2024-07-16 12:25:21,705:INFO:create_model() successfully completed......................................
2024-07-16 12:25:21,768:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:21,768:INFO:Creating metrics dataframe
2024-07-16 12:25:21,774:INFO:Initializing Quadratic Discriminant Analysis
2024-07-16 12:25:21,774:INFO:Total runtime is 0.29022739330927527 minutes
2024-07-16 12:25:21,775:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:21,776:INFO:Initializing create_model()
2024-07-16 12:25:21,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:21,776:INFO:Checking exceptions
2024-07-16 12:25:21,776:INFO:Importing libraries
2024-07-16 12:25:21,776:INFO:Copying training dataset
2024-07-16 12:25:21,777:INFO:Defining folds
2024-07-16 12:25:21,777:INFO:Declaring metric variables
2024-07-16 12:25:21,779:INFO:Importing untrained model
2024-07-16 12:25:21,780:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-16 12:25:21,784:INFO:Starting cross validation
2024-07-16 12:25:21,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:23,715:INFO:Calculating mean and std
2024-07-16 12:25:23,715:INFO:Creating metrics dataframe
2024-07-16 12:25:23,875:INFO:Uploading results into container
2024-07-16 12:25:23,876:INFO:Uploading model into container now
2024-07-16 12:25:23,876:INFO:_master_model_container: 8
2024-07-16 12:25:23,876:INFO:_display_container: 2
2024-07-16 12:25:23,876:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-16 12:25:23,876:INFO:create_model() successfully completed......................................
2024-07-16 12:25:23,944:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:23,944:INFO:Creating metrics dataframe
2024-07-16 12:25:23,950:INFO:Initializing Ada Boost Classifier
2024-07-16 12:25:23,950:INFO:Total runtime is 0.3264936010042826 minutes
2024-07-16 12:25:23,952:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:23,952:INFO:Initializing create_model()
2024-07-16 12:25:23,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:23,952:INFO:Checking exceptions
2024-07-16 12:25:23,952:INFO:Importing libraries
2024-07-16 12:25:23,952:INFO:Copying training dataset
2024-07-16 12:25:23,954:INFO:Defining folds
2024-07-16 12:25:23,954:INFO:Declaring metric variables
2024-07-16 12:25:23,956:INFO:Importing untrained model
2024-07-16 12:25:23,958:INFO:Ada Boost Classifier Imported successfully
2024-07-16 12:25:23,962:INFO:Starting cross validation
2024-07-16 12:25:23,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:26,742:INFO:Calculating mean and std
2024-07-16 12:25:26,743:INFO:Creating metrics dataframe
2024-07-16 12:25:26,903:INFO:Uploading results into container
2024-07-16 12:25:26,903:INFO:Uploading model into container now
2024-07-16 12:25:26,904:INFO:_master_model_container: 9
2024-07-16 12:25:26,904:INFO:_display_container: 2
2024-07-16 12:25:26,904:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=4992)
2024-07-16 12:25:26,904:INFO:create_model() successfully completed......................................
2024-07-16 12:25:26,977:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:26,978:INFO:Creating metrics dataframe
2024-07-16 12:25:26,984:INFO:Initializing Gradient Boosting Classifier
2024-07-16 12:25:26,984:INFO:Total runtime is 0.3770596901575724 minutes
2024-07-16 12:25:26,986:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:26,986:INFO:Initializing create_model()
2024-07-16 12:25:26,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:26,986:INFO:Checking exceptions
2024-07-16 12:25:26,986:INFO:Importing libraries
2024-07-16 12:25:26,986:INFO:Copying training dataset
2024-07-16 12:25:26,988:INFO:Defining folds
2024-07-16 12:25:26,988:INFO:Declaring metric variables
2024-07-16 12:25:26,991:INFO:Importing untrained model
2024-07-16 12:25:26,993:INFO:Gradient Boosting Classifier Imported successfully
2024-07-16 12:25:26,997:INFO:Starting cross validation
2024-07-16 12:25:26,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:29,800:INFO:Calculating mean and std
2024-07-16 12:25:29,800:INFO:Creating metrics dataframe
2024-07-16 12:25:29,960:INFO:Uploading results into container
2024-07-16 12:25:29,962:INFO:Uploading model into container now
2024-07-16 12:25:29,962:INFO:_master_model_container: 10
2024-07-16 12:25:29,962:INFO:_display_container: 2
2024-07-16 12:25:29,963:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4992, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-16 12:25:29,963:INFO:create_model() successfully completed......................................
2024-07-16 12:25:30,028:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:30,028:INFO:Creating metrics dataframe
2024-07-16 12:25:30,034:INFO:Initializing Linear Discriminant Analysis
2024-07-16 12:25:30,034:INFO:Total runtime is 0.4278948942820231 minutes
2024-07-16 12:25:30,036:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:30,036:INFO:Initializing create_model()
2024-07-16 12:25:30,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:30,037:INFO:Checking exceptions
2024-07-16 12:25:30,037:INFO:Importing libraries
2024-07-16 12:25:30,037:INFO:Copying training dataset
2024-07-16 12:25:30,038:INFO:Defining folds
2024-07-16 12:25:30,038:INFO:Declaring metric variables
2024-07-16 12:25:30,040:INFO:Importing untrained model
2024-07-16 12:25:30,041:INFO:Linear Discriminant Analysis Imported successfully
2024-07-16 12:25:30,046:INFO:Starting cross validation
2024-07-16 12:25:30,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:31,963:INFO:Calculating mean and std
2024-07-16 12:25:31,963:INFO:Creating metrics dataframe
2024-07-16 12:25:32,140:INFO:Uploading results into container
2024-07-16 12:25:32,140:INFO:Uploading model into container now
2024-07-16 12:25:32,140:INFO:_master_model_container: 11
2024-07-16 12:25:32,140:INFO:_display_container: 2
2024-07-16 12:25:32,140:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-16 12:25:32,140:INFO:create_model() successfully completed......................................
2024-07-16 12:25:32,214:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:32,214:INFO:Creating metrics dataframe
2024-07-16 12:25:32,220:INFO:Initializing Extra Trees Classifier
2024-07-16 12:25:32,220:INFO:Total runtime is 0.4643247405687968 minutes
2024-07-16 12:25:32,222:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:32,222:INFO:Initializing create_model()
2024-07-16 12:25:32,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:32,222:INFO:Checking exceptions
2024-07-16 12:25:32,222:INFO:Importing libraries
2024-07-16 12:25:32,223:INFO:Copying training dataset
2024-07-16 12:25:32,224:INFO:Defining folds
2024-07-16 12:25:32,224:INFO:Declaring metric variables
2024-07-16 12:25:32,226:INFO:Importing untrained model
2024-07-16 12:25:32,228:INFO:Extra Trees Classifier Imported successfully
2024-07-16 12:25:32,232:INFO:Starting cross validation
2024-07-16 12:25:32,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:35,814:INFO:Calculating mean and std
2024-07-16 12:25:35,815:INFO:Creating metrics dataframe
2024-07-16 12:25:35,976:INFO:Uploading results into container
2024-07-16 12:25:35,976:INFO:Uploading model into container now
2024-07-16 12:25:35,977:INFO:_master_model_container: 12
2024-07-16 12:25:35,977:INFO:_display_container: 2
2024-07-16 12:25:35,977:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4992, verbose=0, warm_start=False)
2024-07-16 12:25:35,977:INFO:create_model() successfully completed......................................
2024-07-16 12:25:36,050:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:36,050:INFO:Creating metrics dataframe
2024-07-16 12:25:36,056:INFO:Initializing Extreme Gradient Boosting
2024-07-16 12:25:36,057:INFO:Total runtime is 0.5282734791437785 minutes
2024-07-16 12:25:36,059:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:36,059:INFO:Initializing create_model()
2024-07-16 12:25:36,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:36,059:INFO:Checking exceptions
2024-07-16 12:25:36,059:INFO:Importing libraries
2024-07-16 12:25:36,059:INFO:Copying training dataset
2024-07-16 12:25:36,061:INFO:Defining folds
2024-07-16 12:25:36,061:INFO:Declaring metric variables
2024-07-16 12:25:36,062:INFO:Importing untrained model
2024-07-16 12:25:36,065:INFO:Extreme Gradient Boosting Imported successfully
2024-07-16 12:25:36,068:INFO:Starting cross validation
2024-07-16 12:25:36,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:36,357:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:36] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:36,832:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:36] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:37,280:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:37,720:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:38,152:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:38,580:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:39,012:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:39,458:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:39,896:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:40,325:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:25:40] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:25:40,565:INFO:Calculating mean and std
2024-07-16 12:25:40,566:INFO:Creating metrics dataframe
2024-07-16 12:25:40,734:INFO:Uploading results into container
2024-07-16 12:25:40,735:INFO:Uploading model into container now
2024-07-16 12:25:40,735:INFO:_master_model_container: 13
2024-07-16 12:25:40,735:INFO:_display_container: 2
2024-07-16 12:25:40,736:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-16 12:25:40,736:INFO:create_model() successfully completed......................................
2024-07-16 12:25:40,800:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:40,800:INFO:Creating metrics dataframe
2024-07-16 12:25:40,806:INFO:Initializing Light Gradient Boosting Machine
2024-07-16 12:25:40,807:INFO:Total runtime is 0.6074387113253276 minutes
2024-07-16 12:25:40,809:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:40,809:INFO:Initializing create_model()
2024-07-16 12:25:40,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:40,809:INFO:Checking exceptions
2024-07-16 12:25:40,809:INFO:Importing libraries
2024-07-16 12:25:40,809:INFO:Copying training dataset
2024-07-16 12:25:40,810:INFO:Defining folds
2024-07-16 12:25:40,810:INFO:Declaring metric variables
2024-07-16 12:25:40,812:INFO:Importing untrained model
2024-07-16 12:25:40,814:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-16 12:25:40,818:INFO:Starting cross validation
2024-07-16 12:25:40,818:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:25:40,832:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:25:40,832:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:40,832:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:40,832:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:25:40,920:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:40,920:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:40,930:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:40,932:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:40,932:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000452 secs. 0 sparse feature groups
2024-07-16 12:25:40,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:25:40,933:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:25:40,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:40,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,417:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:25:41,417:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:41,417:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:41,417:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:25:41,496:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:41,496:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:41,506:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:41,507:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:41,508:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000399 secs. 0 sparse feature groups
2024-07-16 12:25:41,508:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:25:41,508:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:25:41,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:41,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,000:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:25:42,000:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:42,000:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:42,000:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:25:42,077:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:42,077:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:42,088:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:42,090:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:42,091:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000392 secs. 0 sparse feature groups
2024-07-16 12:25:42,091:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:25:42,091:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:25:42,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,589:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:25:42,589:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:42,589:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:42,589:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:25:42,666:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:42,666:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:42,675:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:42,677:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:42,678:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000449 secs. 0 sparse feature groups
2024-07-16 12:25:42,678:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:25:42,678:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:25:42,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,163:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:25:43,163:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:43,163:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:43,163:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:25:43,239:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:43,239:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:43,248:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:43,250:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:43,251:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000434 secs. 0 sparse feature groups
2024-07-16 12:25:43,251:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:25:43,251:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:25:43,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,723:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:25:43,723:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:43,723:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:43,723:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:25:43,800:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:43,800:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:43,808:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:43,810:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:43,810:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000387 secs. 0 sparse feature groups
2024-07-16 12:25:43,810:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:25:43,810:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:25:43,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:43,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,314:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-16 12:25:44,314:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:44,314:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:44,314:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:25:44,395:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:44,396:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:44,405:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:44,407:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:44,407:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000400 secs. 0 sparse feature groups
2024-07-16 12:25:44,408:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-16 12:25:44,408:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-16 12:25:44,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,901:INFO:[LightGBM] [Info] Number of positive: 837, number of negative: 664
2024-07-16 12:25:44,901:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:44,901:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:44,901:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 2
2024-07-16 12:25:44,980:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:44,980:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:44,988:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:44,990:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:44,990:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000409 secs. 0 sparse feature groups
2024-07-16 12:25:44,990:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557628 -> initscore=0.231542
2024-07-16 12:25:44,990:INFO:[LightGBM] [Info] Start training from score 0.231542
2024-07-16 12:25:44,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:44,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,484:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 664
2024-07-16 12:25:45,485:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:45,485:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:45,485:INFO:[LightGBM] [Info] Number of data points in the train set: 1502, number of used features: 2
2024-07-16 12:25:45,561:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:45,561:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:45,571:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:45,572:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:45,573:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000423 secs. 0 sparse feature groups
2024-07-16 12:25:45,573:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557923 -> initscore=0.232736
2024-07-16 12:25:45,573:INFO:[LightGBM] [Info] Start training from score 0.232736
2024-07-16 12:25:45,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:45,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,086:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 664
2024-07-16 12:25:46,086:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:25:46,087:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:25:46,087:INFO:[LightGBM] [Info] Number of data points in the train set: 1502, number of used features: 2
2024-07-16 12:25:46,165:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:25:46,165:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:25:46,176:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:25:46,178:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:25:46,178:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000428 secs. 0 sparse feature groups
2024-07-16 12:25:46,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557923 -> initscore=0.232736
2024-07-16 12:25:46,178:INFO:[LightGBM] [Info] Start training from score 0.232736
2024-07-16 12:25:46,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:25:46,672:INFO:Calculating mean and std
2024-07-16 12:25:46,672:INFO:Creating metrics dataframe
2024-07-16 12:25:46,853:INFO:Uploading results into container
2024-07-16 12:25:46,854:INFO:Uploading model into container now
2024-07-16 12:25:46,854:INFO:_master_model_container: 14
2024-07-16 12:25:46,854:INFO:_display_container: 2
2024-07-16 12:25:46,855:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=4992, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-16 12:25:46,855:INFO:create_model() successfully completed......................................
2024-07-16 12:25:46,919:INFO:SubProcess create_model() end ==================================
2024-07-16 12:25:46,919:INFO:Creating metrics dataframe
2024-07-16 12:25:46,925:INFO:Initializing CatBoost Classifier
2024-07-16 12:25:46,925:INFO:Total runtime is 0.7094203114509583 minutes
2024-07-16 12:25:46,927:INFO:SubProcess create_model() called ==================================
2024-07-16 12:25:46,928:INFO:Initializing create_model()
2024-07-16 12:25:46,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E38750>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:25:46,928:INFO:Checking exceptions
2024-07-16 12:25:46,928:INFO:Importing libraries
2024-07-16 12:25:46,928:INFO:Copying training dataset
2024-07-16 12:25:46,931:INFO:Defining folds
2024-07-16 12:25:46,931:INFO:Declaring metric variables
2024-07-16 12:25:46,933:INFO:Importing untrained model
2024-07-16 12:25:46,935:INFO:CatBoost Classifier Imported successfully
2024-07-16 12:25:46,940:INFO:Starting cross validation
2024-07-16 12:25:46,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:16,117:INFO:Calculating mean and std
2024-07-16 12:29:16,118:INFO:Creating metrics dataframe
2024-07-16 12:29:16,302:INFO:Uploading results into container
2024-07-16 12:29:16,303:INFO:Uploading model into container now
2024-07-16 12:29:16,303:INFO:_master_model_container: 15
2024-07-16 12:29:16,303:INFO:_display_container: 2
2024-07-16 12:29:16,303:INFO:<catboost.core.CatBoostClassifier object at 0x0000022DA4E26010>
2024-07-16 12:29:16,304:INFO:create_model() successfully completed......................................
2024-07-16 12:29:16,378:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:16,378:INFO:Creating metrics dataframe
2024-07-16 12:29:16,385:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-16 12:29:16,391:INFO:Initializing create_model()
2024-07-16 12:29:16,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52CBB290>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4992, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:16,391:INFO:Checking exceptions
2024-07-16 12:29:16,392:INFO:Importing libraries
2024-07-16 12:29:16,392:INFO:Copying training dataset
2024-07-16 12:29:16,394:INFO:Defining folds
2024-07-16 12:29:16,394:INFO:Declaring metric variables
2024-07-16 12:29:16,394:INFO:Importing untrained model
2024-07-16 12:29:16,394:INFO:Declaring custom model
2024-07-16 12:29:16,394:INFO:Decision Tree Classifier Imported successfully
2024-07-16 12:29:16,394:INFO:Cross validation set to False
2024-07-16 12:29:16,395:INFO:Fitting Model
2024-07-16 12:29:16,576:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4992, splitter='best')
2024-07-16 12:29:16,576:INFO:create_model() successfully completed......................................
2024-07-16 12:29:16,656:INFO:_master_model_container: 15
2024-07-16 12:29:16,657:INFO:_display_container: 2
2024-07-16 12:29:16,657:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4992, splitter='best')
2024-07-16 12:29:16,657:INFO:compare_models() successfully completed......................................
2024-07-16 12:29:16,668:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\codecarbon\output_methods\file.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  df = pd.concat([df, pd.DataFrame.from_records([dict(total.values)])])

2024-07-16 12:29:16,670:WARNING:C:\Users\JAL\AppData\Local\Temp\ipykernel_29900\796603356.py:82: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  best_model[best_model.select_dtypes(include=['number']).columns] *= 100

2024-07-16 12:29:17,017:INFO:PyCaret ClassificationExperiment
2024-07-16 12:29:17,017:INFO:Logging name: clf-default-name
2024-07-16 12:29:17,017:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-16 12:29:17,017:INFO:version 3.0.0
2024-07-16 12:29:17,017:INFO:Initializing setup()
2024-07-16 12:29:17,017:INFO:self.USI: 6617
2024-07-16 12:29:17,017:INFO:self._variable_keys: {'y_test', 'y', 'fold_shuffle_param', 'y_train', 'log_plots_param', 'html_param', 'data', 'exp_name_log', 'logging_param', 'gpu_n_jobs_param', 'X_test', 'idx', 'exp_id', 'fold_generator', 'X', 'is_multiclass', 'seed', '_available_plots', 'fold_groups_param', 'gpu_param', 'X_train', '_ml_usecase', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'memory', 'target_param', 'USI'}
2024-07-16 12:29:17,017:INFO:Checking environment
2024-07-16 12:29:17,017:INFO:python_version: 3.11.4
2024-07-16 12:29:17,017:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2024-07-16 12:29:17,017:INFO:machine: AMD64
2024-07-16 12:29:17,017:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-16 12:29:17,022:INFO:Memory: svmem(total=68659781632, available=50947231744, percent=25.8, used=17712549888, free=50947231744)
2024-07-16 12:29:17,022:INFO:Physical Core: 16
2024-07-16 12:29:17,022:INFO:Logical Core: 32
2024-07-16 12:29:17,022:INFO:Checking libraries
2024-07-16 12:29:17,022:INFO:System:
2024-07-16 12:29:17,022:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2024-07-16 12:29:17,022:INFO:executable: c:\Users\JAL\AppData\Local\Programs\Python\Python311\python.exe
2024-07-16 12:29:17,022:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-16 12:29:17,022:INFO:PyCaret required dependencies:
2024-07-16 12:29:17,022:INFO:                 pip: 24.1.2
2024-07-16 12:29:17,022:INFO:          setuptools: 70.3.0
2024-07-16 12:29:17,022:INFO:             pycaret: 3.0.0
2024-07-16 12:29:17,022:INFO:             IPython: 8.15.0
2024-07-16 12:29:17,022:INFO:          ipywidgets: 8.1.3
2024-07-16 12:29:17,022:INFO:                tqdm: 4.66.4
2024-07-16 12:29:17,022:INFO:               numpy: 1.24.4
2024-07-16 12:29:17,022:INFO:              pandas: 2.2.2
2024-07-16 12:29:17,022:INFO:              jinja2: 3.1.4
2024-07-16 12:29:17,022:INFO:               scipy: 1.11.4
2024-07-16 12:29:17,022:INFO:              joblib: 1.3.2
2024-07-16 12:29:17,022:INFO:             sklearn: 1.3.0
2024-07-16 12:29:17,022:INFO:                pyod: 2.0.1
2024-07-16 12:29:17,022:INFO:            imblearn: 0.12.3
2024-07-16 12:29:17,022:INFO:   category_encoders: 2.6.3
2024-07-16 12:29:17,022:INFO:            lightgbm: 4.3.0
2024-07-16 12:29:17,022:INFO:               numba: 0.60.0
2024-07-16 12:29:17,022:INFO:            requests: 2.32.3
2024-07-16 12:29:17,022:INFO:          matplotlib: 3.7.5
2024-07-16 12:29:17,022:INFO:          scikitplot: 0.3.7
2024-07-16 12:29:17,022:INFO:         yellowbrick: 1.5
2024-07-16 12:29:17,022:INFO:              plotly: 5.22.0
2024-07-16 12:29:17,022:INFO:             kaleido: 0.2.1
2024-07-16 12:29:17,022:INFO:         statsmodels: 0.14.2
2024-07-16 12:29:17,022:INFO:              sktime: 0.26.0
2024-07-16 12:29:17,022:INFO:               tbats: 1.1.3
2024-07-16 12:29:17,023:INFO:            pmdarima: 2.0.4
2024-07-16 12:29:17,023:INFO:              psutil: 5.9.5
2024-07-16 12:29:17,023:INFO:PyCaret optional dependencies:
2024-07-16 12:29:17,023:INFO:                shap: Not installed
2024-07-16 12:29:17,023:INFO:           interpret: Not installed
2024-07-16 12:29:17,023:INFO:                umap: Not installed
2024-07-16 12:29:17,023:INFO:    pandas_profiling: Not installed
2024-07-16 12:29:17,023:INFO:  explainerdashboard: Not installed
2024-07-16 12:29:17,023:INFO:             autoviz: Not installed
2024-07-16 12:29:17,023:INFO:           fairlearn: Not installed
2024-07-16 12:29:17,023:INFO:             xgboost: 2.0.3
2024-07-16 12:29:17,023:INFO:            catboost: 1.2.5
2024-07-16 12:29:17,023:INFO:              kmodes: Not installed
2024-07-16 12:29:17,023:INFO:             mlxtend: Not installed
2024-07-16 12:29:17,023:INFO:       statsforecast: 1.4.0
2024-07-16 12:29:17,023:INFO:        tune_sklearn: Not installed
2024-07-16 12:29:17,023:INFO:                 ray: 2.10.0
2024-07-16 12:29:17,023:INFO:            hyperopt: 0.2.7
2024-07-16 12:29:17,023:INFO:              optuna: Not installed
2024-07-16 12:29:17,023:INFO:               skopt: Not installed
2024-07-16 12:29:17,023:INFO:              mlflow: Not installed
2024-07-16 12:29:17,023:INFO:              gradio: Not installed
2024-07-16 12:29:17,023:INFO:             fastapi: Not installed
2024-07-16 12:29:17,023:INFO:             uvicorn: Not installed
2024-07-16 12:29:17,023:INFO:              m2cgen: Not installed
2024-07-16 12:29:17,023:INFO:           evidently: Not installed
2024-07-16 12:29:17,023:INFO:               fugue: Not installed
2024-07-16 12:29:17,023:INFO:           streamlit: 1.31.0
2024-07-16 12:29:17,023:INFO:             prophet: Not installed
2024-07-16 12:29:17,023:INFO:None
2024-07-16 12:29:17,023:INFO:Set up GPU usage.
2024-07-16 12:29:17,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,023:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2024-07-16 12:29:17,023:INFO:Set up data.
2024-07-16 12:29:17,025:INFO:Set up train/test split.
2024-07-16 12:29:17,027:INFO:Set up index.
2024-07-16 12:29:17,027:INFO:Set up folding strategy.
2024-07-16 12:29:17,027:INFO:Assigning column types.
2024-07-16 12:29:17,028:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-16 12:29:17,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:29:17,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,059:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:29:17,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,078:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:29:17,187:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:29:17,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:29:17,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:29:17,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,239:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:29:17,336:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:29:17,337:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-16 12:29:17,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,373:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:29:17,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,391:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,395:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:29:17,496:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:29:17,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,528:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:29:17,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,547:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:29:17,651:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:29:17,651:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-16 12:29:17,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,707:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:29:17,810:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:29:17,810:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,847:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,847:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:17,866:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:29:17,962:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:29:17,963:INFO:Preparing preprocessing pipeline...
2024-07-16 12:29:17,964:INFO:Set up simple imputation.
2024-07-16 12:29:17,973:INFO:Finished creating preprocessing pipeline.
2024-07-16 12:29:17,975:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-16 12:29:17,975:INFO:Creating final display dataframe.
2024-07-16 12:29:18,009:INFO:Setup _display_container:                     Description             Value
0                    Session id              1487
1                        Target       PlacedOrNot
2                   Target type            Binary
3           Original data shape         (2966, 3)
4        Transformed data shape         (2966, 3)
5   Transformed train set shape         (2076, 3)
6    Transformed test set shape          (890, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              6617
2024-07-16 12:29:18,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,070:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:29:18,168:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:29:18,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-16 12:29:18,220:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:29:18,321:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:29:18,322:INFO:setup() successfully completed in 1.47s...............
2024-07-16 12:29:18,322:INFO:Initializing compare_models()
2024-07-16 12:29:18,322:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-16 12:29:18,322:INFO:Checking exceptions
2024-07-16 12:29:18,323:INFO:Preparing display monitor
2024-07-16 12:29:18,338:INFO:Initializing Logistic Regression
2024-07-16 12:29:18,338:INFO:Total runtime is 0.0 minutes
2024-07-16 12:29:18,340:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:18,340:INFO:Initializing create_model()
2024-07-16 12:29:18,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:18,340:INFO:Checking exceptions
2024-07-16 12:29:18,341:INFO:Importing libraries
2024-07-16 12:29:18,341:INFO:Copying training dataset
2024-07-16 12:29:18,343:INFO:Defining folds
2024-07-16 12:29:18,343:INFO:Declaring metric variables
2024-07-16 12:29:18,345:INFO:Importing untrained model
2024-07-16 12:29:18,347:INFO:Logistic Regression Imported successfully
2024-07-16 12:29:18,352:INFO:Starting cross validation
2024-07-16 12:29:18,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:20,395:INFO:Calculating mean and std
2024-07-16 12:29:20,396:INFO:Creating metrics dataframe
2024-07-16 12:29:20,573:INFO:Uploading results into container
2024-07-16 12:29:20,574:INFO:Uploading model into container now
2024-07-16 12:29:20,574:INFO:_master_model_container: 1
2024-07-16 12:29:20,574:INFO:_display_container: 2
2024-07-16 12:29:20,574:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1487, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-16 12:29:20,575:INFO:create_model() successfully completed......................................
2024-07-16 12:29:20,642:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:20,642:INFO:Creating metrics dataframe
2024-07-16 12:29:20,647:INFO:Initializing K Neighbors Classifier
2024-07-16 12:29:20,647:INFO:Total runtime is 0.038476987679799395 minutes
2024-07-16 12:29:20,649:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:20,650:INFO:Initializing create_model()
2024-07-16 12:29:20,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:20,650:INFO:Checking exceptions
2024-07-16 12:29:20,650:INFO:Importing libraries
2024-07-16 12:29:20,650:INFO:Copying training dataset
2024-07-16 12:29:20,652:INFO:Defining folds
2024-07-16 12:29:20,652:INFO:Declaring metric variables
2024-07-16 12:29:20,654:INFO:Importing untrained model
2024-07-16 12:29:20,655:INFO:K Neighbors Classifier Imported successfully
2024-07-16 12:29:20,659:INFO:Starting cross validation
2024-07-16 12:29:20,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:23,174:INFO:Calculating mean and std
2024-07-16 12:29:23,175:INFO:Creating metrics dataframe
2024-07-16 12:29:23,350:INFO:Uploading results into container
2024-07-16 12:29:23,350:INFO:Uploading model into container now
2024-07-16 12:29:23,351:INFO:_master_model_container: 2
2024-07-16 12:29:23,351:INFO:_display_container: 2
2024-07-16 12:29:23,351:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-16 12:29:23,351:INFO:create_model() successfully completed......................................
2024-07-16 12:29:23,415:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:23,415:INFO:Creating metrics dataframe
2024-07-16 12:29:23,419:INFO:Initializing Naive Bayes
2024-07-16 12:29:23,419:INFO:Total runtime is 0.08468257188796996 minutes
2024-07-16 12:29:23,421:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:23,421:INFO:Initializing create_model()
2024-07-16 12:29:23,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:23,422:INFO:Checking exceptions
2024-07-16 12:29:23,422:INFO:Importing libraries
2024-07-16 12:29:23,422:INFO:Copying training dataset
2024-07-16 12:29:23,423:INFO:Defining folds
2024-07-16 12:29:23,423:INFO:Declaring metric variables
2024-07-16 12:29:23,425:INFO:Importing untrained model
2024-07-16 12:29:23,427:INFO:Naive Bayes Imported successfully
2024-07-16 12:29:23,431:INFO:Starting cross validation
2024-07-16 12:29:23,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:25,455:INFO:Calculating mean and std
2024-07-16 12:29:25,456:INFO:Creating metrics dataframe
2024-07-16 12:29:25,631:INFO:Uploading results into container
2024-07-16 12:29:25,632:INFO:Uploading model into container now
2024-07-16 12:29:25,632:INFO:_master_model_container: 3
2024-07-16 12:29:25,632:INFO:_display_container: 2
2024-07-16 12:29:25,632:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-16 12:29:25,632:INFO:create_model() successfully completed......................................
2024-07-16 12:29:25,707:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:25,707:INFO:Creating metrics dataframe
2024-07-16 12:29:25,712:INFO:Initializing Decision Tree Classifier
2024-07-16 12:29:25,712:INFO:Total runtime is 0.12289969523747761 minutes
2024-07-16 12:29:25,714:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:25,714:INFO:Initializing create_model()
2024-07-16 12:29:25,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:25,714:INFO:Checking exceptions
2024-07-16 12:29:25,714:INFO:Importing libraries
2024-07-16 12:29:25,714:INFO:Copying training dataset
2024-07-16 12:29:25,717:INFO:Defining folds
2024-07-16 12:29:25,717:INFO:Declaring metric variables
2024-07-16 12:29:25,718:INFO:Importing untrained model
2024-07-16 12:29:25,720:INFO:Decision Tree Classifier Imported successfully
2024-07-16 12:29:25,724:INFO:Starting cross validation
2024-07-16 12:29:25,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:27,740:INFO:Calculating mean and std
2024-07-16 12:29:27,741:INFO:Creating metrics dataframe
2024-07-16 12:29:27,915:INFO:Uploading results into container
2024-07-16 12:29:27,915:INFO:Uploading model into container now
2024-07-16 12:29:27,915:INFO:_master_model_container: 4
2024-07-16 12:29:27,915:INFO:_display_container: 2
2024-07-16 12:29:27,916:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1487, splitter='best')
2024-07-16 12:29:27,916:INFO:create_model() successfully completed......................................
2024-07-16 12:29:27,984:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:27,984:INFO:Creating metrics dataframe
2024-07-16 12:29:27,988:INFO:Initializing SVM - Linear Kernel
2024-07-16 12:29:27,989:INFO:Total runtime is 0.16085009574890136 minutes
2024-07-16 12:29:27,991:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:27,991:INFO:Initializing create_model()
2024-07-16 12:29:27,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:27,991:INFO:Checking exceptions
2024-07-16 12:29:27,991:INFO:Importing libraries
2024-07-16 12:29:27,991:INFO:Copying training dataset
2024-07-16 12:29:27,993:INFO:Defining folds
2024-07-16 12:29:27,993:INFO:Declaring metric variables
2024-07-16 12:29:27,995:INFO:Importing untrained model
2024-07-16 12:29:27,997:INFO:SVM - Linear Kernel Imported successfully
2024-07-16 12:29:28,000:INFO:Starting cross validation
2024-07-16 12:29:28,001:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:28,026:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:28,233:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:28,433:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:28,632:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:28,829:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:29,036:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:29,248:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:29,447:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:29,649:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:29,847:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:30,022:INFO:Calculating mean and std
2024-07-16 12:29:30,023:INFO:Creating metrics dataframe
2024-07-16 12:29:30,202:INFO:Uploading results into container
2024-07-16 12:29:30,202:INFO:Uploading model into container now
2024-07-16 12:29:30,203:INFO:_master_model_container: 5
2024-07-16 12:29:30,203:INFO:_display_container: 2
2024-07-16 12:29:30,203:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1487, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-16 12:29:30,203:INFO:create_model() successfully completed......................................
2024-07-16 12:29:30,276:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:30,277:INFO:Creating metrics dataframe
2024-07-16 12:29:30,281:INFO:Initializing Ridge Classifier
2024-07-16 12:29:30,282:INFO:Total runtime is 0.19905073245366414 minutes
2024-07-16 12:29:30,283:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:30,284:INFO:Initializing create_model()
2024-07-16 12:29:30,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:30,284:INFO:Checking exceptions
2024-07-16 12:29:30,284:INFO:Importing libraries
2024-07-16 12:29:30,284:INFO:Copying training dataset
2024-07-16 12:29:30,286:INFO:Defining folds
2024-07-16 12:29:30,286:INFO:Declaring metric variables
2024-07-16 12:29:30,288:INFO:Importing untrained model
2024-07-16 12:29:30,290:INFO:Ridge Classifier Imported successfully
2024-07-16 12:29:30,293:INFO:Starting cross validation
2024-07-16 12:29:30,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:30,314:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:30,517:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:30,710:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:30,904:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:31,099:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:31,296:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:31,504:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:31,707:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:31,899:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:32,093:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:29:32,267:INFO:Calculating mean and std
2024-07-16 12:29:32,268:INFO:Creating metrics dataframe
2024-07-16 12:29:32,436:INFO:Uploading results into container
2024-07-16 12:29:32,437:INFO:Uploading model into container now
2024-07-16 12:29:32,437:INFO:_master_model_container: 6
2024-07-16 12:29:32,437:INFO:_display_container: 2
2024-07-16 12:29:32,437:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1487, solver='auto',
                tol=0.0001)
2024-07-16 12:29:32,438:INFO:create_model() successfully completed......................................
2024-07-16 12:29:32,502:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:32,502:INFO:Creating metrics dataframe
2024-07-16 12:29:32,507:INFO:Initializing Random Forest Classifier
2024-07-16 12:29:32,507:INFO:Total runtime is 0.23614716927210488 minutes
2024-07-16 12:29:32,509:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:32,510:INFO:Initializing create_model()
2024-07-16 12:29:32,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:32,510:INFO:Checking exceptions
2024-07-16 12:29:32,510:INFO:Importing libraries
2024-07-16 12:29:32,510:INFO:Copying training dataset
2024-07-16 12:29:32,512:INFO:Defining folds
2024-07-16 12:29:32,512:INFO:Declaring metric variables
2024-07-16 12:29:32,514:INFO:Importing untrained model
2024-07-16 12:29:32,516:INFO:Random Forest Classifier Imported successfully
2024-07-16 12:29:32,519:INFO:Starting cross validation
2024-07-16 12:29:32,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:36,566:INFO:Calculating mean and std
2024-07-16 12:29:36,566:INFO:Creating metrics dataframe
2024-07-16 12:29:36,738:INFO:Uploading results into container
2024-07-16 12:29:36,738:INFO:Uploading model into container now
2024-07-16 12:29:36,739:INFO:_master_model_container: 7
2024-07-16 12:29:36,739:INFO:_display_container: 2
2024-07-16 12:29:36,739:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1487, verbose=0, warm_start=False)
2024-07-16 12:29:36,739:INFO:create_model() successfully completed......................................
2024-07-16 12:29:36,806:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:36,806:INFO:Creating metrics dataframe
2024-07-16 12:29:36,811:INFO:Initializing Quadratic Discriminant Analysis
2024-07-16 12:29:36,811:INFO:Total runtime is 0.30787905454635617 minutes
2024-07-16 12:29:36,813:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:36,814:INFO:Initializing create_model()
2024-07-16 12:29:36,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:36,814:INFO:Checking exceptions
2024-07-16 12:29:36,814:INFO:Importing libraries
2024-07-16 12:29:36,814:INFO:Copying training dataset
2024-07-16 12:29:36,815:INFO:Defining folds
2024-07-16 12:29:36,816:INFO:Declaring metric variables
2024-07-16 12:29:36,817:INFO:Importing untrained model
2024-07-16 12:29:36,819:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-16 12:29:36,822:INFO:Starting cross validation
2024-07-16 12:29:36,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:38,858:INFO:Calculating mean and std
2024-07-16 12:29:38,859:INFO:Creating metrics dataframe
2024-07-16 12:29:39,034:INFO:Uploading results into container
2024-07-16 12:29:39,036:INFO:Uploading model into container now
2024-07-16 12:29:39,036:INFO:_master_model_container: 8
2024-07-16 12:29:39,036:INFO:_display_container: 2
2024-07-16 12:29:39,036:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-16 12:29:39,036:INFO:create_model() successfully completed......................................
2024-07-16 12:29:39,103:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:39,103:INFO:Creating metrics dataframe
2024-07-16 12:29:39,109:INFO:Initializing Ada Boost Classifier
2024-07-16 12:29:39,109:INFO:Total runtime is 0.34617862701416013 minutes
2024-07-16 12:29:39,111:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:39,111:INFO:Initializing create_model()
2024-07-16 12:29:39,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:39,111:INFO:Checking exceptions
2024-07-16 12:29:39,111:INFO:Importing libraries
2024-07-16 12:29:39,111:INFO:Copying training dataset
2024-07-16 12:29:39,113:INFO:Defining folds
2024-07-16 12:29:39,113:INFO:Declaring metric variables
2024-07-16 12:29:39,115:INFO:Importing untrained model
2024-07-16 12:29:39,117:INFO:Ada Boost Classifier Imported successfully
2024-07-16 12:29:39,120:INFO:Starting cross validation
2024-07-16 12:29:39,121:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:42,074:INFO:Calculating mean and std
2024-07-16 12:29:42,074:INFO:Creating metrics dataframe
2024-07-16 12:29:42,257:INFO:Uploading results into container
2024-07-16 12:29:42,258:INFO:Uploading model into container now
2024-07-16 12:29:42,258:INFO:_master_model_container: 9
2024-07-16 12:29:42,258:INFO:_display_container: 2
2024-07-16 12:29:42,258:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1487)
2024-07-16 12:29:42,258:INFO:create_model() successfully completed......................................
2024-07-16 12:29:42,325:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:42,325:INFO:Creating metrics dataframe
2024-07-16 12:29:42,330:INFO:Initializing Gradient Boosting Classifier
2024-07-16 12:29:42,330:INFO:Total runtime is 0.3998682419459025 minutes
2024-07-16 12:29:42,332:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:42,332:INFO:Initializing create_model()
2024-07-16 12:29:42,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:42,332:INFO:Checking exceptions
2024-07-16 12:29:42,333:INFO:Importing libraries
2024-07-16 12:29:42,333:INFO:Copying training dataset
2024-07-16 12:29:42,334:INFO:Defining folds
2024-07-16 12:29:42,334:INFO:Declaring metric variables
2024-07-16 12:29:42,336:INFO:Importing untrained model
2024-07-16 12:29:42,338:INFO:Gradient Boosting Classifier Imported successfully
2024-07-16 12:29:42,342:INFO:Starting cross validation
2024-07-16 12:29:42,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:45,296:INFO:Calculating mean and std
2024-07-16 12:29:45,306:INFO:Creating metrics dataframe
2024-07-16 12:29:45,476:INFO:Uploading results into container
2024-07-16 12:29:45,476:INFO:Uploading model into container now
2024-07-16 12:29:45,476:INFO:_master_model_container: 10
2024-07-16 12:29:45,476:INFO:_display_container: 2
2024-07-16 12:29:45,476:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1487, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-16 12:29:45,476:INFO:create_model() successfully completed......................................
2024-07-16 12:29:45,547:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:45,547:INFO:Creating metrics dataframe
2024-07-16 12:29:45,551:INFO:Initializing Linear Discriminant Analysis
2024-07-16 12:29:45,551:INFO:Total runtime is 0.45354524056116735 minutes
2024-07-16 12:29:45,551:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:45,551:INFO:Initializing create_model()
2024-07-16 12:29:45,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:45,551:INFO:Checking exceptions
2024-07-16 12:29:45,551:INFO:Importing libraries
2024-07-16 12:29:45,551:INFO:Copying training dataset
2024-07-16 12:29:45,556:INFO:Defining folds
2024-07-16 12:29:45,556:INFO:Declaring metric variables
2024-07-16 12:29:45,556:INFO:Importing untrained model
2024-07-16 12:29:45,556:INFO:Linear Discriminant Analysis Imported successfully
2024-07-16 12:29:45,556:INFO:Starting cross validation
2024-07-16 12:29:45,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:47,626:INFO:Calculating mean and std
2024-07-16 12:29:47,626:INFO:Creating metrics dataframe
2024-07-16 12:29:47,805:INFO:Uploading results into container
2024-07-16 12:29:47,806:INFO:Uploading model into container now
2024-07-16 12:29:47,806:INFO:_master_model_container: 11
2024-07-16 12:29:47,806:INFO:_display_container: 2
2024-07-16 12:29:47,806:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-16 12:29:47,807:INFO:create_model() successfully completed......................................
2024-07-16 12:29:47,876:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:47,876:INFO:Creating metrics dataframe
2024-07-16 12:29:47,881:INFO:Initializing Extra Trees Classifier
2024-07-16 12:29:47,881:INFO:Total runtime is 0.4923764586448669 minutes
2024-07-16 12:29:47,881:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:47,881:INFO:Initializing create_model()
2024-07-16 12:29:47,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:47,881:INFO:Checking exceptions
2024-07-16 12:29:47,881:INFO:Importing libraries
2024-07-16 12:29:47,881:INFO:Copying training dataset
2024-07-16 12:29:47,886:INFO:Defining folds
2024-07-16 12:29:47,886:INFO:Declaring metric variables
2024-07-16 12:29:47,886:INFO:Importing untrained model
2024-07-16 12:29:47,888:INFO:Extra Trees Classifier Imported successfully
2024-07-16 12:29:47,888:INFO:Starting cross validation
2024-07-16 12:29:47,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:51,567:INFO:Calculating mean and std
2024-07-16 12:29:51,567:INFO:Creating metrics dataframe
2024-07-16 12:29:51,746:INFO:Uploading results into container
2024-07-16 12:29:51,746:INFO:Uploading model into container now
2024-07-16 12:29:51,746:INFO:_master_model_container: 12
2024-07-16 12:29:51,746:INFO:_display_container: 2
2024-07-16 12:29:51,746:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1487, verbose=0, warm_start=False)
2024-07-16 12:29:51,746:INFO:create_model() successfully completed......................................
2024-07-16 12:29:51,816:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:51,816:INFO:Creating metrics dataframe
2024-07-16 12:29:51,823:INFO:Initializing Extreme Gradient Boosting
2024-07-16 12:29:51,823:INFO:Total runtime is 0.5580733140309652 minutes
2024-07-16 12:29:51,826:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:51,826:INFO:Initializing create_model()
2024-07-16 12:29:51,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:51,826:INFO:Checking exceptions
2024-07-16 12:29:51,826:INFO:Importing libraries
2024-07-16 12:29:51,826:INFO:Copying training dataset
2024-07-16 12:29:51,826:INFO:Defining folds
2024-07-16 12:29:51,826:INFO:Declaring metric variables
2024-07-16 12:29:51,826:INFO:Importing untrained model
2024-07-16 12:29:51,826:INFO:Extreme Gradient Boosting Imported successfully
2024-07-16 12:29:51,836:INFO:Starting cross validation
2024-07-16 12:29:51,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:52,171:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:52] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:52,556:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:52] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:52,946:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:52] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:53,337:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:53] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:53,721:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:53] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:54,150:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:54] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:54,575:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:54] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:54,986:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:54] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:55,425:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:55] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:55,876:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [12:29:55] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-16 12:29:56,127:INFO:Calculating mean and std
2024-07-16 12:29:56,127:INFO:Creating metrics dataframe
2024-07-16 12:29:56,316:INFO:Uploading results into container
2024-07-16 12:29:56,316:INFO:Uploading model into container now
2024-07-16 12:29:56,316:INFO:_master_model_container: 13
2024-07-16 12:29:56,316:INFO:_display_container: 2
2024-07-16 12:29:56,316:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-16 12:29:56,316:INFO:create_model() successfully completed......................................
2024-07-16 12:29:56,379:INFO:SubProcess create_model() end ==================================
2024-07-16 12:29:56,379:INFO:Creating metrics dataframe
2024-07-16 12:29:56,387:INFO:Initializing Light Gradient Boosting Machine
2024-07-16 12:29:56,387:INFO:Total runtime is 0.6341498613357544 minutes
2024-07-16 12:29:56,387:INFO:SubProcess create_model() called ==================================
2024-07-16 12:29:56,387:INFO:Initializing create_model()
2024-07-16 12:29:56,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:29:56,387:INFO:Checking exceptions
2024-07-16 12:29:56,387:INFO:Importing libraries
2024-07-16 12:29:56,387:INFO:Copying training dataset
2024-07-16 12:29:56,387:INFO:Defining folds
2024-07-16 12:29:56,387:INFO:Declaring metric variables
2024-07-16 12:29:56,395:INFO:Importing untrained model
2024-07-16 12:29:56,396:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-16 12:29:56,396:INFO:Starting cross validation
2024-07-16 12:29:56,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:29:56,411:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-16 12:29:56,411:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:29:56,411:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:29:56,411:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 2
2024-07-16 12:29:56,497:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:29:56,497:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:29:56,507:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:29:56,507:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:29:56,507:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000417 secs. 0 sparse feature groups
2024-07-16 12:29:56,507:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-16 12:29:56,507:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-16 12:29:56,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:56,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,050:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-16 12:29:57,050:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:29:57,050:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:29:57,050:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 2
2024-07-16 12:29:57,126:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:29:57,126:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:29:57,136:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:29:57,136:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:29:57,136:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000462 secs. 0 sparse feature groups
2024-07-16 12:29:57,136:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-16 12:29:57,136:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-16 12:29:57,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,658:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-16 12:29:57,658:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:29:57,658:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:29:57,658:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 2
2024-07-16 12:29:57,735:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:29:57,735:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:29:57,745:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:29:57,745:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:29:57,745:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000409 secs. 0 sparse feature groups
2024-07-16 12:29:57,745:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-16 12:29:57,745:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-16 12:29:57,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:57,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,249:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-16 12:29:58,249:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:29:58,249:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:29:58,249:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 2
2024-07-16 12:29:58,326:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:29:58,326:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:29:58,336:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:29:58,339:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:29:58,340:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000563 secs. 0 sparse feature groups
2024-07-16 12:29:58,340:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-16 12:29:58,340:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-16 12:29:58,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,841:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-16 12:29:58,841:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:29:58,841:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:29:58,841:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 2
2024-07-16 12:29:58,917:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:29:58,917:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:29:58,926:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:29:58,927:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:29:58,928:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000467 secs. 0 sparse feature groups
2024-07-16 12:29:58,928:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-16 12:29:58,928:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-16 12:29:58,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:58,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,455:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-16 12:29:59,455:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:29:59,455:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:29:59,455:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 2
2024-07-16 12:29:59,535:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:29:59,535:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:29:59,544:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:29:59,545:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:29:59,545:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000423 secs. 0 sparse feature groups
2024-07-16 12:29:59,546:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-16 12:29:59,546:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-16 12:29:59,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:29:59,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,080:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 837
2024-07-16 12:30:00,080:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:30:00,080:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:30:00,080:INFO:[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 2
2024-07-16 12:30:00,159:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:30:00,159:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:30:00,167:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:30:00,168:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:30:00,170:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000447 secs. 0 sparse feature groups
2024-07-16 12:30:00,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552167 -> initscore=0.209430
2024-07-16 12:30:00,170:INFO:[LightGBM] [Info] Start training from score 0.209430
2024-07-16 12:30:00,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,709:INFO:[LightGBM] [Info] Number of positive: 1033, number of negative: 836
2024-07-16 12:30:00,709:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:30:00,709:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:30:00,709:INFO:[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 2
2024-07-16 12:30:00,786:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:30:00,786:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:30:00,794:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:30:00,797:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:30:00,798:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000418 secs. 0 sparse feature groups
2024-07-16 12:30:00,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552702 -> initscore=0.211594
2024-07-16 12:30:00,798:INFO:[LightGBM] [Info] Start training from score 0.211594
2024-07-16 12:30:00,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:00,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,339:INFO:[LightGBM] [Info] Number of positive: 1033, number of negative: 836
2024-07-16 12:30:01,339:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:30:01,339:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:30:01,339:INFO:[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 2
2024-07-16 12:30:01,411:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:30:01,411:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:30:01,420:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:30:01,421:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:30:01,422:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000399 secs. 0 sparse feature groups
2024-07-16 12:30:01,422:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552702 -> initscore=0.211594
2024-07-16 12:30:01,422:INFO:[LightGBM] [Info] Start training from score 0.211594
2024-07-16 12:30:01,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:01,925:INFO:[LightGBM] [Info] Number of positive: 1033, number of negative: 836
2024-07-16 12:30:01,925:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-16 12:30:01,925:INFO:[LightGBM] [Info] Total Bins 10
2024-07-16 12:30:01,925:INFO:[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 2
2024-07-16 12:30:02,005:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-16 12:30:02,005:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-16 12:30:02,015:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-16 12:30:02,017:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-16 12:30:02,017:INFO:[LightGBM] [Info] 2 dense feature groups (0.01 MB) transferred to GPU in 0.000416 secs. 0 sparse feature groups
2024-07-16 12:30:02,017:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552702 -> initscore=0.211594
2024-07-16 12:30:02,017:INFO:[LightGBM] [Info] Start training from score 0.211594
2024-07-16 12:30:02,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-16 12:30:02,556:INFO:Calculating mean and std
2024-07-16 12:30:02,557:INFO:Creating metrics dataframe
2024-07-16 12:30:02,751:INFO:Uploading results into container
2024-07-16 12:30:02,751:INFO:Uploading model into container now
2024-07-16 12:30:02,752:INFO:_master_model_container: 14
2024-07-16 12:30:02,752:INFO:_display_container: 2
2024-07-16 12:30:02,752:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1487, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-16 12:30:02,752:INFO:create_model() successfully completed......................................
2024-07-16 12:30:02,817:INFO:SubProcess create_model() end ==================================
2024-07-16 12:30:02,817:INFO:Creating metrics dataframe
2024-07-16 12:30:02,823:INFO:Initializing CatBoost Classifier
2024-07-16 12:30:02,823:INFO:Total runtime is 0.7414129972457886 minutes
2024-07-16 12:30:02,825:INFO:SubProcess create_model() called ==================================
2024-07-16 12:30:02,825:INFO:Initializing create_model()
2024-07-16 12:30:02,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E16050>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:30:02,826:INFO:Checking exceptions
2024-07-16 12:30:02,826:INFO:Importing libraries
2024-07-16 12:30:02,826:INFO:Copying training dataset
2024-07-16 12:30:02,827:INFO:Defining folds
2024-07-16 12:30:02,827:INFO:Declaring metric variables
2024-07-16 12:30:02,829:INFO:Importing untrained model
2024-07-16 12:30:02,831:INFO:CatBoost Classifier Imported successfully
2024-07-16 12:30:02,835:INFO:Starting cross validation
2024-07-16 12:30:02,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-16 12:33:38,608:INFO:Calculating mean and std
2024-07-16 12:33:38,609:INFO:Creating metrics dataframe
2024-07-16 12:33:38,802:INFO:Uploading results into container
2024-07-16 12:33:38,803:INFO:Uploading model into container now
2024-07-16 12:33:38,803:INFO:_master_model_container: 15
2024-07-16 12:33:38,803:INFO:_display_container: 2
2024-07-16 12:33:38,803:INFO:<catboost.core.CatBoostClassifier object at 0x0000022D4A277B50>
2024-07-16 12:33:38,803:INFO:create_model() successfully completed......................................
2024-07-16 12:33:38,883:INFO:SubProcess create_model() end ==================================
2024-07-16 12:33:38,883:INFO:Creating metrics dataframe
2024-07-16 12:33:38,890:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-16 12:33:38,895:INFO:Initializing create_model()
2024-07-16 12:33:38,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D52C43E50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1487, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:33:38,896:INFO:Checking exceptions
2024-07-16 12:33:38,897:INFO:Importing libraries
2024-07-16 12:33:38,897:INFO:Copying training dataset
2024-07-16 12:33:38,898:INFO:Defining folds
2024-07-16 12:33:38,898:INFO:Declaring metric variables
2024-07-16 12:33:38,898:INFO:Importing untrained model
2024-07-16 12:33:38,898:INFO:Declaring custom model
2024-07-16 12:33:38,899:INFO:Random Forest Classifier Imported successfully
2024-07-16 12:33:38,899:INFO:Cross validation set to False
2024-07-16 12:33:38,899:INFO:Fitting Model
2024-07-16 12:33:39,254:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1487, verbose=0, warm_start=False)
2024-07-16 12:33:39,254:INFO:create_model() successfully completed......................................
2024-07-16 12:33:39,335:INFO:_master_model_container: 15
2024-07-16 12:33:39,335:INFO:_display_container: 2
2024-07-16 12:33:39,335:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1487, verbose=0, warm_start=False)
2024-07-16 12:33:39,336:INFO:compare_models() successfully completed......................................
2024-07-16 12:33:39,354:WARNING:C:\Users\JAL\AppData\Local\Temp\ipykernel_29900\796603356.py:82: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  best_model[best_model.select_dtypes(include=['number']).columns] *= 100

2024-07-16 12:33:39,721:INFO:PyCaret ClassificationExperiment
2024-07-16 12:33:39,721:INFO:Logging name: clf-default-name
2024-07-16 12:33:39,721:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-16 12:33:39,721:INFO:version 3.0.0
2024-07-16 12:33:39,721:INFO:Initializing setup()
2024-07-16 12:33:39,721:INFO:self.USI: e598
2024-07-16 12:33:39,721:INFO:self._variable_keys: {'y_test', 'y', 'fold_shuffle_param', 'y_train', 'log_plots_param', 'html_param', 'data', 'exp_name_log', 'logging_param', 'gpu_n_jobs_param', 'X_test', 'idx', 'exp_id', 'fold_generator', 'X', 'is_multiclass', 'seed', '_available_plots', 'fold_groups_param', 'gpu_param', 'X_train', '_ml_usecase', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'memory', 'target_param', 'USI'}
2024-07-16 12:33:39,722:INFO:Checking environment
2024-07-16 12:33:39,722:INFO:python_version: 3.11.4
2024-07-16 12:33:39,722:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2024-07-16 12:33:39,722:INFO:machine: AMD64
2024-07-16 12:33:39,722:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-16 12:33:39,725:INFO:Memory: svmem(total=68659781632, available=50880241664, percent=25.9, used=17779539968, free=50880241664)
2024-07-16 12:33:39,725:INFO:Physical Core: 16
2024-07-16 12:33:39,726:INFO:Logical Core: 32
2024-07-16 12:33:39,726:INFO:Checking libraries
2024-07-16 12:33:39,726:INFO:System:
2024-07-16 12:33:39,726:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2024-07-16 12:33:39,726:INFO:executable: c:\Users\JAL\AppData\Local\Programs\Python\Python311\python.exe
2024-07-16 12:33:39,726:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-16 12:33:39,726:INFO:PyCaret required dependencies:
2024-07-16 12:33:39,726:INFO:                 pip: 24.1.2
2024-07-16 12:33:39,726:INFO:          setuptools: 70.3.0
2024-07-16 12:33:39,726:INFO:             pycaret: 3.0.0
2024-07-16 12:33:39,726:INFO:             IPython: 8.15.0
2024-07-16 12:33:39,726:INFO:          ipywidgets: 8.1.3
2024-07-16 12:33:39,726:INFO:                tqdm: 4.66.4
2024-07-16 12:33:39,726:INFO:               numpy: 1.24.4
2024-07-16 12:33:39,726:INFO:              pandas: 2.2.2
2024-07-16 12:33:39,726:INFO:              jinja2: 3.1.4
2024-07-16 12:33:39,726:INFO:               scipy: 1.11.4
2024-07-16 12:33:39,726:INFO:              joblib: 1.3.2
2024-07-16 12:33:39,726:INFO:             sklearn: 1.3.0
2024-07-16 12:33:39,726:INFO:                pyod: 2.0.1
2024-07-16 12:33:39,726:INFO:            imblearn: 0.12.3
2024-07-16 12:33:39,726:INFO:   category_encoders: 2.6.3
2024-07-16 12:33:39,726:INFO:            lightgbm: 4.3.0
2024-07-16 12:33:39,726:INFO:               numba: 0.60.0
2024-07-16 12:33:39,726:INFO:            requests: 2.32.3
2024-07-16 12:33:39,726:INFO:          matplotlib: 3.7.5
2024-07-16 12:33:39,726:INFO:          scikitplot: 0.3.7
2024-07-16 12:33:39,726:INFO:         yellowbrick: 1.5
2024-07-16 12:33:39,726:INFO:              plotly: 5.22.0
2024-07-16 12:33:39,726:INFO:             kaleido: 0.2.1
2024-07-16 12:33:39,726:INFO:         statsmodels: 0.14.2
2024-07-16 12:33:39,726:INFO:              sktime: 0.26.0
2024-07-16 12:33:39,726:INFO:               tbats: 1.1.3
2024-07-16 12:33:39,726:INFO:            pmdarima: 2.0.4
2024-07-16 12:33:39,726:INFO:              psutil: 5.9.5
2024-07-16 12:33:39,726:INFO:PyCaret optional dependencies:
2024-07-16 12:33:39,726:INFO:                shap: Not installed
2024-07-16 12:33:39,727:INFO:           interpret: Not installed
2024-07-16 12:33:39,727:INFO:                umap: Not installed
2024-07-16 12:33:39,727:INFO:    pandas_profiling: Not installed
2024-07-16 12:33:39,727:INFO:  explainerdashboard: Not installed
2024-07-16 12:33:39,727:INFO:             autoviz: Not installed
2024-07-16 12:33:39,727:INFO:           fairlearn: Not installed
2024-07-16 12:33:39,727:INFO:             xgboost: 2.0.3
2024-07-16 12:33:39,727:INFO:            catboost: 1.2.5
2024-07-16 12:33:39,727:INFO:              kmodes: Not installed
2024-07-16 12:33:39,727:INFO:             mlxtend: Not installed
2024-07-16 12:33:39,727:INFO:       statsforecast: 1.4.0
2024-07-16 12:33:39,727:INFO:        tune_sklearn: Not installed
2024-07-16 12:33:39,727:INFO:                 ray: 2.10.0
2024-07-16 12:33:39,727:INFO:            hyperopt: 0.2.7
2024-07-16 12:33:39,727:INFO:              optuna: Not installed
2024-07-16 12:33:39,727:INFO:               skopt: Not installed
2024-07-16 12:33:39,727:INFO:              mlflow: Not installed
2024-07-16 12:33:39,727:INFO:              gradio: Not installed
2024-07-16 12:33:39,727:INFO:             fastapi: Not installed
2024-07-16 12:33:39,727:INFO:             uvicorn: Not installed
2024-07-16 12:33:39,727:INFO:              m2cgen: Not installed
2024-07-16 12:33:39,727:INFO:           evidently: Not installed
2024-07-16 12:33:39,727:INFO:               fugue: Not installed
2024-07-16 12:33:39,727:INFO:           streamlit: 1.31.0
2024-07-16 12:33:39,727:INFO:             prophet: Not installed
2024-07-16 12:33:39,727:INFO:None
2024-07-16 12:33:39,727:INFO:Set up data.
2024-07-16 12:33:39,729:INFO:Set up train/test split.
2024-07-16 12:33:39,731:INFO:Set up index.
2024-07-16 12:33:39,731:INFO:Set up folding strategy.
2024-07-16 12:33:39,731:INFO:Assigning column types.
2024-07-16 12:33:39,733:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-16 12:33:39,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:33:39,763:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:33:39,782:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:33:39,784:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:33:39,814:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:33:39,814:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:33:39,834:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:33:39,835:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:33:39,836:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-16 12:33:39,866:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:33:39,884:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:33:39,886:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:33:39,917:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:33:39,936:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:33:39,937:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:33:39,937:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-16 12:33:39,986:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:33:39,988:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:33:40,037:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:33:40,039:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:33:40,040:INFO:Preparing preprocessing pipeline...
2024-07-16 12:33:40,040:INFO:Set up simple imputation.
2024-07-16 12:33:40,048:INFO:Finished creating preprocessing pipeline.
2024-07-16 12:33:40,050:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-16 12:33:40,050:INFO:Creating final display dataframe.
2024-07-16 12:33:40,078:INFO:Setup _display_container:                     Description             Value
0                    Session id              6087
1                        Target       PlacedOrNot
2                   Target type            Binary
3           Original data shape         (2224, 3)
4        Transformed data shape         (2224, 3)
5   Transformed train set shape         (1668, 3)
6    Transformed test set shape          (556, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e598
2024-07-16 12:33:40,130:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:33:40,132:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:33:40,181:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:33:40,183:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:33:40,184:INFO:setup() successfully completed in 0.65s...............
2024-07-16 12:33:40,184:INFO:Initializing compare_models()
2024-07-16 12:33:40,184:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-16 12:33:40,184:INFO:Checking exceptions
2024-07-16 12:33:40,185:INFO:Preparing display monitor
2024-07-16 12:33:40,198:INFO:Initializing Logistic Regression
2024-07-16 12:33:40,198:INFO:Total runtime is 0.0 minutes
2024-07-16 12:33:40,199:INFO:SubProcess create_model() called ==================================
2024-07-16 12:33:40,200:INFO:Initializing create_model()
2024-07-16 12:33:40,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:33:40,200:INFO:Checking exceptions
2024-07-16 12:33:40,200:INFO:Importing libraries
2024-07-16 12:33:40,200:INFO:Copying training dataset
2024-07-16 12:33:40,201:INFO:Defining folds
2024-07-16 12:33:40,201:INFO:Declaring metric variables
2024-07-16 12:33:40,203:INFO:Importing untrained model
2024-07-16 12:33:40,205:INFO:Logistic Regression Imported successfully
2024-07-16 12:33:40,209:INFO:Starting cross validation
2024-07-16 12:33:40,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:33:44,029:INFO:Calculating mean and std
2024-07-16 12:33:44,030:INFO:Creating metrics dataframe
2024-07-16 12:33:44,261:INFO:Uploading results into container
2024-07-16 12:33:44,262:INFO:Uploading model into container now
2024-07-16 12:33:44,262:INFO:_master_model_container: 1
2024-07-16 12:33:44,262:INFO:_display_container: 2
2024-07-16 12:33:44,263:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6087, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-16 12:33:44,263:INFO:create_model() successfully completed......................................
2024-07-16 12:33:44,332:INFO:SubProcess create_model() end ==================================
2024-07-16 12:33:44,332:INFO:Creating metrics dataframe
2024-07-16 12:33:44,337:INFO:Initializing K Neighbors Classifier
2024-07-16 12:33:44,337:INFO:Total runtime is 0.06899357636769612 minutes
2024-07-16 12:33:44,339:INFO:SubProcess create_model() called ==================================
2024-07-16 12:33:44,339:INFO:Initializing create_model()
2024-07-16 12:33:44,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:33:44,339:INFO:Checking exceptions
2024-07-16 12:33:44,339:INFO:Importing libraries
2024-07-16 12:33:44,339:INFO:Copying training dataset
2024-07-16 12:33:44,340:INFO:Defining folds
2024-07-16 12:33:44,340:INFO:Declaring metric variables
2024-07-16 12:33:44,343:INFO:Importing untrained model
2024-07-16 12:33:44,345:INFO:K Neighbors Classifier Imported successfully
2024-07-16 12:33:44,349:INFO:Starting cross validation
2024-07-16 12:33:44,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:33:47,911:INFO:Calculating mean and std
2024-07-16 12:33:47,912:INFO:Creating metrics dataframe
2024-07-16 12:33:48,149:INFO:Uploading results into container
2024-07-16 12:33:48,149:INFO:Uploading model into container now
2024-07-16 12:33:48,150:INFO:_master_model_container: 2
2024-07-16 12:33:48,150:INFO:_display_container: 2
2024-07-16 12:33:48,150:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-16 12:33:48,150:INFO:create_model() successfully completed......................................
2024-07-16 12:33:48,217:INFO:SubProcess create_model() end ==================================
2024-07-16 12:33:48,217:INFO:Creating metrics dataframe
2024-07-16 12:33:48,221:INFO:Initializing Naive Bayes
2024-07-16 12:33:48,221:INFO:Total runtime is 0.1337246100107829 minutes
2024-07-16 12:33:48,224:INFO:SubProcess create_model() called ==================================
2024-07-16 12:33:48,224:INFO:Initializing create_model()
2024-07-16 12:33:48,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:33:48,224:INFO:Checking exceptions
2024-07-16 12:33:48,224:INFO:Importing libraries
2024-07-16 12:33:48,224:INFO:Copying training dataset
2024-07-16 12:33:48,226:INFO:Defining folds
2024-07-16 12:33:48,226:INFO:Declaring metric variables
2024-07-16 12:33:48,227:INFO:Importing untrained model
2024-07-16 12:33:48,229:INFO:Naive Bayes Imported successfully
2024-07-16 12:33:48,233:INFO:Starting cross validation
2024-07-16 12:33:48,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:33:51,956:INFO:Calculating mean and std
2024-07-16 12:33:51,957:INFO:Creating metrics dataframe
2024-07-16 12:33:52,190:INFO:Uploading results into container
2024-07-16 12:33:52,191:INFO:Uploading model into container now
2024-07-16 12:33:52,191:INFO:_master_model_container: 3
2024-07-16 12:33:52,191:INFO:_display_container: 2
2024-07-16 12:33:52,191:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-16 12:33:52,191:INFO:create_model() successfully completed......................................
2024-07-16 12:33:52,259:INFO:SubProcess create_model() end ==================================
2024-07-16 12:33:52,259:INFO:Creating metrics dataframe
2024-07-16 12:33:52,264:INFO:Initializing Decision Tree Classifier
2024-07-16 12:33:52,264:INFO:Total runtime is 0.20110982259114585 minutes
2024-07-16 12:33:52,266:INFO:SubProcess create_model() called ==================================
2024-07-16 12:33:52,266:INFO:Initializing create_model()
2024-07-16 12:33:52,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:33:52,266:INFO:Checking exceptions
2024-07-16 12:33:52,266:INFO:Importing libraries
2024-07-16 12:33:52,266:INFO:Copying training dataset
2024-07-16 12:33:52,268:INFO:Defining folds
2024-07-16 12:33:52,268:INFO:Declaring metric variables
2024-07-16 12:33:52,270:INFO:Importing untrained model
2024-07-16 12:33:52,272:INFO:Decision Tree Classifier Imported successfully
2024-07-16 12:33:52,275:INFO:Starting cross validation
2024-07-16 12:33:52,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:33:54,216:INFO:Calculating mean and std
2024-07-16 12:33:54,216:INFO:Creating metrics dataframe
2024-07-16 12:33:54,454:INFO:Uploading results into container
2024-07-16 12:33:54,454:INFO:Uploading model into container now
2024-07-16 12:33:54,455:INFO:_master_model_container: 4
2024-07-16 12:33:54,455:INFO:_display_container: 2
2024-07-16 12:33:54,455:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6087, splitter='best')
2024-07-16 12:33:54,455:INFO:create_model() successfully completed......................................
2024-07-16 12:33:54,524:INFO:SubProcess create_model() end ==================================
2024-07-16 12:33:54,525:INFO:Creating metrics dataframe
2024-07-16 12:33:54,529:INFO:Initializing SVM - Linear Kernel
2024-07-16 12:33:54,529:INFO:Total runtime is 0.23886036078135175 minutes
2024-07-16 12:33:54,532:INFO:SubProcess create_model() called ==================================
2024-07-16 12:33:54,532:INFO:Initializing create_model()
2024-07-16 12:33:54,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:33:54,532:INFO:Checking exceptions
2024-07-16 12:33:54,532:INFO:Importing libraries
2024-07-16 12:33:54,532:INFO:Copying training dataset
2024-07-16 12:33:54,534:INFO:Defining folds
2024-07-16 12:33:54,534:INFO:Declaring metric variables
2024-07-16 12:33:54,536:INFO:Importing untrained model
2024-07-16 12:33:54,538:INFO:SVM - Linear Kernel Imported successfully
2024-07-16 12:33:54,542:INFO:Starting cross validation
2024-07-16 12:33:54,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:33:54,577:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:54,579:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:54,580:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:54,582:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:54,583:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:54,585:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:54,585:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:54,587:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:54,588:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:54,590:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,284:INFO:Calculating mean and std
2024-07-16 12:33:56,284:INFO:Creating metrics dataframe
2024-07-16 12:33:56,530:INFO:Uploading results into container
2024-07-16 12:33:56,532:INFO:Uploading model into container now
2024-07-16 12:33:56,532:INFO:_master_model_container: 5
2024-07-16 12:33:56,532:INFO:_display_container: 2
2024-07-16 12:33:56,532:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6087, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-16 12:33:56,533:INFO:create_model() successfully completed......................................
2024-07-16 12:33:56,600:INFO:SubProcess create_model() end ==================================
2024-07-16 12:33:56,600:INFO:Creating metrics dataframe
2024-07-16 12:33:56,606:INFO:Initializing Ridge Classifier
2024-07-16 12:33:56,606:INFO:Total runtime is 0.2734668493270874 minutes
2024-07-16 12:33:56,608:INFO:SubProcess create_model() called ==================================
2024-07-16 12:33:56,608:INFO:Initializing create_model()
2024-07-16 12:33:56,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:33:56,608:INFO:Checking exceptions
2024-07-16 12:33:56,608:INFO:Importing libraries
2024-07-16 12:33:56,608:INFO:Copying training dataset
2024-07-16 12:33:56,610:INFO:Defining folds
2024-07-16 12:33:56,610:INFO:Declaring metric variables
2024-07-16 12:33:56,612:INFO:Importing untrained model
2024-07-16 12:33:56,613:INFO:Ridge Classifier Imported successfully
2024-07-16 12:33:56,617:INFO:Starting cross validation
2024-07-16 12:33:56,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:33:56,649:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,651:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,653:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,654:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,654:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,656:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,657:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,660:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,662:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:56,664:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:33:58,360:INFO:Calculating mean and std
2024-07-16 12:33:58,361:INFO:Creating metrics dataframe
2024-07-16 12:33:58,590:INFO:Uploading results into container
2024-07-16 12:33:58,591:INFO:Uploading model into container now
2024-07-16 12:33:58,591:INFO:_master_model_container: 6
2024-07-16 12:33:58,591:INFO:_display_container: 2
2024-07-16 12:33:58,592:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6087, solver='auto',
                tol=0.0001)
2024-07-16 12:33:58,592:INFO:create_model() successfully completed......................................
2024-07-16 12:33:58,659:INFO:SubProcess create_model() end ==================================
2024-07-16 12:33:58,659:INFO:Creating metrics dataframe
2024-07-16 12:33:58,664:INFO:Initializing Random Forest Classifier
2024-07-16 12:33:58,665:INFO:Total runtime is 0.3077847838401795 minutes
2024-07-16 12:33:58,667:INFO:SubProcess create_model() called ==================================
2024-07-16 12:33:58,667:INFO:Initializing create_model()
2024-07-16 12:33:58,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:33:58,667:INFO:Checking exceptions
2024-07-16 12:33:58,667:INFO:Importing libraries
2024-07-16 12:33:58,667:INFO:Copying training dataset
2024-07-16 12:33:58,669:INFO:Defining folds
2024-07-16 12:33:58,669:INFO:Declaring metric variables
2024-07-16 12:33:58,671:INFO:Importing untrained model
2024-07-16 12:33:58,672:INFO:Random Forest Classifier Imported successfully
2024-07-16 12:33:58,677:INFO:Starting cross validation
2024-07-16 12:33:58,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:00,753:INFO:Calculating mean and std
2024-07-16 12:34:00,754:INFO:Creating metrics dataframe
2024-07-16 12:34:00,998:INFO:Uploading results into container
2024-07-16 12:34:00,998:INFO:Uploading model into container now
2024-07-16 12:34:00,999:INFO:_master_model_container: 7
2024-07-16 12:34:00,999:INFO:_display_container: 2
2024-07-16 12:34:00,999:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6087, verbose=0, warm_start=False)
2024-07-16 12:34:00,999:INFO:create_model() successfully completed......................................
2024-07-16 12:34:01,068:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:01,068:INFO:Creating metrics dataframe
2024-07-16 12:34:01,073:INFO:Initializing Quadratic Discriminant Analysis
2024-07-16 12:34:01,073:INFO:Total runtime is 0.3479128956794739 minutes
2024-07-16 12:34:01,075:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:01,076:INFO:Initializing create_model()
2024-07-16 12:34:01,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:01,076:INFO:Checking exceptions
2024-07-16 12:34:01,076:INFO:Importing libraries
2024-07-16 12:34:01,076:INFO:Copying training dataset
2024-07-16 12:34:01,078:INFO:Defining folds
2024-07-16 12:34:01,078:INFO:Declaring metric variables
2024-07-16 12:34:01,080:INFO:Importing untrained model
2024-07-16 12:34:01,082:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-16 12:34:01,086:INFO:Starting cross validation
2024-07-16 12:34:01,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:02,864:INFO:Calculating mean and std
2024-07-16 12:34:02,865:INFO:Creating metrics dataframe
2024-07-16 12:34:03,109:INFO:Uploading results into container
2024-07-16 12:34:03,109:INFO:Uploading model into container now
2024-07-16 12:34:03,109:INFO:_master_model_container: 8
2024-07-16 12:34:03,109:INFO:_display_container: 2
2024-07-16 12:34:03,110:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-16 12:34:03,110:INFO:create_model() successfully completed......................................
2024-07-16 12:34:03,178:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:03,179:INFO:Creating metrics dataframe
2024-07-16 12:34:03,184:INFO:Initializing Ada Boost Classifier
2024-07-16 12:34:03,184:INFO:Total runtime is 0.38310857216517136 minutes
2024-07-16 12:34:03,186:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:03,186:INFO:Initializing create_model()
2024-07-16 12:34:03,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:03,187:INFO:Checking exceptions
2024-07-16 12:34:03,187:INFO:Importing libraries
2024-07-16 12:34:03,187:INFO:Copying training dataset
2024-07-16 12:34:03,188:INFO:Defining folds
2024-07-16 12:34:03,188:INFO:Declaring metric variables
2024-07-16 12:34:03,190:INFO:Importing untrained model
2024-07-16 12:34:03,192:INFO:Ada Boost Classifier Imported successfully
2024-07-16 12:34:03,196:INFO:Starting cross validation
2024-07-16 12:34:03,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:05,066:INFO:Calculating mean and std
2024-07-16 12:34:05,067:INFO:Creating metrics dataframe
2024-07-16 12:34:05,316:INFO:Uploading results into container
2024-07-16 12:34:05,316:INFO:Uploading model into container now
2024-07-16 12:34:05,317:INFO:_master_model_container: 9
2024-07-16 12:34:05,317:INFO:_display_container: 2
2024-07-16 12:34:05,317:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6087)
2024-07-16 12:34:05,317:INFO:create_model() successfully completed......................................
2024-07-16 12:34:05,384:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:05,384:INFO:Creating metrics dataframe
2024-07-16 12:34:05,390:INFO:Initializing Gradient Boosting Classifier
2024-07-16 12:34:05,390:INFO:Total runtime is 0.4198755105336508 minutes
2024-07-16 12:34:05,392:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:05,393:INFO:Initializing create_model()
2024-07-16 12:34:05,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:05,393:INFO:Checking exceptions
2024-07-16 12:34:05,393:INFO:Importing libraries
2024-07-16 12:34:05,393:INFO:Copying training dataset
2024-07-16 12:34:05,395:INFO:Defining folds
2024-07-16 12:34:05,395:INFO:Declaring metric variables
2024-07-16 12:34:05,396:INFO:Importing untrained model
2024-07-16 12:34:05,398:INFO:Gradient Boosting Classifier Imported successfully
2024-07-16 12:34:05,402:INFO:Starting cross validation
2024-07-16 12:34:05,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:07,300:INFO:Calculating mean and std
2024-07-16 12:34:07,301:INFO:Creating metrics dataframe
2024-07-16 12:34:07,539:INFO:Uploading results into container
2024-07-16 12:34:07,540:INFO:Uploading model into container now
2024-07-16 12:34:07,540:INFO:_master_model_container: 10
2024-07-16 12:34:07,540:INFO:_display_container: 2
2024-07-16 12:34:07,541:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6087, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-16 12:34:07,541:INFO:create_model() successfully completed......................................
2024-07-16 12:34:07,604:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:07,605:INFO:Creating metrics dataframe
2024-07-16 12:34:07,610:INFO:Initializing Linear Discriminant Analysis
2024-07-16 12:34:07,610:INFO:Total runtime is 0.4568725029627483 minutes
2024-07-16 12:34:07,613:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:07,613:INFO:Initializing create_model()
2024-07-16 12:34:07,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:07,614:INFO:Checking exceptions
2024-07-16 12:34:07,614:INFO:Importing libraries
2024-07-16 12:34:07,614:INFO:Copying training dataset
2024-07-16 12:34:07,615:INFO:Defining folds
2024-07-16 12:34:07,615:INFO:Declaring metric variables
2024-07-16 12:34:07,617:INFO:Importing untrained model
2024-07-16 12:34:07,619:INFO:Linear Discriminant Analysis Imported successfully
2024-07-16 12:34:07,622:INFO:Starting cross validation
2024-07-16 12:34:07,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:09,431:INFO:Calculating mean and std
2024-07-16 12:34:09,432:INFO:Creating metrics dataframe
2024-07-16 12:34:09,672:INFO:Uploading results into container
2024-07-16 12:34:09,673:INFO:Uploading model into container now
2024-07-16 12:34:09,673:INFO:_master_model_container: 11
2024-07-16 12:34:09,673:INFO:_display_container: 2
2024-07-16 12:34:09,674:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-16 12:34:09,674:INFO:create_model() successfully completed......................................
2024-07-16 12:34:09,744:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:09,744:INFO:Creating metrics dataframe
2024-07-16 12:34:09,749:INFO:Initializing Extra Trees Classifier
2024-07-16 12:34:09,749:INFO:Total runtime is 0.4925139983495077 minutes
2024-07-16 12:34:09,752:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:09,752:INFO:Initializing create_model()
2024-07-16 12:34:09,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:09,752:INFO:Checking exceptions
2024-07-16 12:34:09,752:INFO:Importing libraries
2024-07-16 12:34:09,752:INFO:Copying training dataset
2024-07-16 12:34:09,753:INFO:Defining folds
2024-07-16 12:34:09,753:INFO:Declaring metric variables
2024-07-16 12:34:09,755:INFO:Importing untrained model
2024-07-16 12:34:09,757:INFO:Extra Trees Classifier Imported successfully
2024-07-16 12:34:09,760:INFO:Starting cross validation
2024-07-16 12:34:09,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:11,778:INFO:Calculating mean and std
2024-07-16 12:34:11,778:INFO:Creating metrics dataframe
2024-07-16 12:34:12,014:INFO:Uploading results into container
2024-07-16 12:34:12,014:INFO:Uploading model into container now
2024-07-16 12:34:12,014:INFO:_master_model_container: 12
2024-07-16 12:34:12,015:INFO:_display_container: 2
2024-07-16 12:34:12,015:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6087, verbose=0, warm_start=False)
2024-07-16 12:34:12,015:INFO:create_model() successfully completed......................................
2024-07-16 12:34:12,083:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:12,083:INFO:Creating metrics dataframe
2024-07-16 12:34:12,089:INFO:Initializing Extreme Gradient Boosting
2024-07-16 12:34:12,089:INFO:Total runtime is 0.5315253059069316 minutes
2024-07-16 12:34:12,090:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:12,090:INFO:Initializing create_model()
2024-07-16 12:34:12,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:12,090:INFO:Checking exceptions
2024-07-16 12:34:12,092:INFO:Importing libraries
2024-07-16 12:34:12,092:INFO:Copying training dataset
2024-07-16 12:34:12,093:INFO:Defining folds
2024-07-16 12:34:12,093:INFO:Declaring metric variables
2024-07-16 12:34:12,095:INFO:Importing untrained model
2024-07-16 12:34:12,097:INFO:Extreme Gradient Boosting Imported successfully
2024-07-16 12:34:12,101:INFO:Starting cross validation
2024-07-16 12:34:12,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:14,019:INFO:Calculating mean and std
2024-07-16 12:34:14,019:INFO:Creating metrics dataframe
2024-07-16 12:34:14,260:INFO:Uploading results into container
2024-07-16 12:34:14,261:INFO:Uploading model into container now
2024-07-16 12:34:14,261:INFO:_master_model_container: 13
2024-07-16 12:34:14,262:INFO:_display_container: 2
2024-07-16 12:34:14,262:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-16 12:34:14,262:INFO:create_model() successfully completed......................................
2024-07-16 12:34:14,326:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:14,326:INFO:Creating metrics dataframe
2024-07-16 12:34:14,333:INFO:Initializing Light Gradient Boosting Machine
2024-07-16 12:34:14,333:INFO:Total runtime is 0.5689125617345174 minutes
2024-07-16 12:34:14,335:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:14,336:INFO:Initializing create_model()
2024-07-16 12:34:14,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:14,336:INFO:Checking exceptions
2024-07-16 12:34:14,336:INFO:Importing libraries
2024-07-16 12:34:14,336:INFO:Copying training dataset
2024-07-16 12:34:14,337:INFO:Defining folds
2024-07-16 12:34:14,337:INFO:Declaring metric variables
2024-07-16 12:34:14,339:INFO:Importing untrained model
2024-07-16 12:34:14,341:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-16 12:34:14,344:INFO:Starting cross validation
2024-07-16 12:34:14,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:16,587:INFO:Calculating mean and std
2024-07-16 12:34:16,588:INFO:Creating metrics dataframe
2024-07-16 12:34:16,833:INFO:Uploading results into container
2024-07-16 12:34:16,833:INFO:Uploading model into container now
2024-07-16 12:34:16,833:INFO:_master_model_container: 14
2024-07-16 12:34:16,833:INFO:_display_container: 2
2024-07-16 12:34:16,834:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6087, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-16 12:34:16,834:INFO:create_model() successfully completed......................................
2024-07-16 12:34:16,898:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:16,898:INFO:Creating metrics dataframe
2024-07-16 12:34:16,904:INFO:Initializing CatBoost Classifier
2024-07-16 12:34:16,904:INFO:Total runtime is 0.6117788394292196 minutes
2024-07-16 12:34:16,906:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:16,906:INFO:Initializing create_model()
2024-07-16 12:34:16,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022D50E11250>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:16,907:INFO:Checking exceptions
2024-07-16 12:34:16,907:INFO:Importing libraries
2024-07-16 12:34:16,907:INFO:Copying training dataset
2024-07-16 12:34:16,908:INFO:Defining folds
2024-07-16 12:34:16,908:INFO:Declaring metric variables
2024-07-16 12:34:16,910:INFO:Importing untrained model
2024-07-16 12:34:16,913:INFO:CatBoost Classifier Imported successfully
2024-07-16 12:34:16,917:INFO:Starting cross validation
2024-07-16 12:34:16,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:20,895:INFO:Calculating mean and std
2024-07-16 12:34:20,896:INFO:Creating metrics dataframe
2024-07-16 12:34:21,159:INFO:Uploading results into container
2024-07-16 12:34:21,159:INFO:Uploading model into container now
2024-07-16 12:34:21,159:INFO:_master_model_container: 15
2024-07-16 12:34:21,159:INFO:_display_container: 2
2024-07-16 12:34:21,159:INFO:<catboost.core.CatBoostClassifier object at 0x0000022D49EF1350>
2024-07-16 12:34:21,160:INFO:create_model() successfully completed......................................
2024-07-16 12:34:21,226:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:21,226:INFO:Creating metrics dataframe
2024-07-16 12:34:21,233:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-16 12:34:21,237:INFO:Initializing create_model()
2024-07-16 12:34:21,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D4A2B3350>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6087), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:21,237:INFO:Checking exceptions
2024-07-16 12:34:21,238:INFO:Importing libraries
2024-07-16 12:34:21,238:INFO:Copying training dataset
2024-07-16 12:34:21,240:INFO:Defining folds
2024-07-16 12:34:21,240:INFO:Declaring metric variables
2024-07-16 12:34:21,240:INFO:Importing untrained model
2024-07-16 12:34:21,240:INFO:Declaring custom model
2024-07-16 12:34:21,240:INFO:str Imported successfully
2024-07-16 12:34:21,240:INFO:Cross validation set to False
2024-07-16 12:34:21,240:INFO:Fitting Model
2024-07-16 12:34:21,507:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6087)
2024-07-16 12:34:21,507:INFO:create_model() successfully completed......................................
2024-07-16 12:34:21,612:INFO:_master_model_container: 15
2024-07-16 12:34:21,612:INFO:_display_container: 2
2024-07-16 12:34:21,612:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6087)
2024-07-16 12:34:21,613:INFO:compare_models() successfully completed......................................
2024-07-16 12:34:21,650:WARNING:C:\Users\JAL\AppData\Local\Temp\ipykernel_29900\796603356.py:82: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  best_model[best_model.select_dtypes(include=['number']).columns] *= 100

2024-07-16 12:34:22,068:INFO:PyCaret ClassificationExperiment
2024-07-16 12:34:22,068:INFO:Logging name: clf-default-name
2024-07-16 12:34:22,068:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-16 12:34:22,068:INFO:version 3.0.0
2024-07-16 12:34:22,068:INFO:Initializing setup()
2024-07-16 12:34:22,068:INFO:self.USI: 9eb9
2024-07-16 12:34:22,068:INFO:self._variable_keys: {'y_test', 'y', 'fold_shuffle_param', 'y_train', 'log_plots_param', 'html_param', 'data', 'exp_name_log', 'logging_param', 'gpu_n_jobs_param', 'X_test', 'idx', 'exp_id', 'fold_generator', 'X', 'is_multiclass', 'seed', '_available_plots', 'fold_groups_param', 'gpu_param', 'X_train', '_ml_usecase', 'pipeline', 'n_jobs_param', 'fix_imbalance', 'memory', 'target_param', 'USI'}
2024-07-16 12:34:22,068:INFO:Checking environment
2024-07-16 12:34:22,068:INFO:python_version: 3.11.4
2024-07-16 12:34:22,068:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2024-07-16 12:34:22,068:INFO:machine: AMD64
2024-07-16 12:34:22,068:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-16 12:34:22,074:INFO:Memory: svmem(total=68659781632, available=45887901696, percent=33.2, used=22771879936, free=45887901696)
2024-07-16 12:34:22,074:INFO:Physical Core: 16
2024-07-16 12:34:22,074:INFO:Logical Core: 32
2024-07-16 12:34:22,074:INFO:Checking libraries
2024-07-16 12:34:22,074:INFO:System:
2024-07-16 12:34:22,074:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2024-07-16 12:34:22,074:INFO:executable: c:\Users\JAL\AppData\Local\Programs\Python\Python311\python.exe
2024-07-16 12:34:22,074:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-16 12:34:22,074:INFO:PyCaret required dependencies:
2024-07-16 12:34:22,074:INFO:                 pip: 24.1.2
2024-07-16 12:34:22,074:INFO:          setuptools: 70.3.0
2024-07-16 12:34:22,074:INFO:             pycaret: 3.0.0
2024-07-16 12:34:22,074:INFO:             IPython: 8.15.0
2024-07-16 12:34:22,074:INFO:          ipywidgets: 8.1.3
2024-07-16 12:34:22,074:INFO:                tqdm: 4.66.4
2024-07-16 12:34:22,074:INFO:               numpy: 1.24.4
2024-07-16 12:34:22,074:INFO:              pandas: 2.2.2
2024-07-16 12:34:22,074:INFO:              jinja2: 3.1.4
2024-07-16 12:34:22,074:INFO:               scipy: 1.11.4
2024-07-16 12:34:22,074:INFO:              joblib: 1.3.2
2024-07-16 12:34:22,074:INFO:             sklearn: 1.3.0
2024-07-16 12:34:22,074:INFO:                pyod: 2.0.1
2024-07-16 12:34:22,074:INFO:            imblearn: 0.12.3
2024-07-16 12:34:22,074:INFO:   category_encoders: 2.6.3
2024-07-16 12:34:22,074:INFO:            lightgbm: 4.3.0
2024-07-16 12:34:22,074:INFO:               numba: 0.60.0
2024-07-16 12:34:22,074:INFO:            requests: 2.32.3
2024-07-16 12:34:22,074:INFO:          matplotlib: 3.7.5
2024-07-16 12:34:22,074:INFO:          scikitplot: 0.3.7
2024-07-16 12:34:22,074:INFO:         yellowbrick: 1.5
2024-07-16 12:34:22,074:INFO:              plotly: 5.22.0
2024-07-16 12:34:22,074:INFO:             kaleido: 0.2.1
2024-07-16 12:34:22,074:INFO:         statsmodels: 0.14.2
2024-07-16 12:34:22,075:INFO:              sktime: 0.26.0
2024-07-16 12:34:22,075:INFO:               tbats: 1.1.3
2024-07-16 12:34:22,075:INFO:            pmdarima: 2.0.4
2024-07-16 12:34:22,075:INFO:              psutil: 5.9.5
2024-07-16 12:34:22,075:INFO:PyCaret optional dependencies:
2024-07-16 12:34:22,075:INFO:                shap: Not installed
2024-07-16 12:34:22,075:INFO:           interpret: Not installed
2024-07-16 12:34:22,075:INFO:                umap: Not installed
2024-07-16 12:34:22,075:INFO:    pandas_profiling: Not installed
2024-07-16 12:34:22,075:INFO:  explainerdashboard: Not installed
2024-07-16 12:34:22,075:INFO:             autoviz: Not installed
2024-07-16 12:34:22,075:INFO:           fairlearn: Not installed
2024-07-16 12:34:22,075:INFO:             xgboost: 2.0.3
2024-07-16 12:34:22,075:INFO:            catboost: 1.2.5
2024-07-16 12:34:22,075:INFO:              kmodes: Not installed
2024-07-16 12:34:22,075:INFO:             mlxtend: Not installed
2024-07-16 12:34:22,075:INFO:       statsforecast: 1.4.0
2024-07-16 12:34:22,075:INFO:        tune_sklearn: Not installed
2024-07-16 12:34:22,075:INFO:                 ray: 2.10.0
2024-07-16 12:34:22,075:INFO:            hyperopt: 0.2.7
2024-07-16 12:34:22,075:INFO:              optuna: Not installed
2024-07-16 12:34:22,075:INFO:               skopt: Not installed
2024-07-16 12:34:22,075:INFO:              mlflow: Not installed
2024-07-16 12:34:22,075:INFO:              gradio: Not installed
2024-07-16 12:34:22,075:INFO:             fastapi: Not installed
2024-07-16 12:34:22,075:INFO:             uvicorn: Not installed
2024-07-16 12:34:22,075:INFO:              m2cgen: Not installed
2024-07-16 12:34:22,075:INFO:           evidently: Not installed
2024-07-16 12:34:22,075:INFO:               fugue: Not installed
2024-07-16 12:34:22,075:INFO:           streamlit: 1.31.0
2024-07-16 12:34:22,075:INFO:             prophet: Not installed
2024-07-16 12:34:22,075:INFO:None
2024-07-16 12:34:22,075:INFO:Set up data.
2024-07-16 12:34:22,077:INFO:Set up train/test split.
2024-07-16 12:34:22,079:INFO:Set up index.
2024-07-16 12:34:22,079:INFO:Set up folding strategy.
2024-07-16 12:34:22,079:INFO:Assigning column types.
2024-07-16 12:34:22,080:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-16 12:34:22,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:34:22,112:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:34:22,130:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:34:22,133:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:34:22,164:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-16 12:34:22,165:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:34:22,183:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:34:22,185:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:34:22,185:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-16 12:34:22,217:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:34:22,236:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:34:22,238:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:34:22,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-16 12:34:22,288:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:34:22,289:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:34:22,289:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-16 12:34:22,342:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:34:22,344:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:34:22,396:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:34:22,398:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:34:22,398:INFO:Preparing preprocessing pipeline...
2024-07-16 12:34:22,399:INFO:Set up simple imputation.
2024-07-16 12:34:22,408:INFO:Finished creating preprocessing pipeline.
2024-07-16 12:34:22,410:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-16 12:34:22,410:INFO:Creating final display dataframe.
2024-07-16 12:34:22,438:INFO:Setup _display_container:                     Description             Value
0                    Session id              8129
1                        Target       PlacedOrNot
2                   Target type            Binary
3           Original data shape         (2966, 3)
4        Transformed data shape         (2966, 3)
5   Transformed train set shape         (2076, 3)
6    Transformed test set shape          (890, 3)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9eb9
2024-07-16 12:34:22,492:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:34:22,493:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:34:22,544:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-16 12:34:22,545:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-16 12:34:22,546:INFO:setup() successfully completed in 0.68s...............
2024-07-16 12:34:22,546:INFO:Initializing compare_models()
2024-07-16 12:34:22,546:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-16 12:34:22,546:INFO:Checking exceptions
2024-07-16 12:34:22,548:INFO:Preparing display monitor
2024-07-16 12:34:22,560:INFO:Initializing Logistic Regression
2024-07-16 12:34:22,560:INFO:Total runtime is 0.0 minutes
2024-07-16 12:34:22,562:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:22,562:INFO:Initializing create_model()
2024-07-16 12:34:22,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:22,563:INFO:Checking exceptions
2024-07-16 12:34:22,563:INFO:Importing libraries
2024-07-16 12:34:22,563:INFO:Copying training dataset
2024-07-16 12:34:22,565:INFO:Defining folds
2024-07-16 12:34:22,565:INFO:Declaring metric variables
2024-07-16 12:34:22,568:INFO:Importing untrained model
2024-07-16 12:34:22,571:INFO:Logistic Regression Imported successfully
2024-07-16 12:34:22,575:INFO:Starting cross validation
2024-07-16 12:34:22,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:24,486:INFO:Calculating mean and std
2024-07-16 12:34:24,487:INFO:Creating metrics dataframe
2024-07-16 12:34:24,743:INFO:Uploading results into container
2024-07-16 12:34:24,744:INFO:Uploading model into container now
2024-07-16 12:34:24,744:INFO:_master_model_container: 1
2024-07-16 12:34:24,744:INFO:_display_container: 2
2024-07-16 12:34:24,744:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8129, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-16 12:34:24,744:INFO:create_model() successfully completed......................................
2024-07-16 12:34:24,810:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:24,810:INFO:Creating metrics dataframe
2024-07-16 12:34:24,815:INFO:Initializing K Neighbors Classifier
2024-07-16 12:34:24,815:INFO:Total runtime is 0.03758629560470581 minutes
2024-07-16 12:34:24,817:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:24,817:INFO:Initializing create_model()
2024-07-16 12:34:24,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:24,817:INFO:Checking exceptions
2024-07-16 12:34:24,817:INFO:Importing libraries
2024-07-16 12:34:24,817:INFO:Copying training dataset
2024-07-16 12:34:24,819:INFO:Defining folds
2024-07-16 12:34:24,819:INFO:Declaring metric variables
2024-07-16 12:34:24,820:INFO:Importing untrained model
2024-07-16 12:34:24,823:INFO:K Neighbors Classifier Imported successfully
2024-07-16 12:34:24,827:INFO:Starting cross validation
2024-07-16 12:34:24,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:26,742:INFO:Calculating mean and std
2024-07-16 12:34:26,743:INFO:Creating metrics dataframe
2024-07-16 12:34:26,998:INFO:Uploading results into container
2024-07-16 12:34:26,999:INFO:Uploading model into container now
2024-07-16 12:34:26,999:INFO:_master_model_container: 2
2024-07-16 12:34:26,999:INFO:_display_container: 2
2024-07-16 12:34:26,999:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-16 12:34:26,999:INFO:create_model() successfully completed......................................
2024-07-16 12:34:27,064:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:27,064:INFO:Creating metrics dataframe
2024-07-16 12:34:27,068:INFO:Initializing Naive Bayes
2024-07-16 12:34:27,068:INFO:Total runtime is 0.07513990004857382 minutes
2024-07-16 12:34:27,070:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:27,070:INFO:Initializing create_model()
2024-07-16 12:34:27,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:27,071:INFO:Checking exceptions
2024-07-16 12:34:27,071:INFO:Importing libraries
2024-07-16 12:34:27,071:INFO:Copying training dataset
2024-07-16 12:34:27,073:INFO:Defining folds
2024-07-16 12:34:27,073:INFO:Declaring metric variables
2024-07-16 12:34:27,075:INFO:Importing untrained model
2024-07-16 12:34:27,076:INFO:Naive Bayes Imported successfully
2024-07-16 12:34:27,080:INFO:Starting cross validation
2024-07-16 12:34:27,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:28,950:INFO:Calculating mean and std
2024-07-16 12:34:28,950:INFO:Creating metrics dataframe
2024-07-16 12:34:29,205:INFO:Uploading results into container
2024-07-16 12:34:29,206:INFO:Uploading model into container now
2024-07-16 12:34:29,206:INFO:_master_model_container: 3
2024-07-16 12:34:29,206:INFO:_display_container: 2
2024-07-16 12:34:29,206:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-16 12:34:29,206:INFO:create_model() successfully completed......................................
2024-07-16 12:34:29,281:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:29,281:INFO:Creating metrics dataframe
2024-07-16 12:34:29,286:INFO:Initializing Decision Tree Classifier
2024-07-16 12:34:29,286:INFO:Total runtime is 0.11209620634714763 minutes
2024-07-16 12:34:29,287:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:29,288:INFO:Initializing create_model()
2024-07-16 12:34:29,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:29,288:INFO:Checking exceptions
2024-07-16 12:34:29,288:INFO:Importing libraries
2024-07-16 12:34:29,288:INFO:Copying training dataset
2024-07-16 12:34:29,290:INFO:Defining folds
2024-07-16 12:34:29,290:INFO:Declaring metric variables
2024-07-16 12:34:29,291:INFO:Importing untrained model
2024-07-16 12:34:29,294:INFO:Decision Tree Classifier Imported successfully
2024-07-16 12:34:29,297:INFO:Starting cross validation
2024-07-16 12:34:29,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:31,158:INFO:Calculating mean and std
2024-07-16 12:34:31,159:INFO:Creating metrics dataframe
2024-07-16 12:34:31,426:INFO:Uploading results into container
2024-07-16 12:34:31,427:INFO:Uploading model into container now
2024-07-16 12:34:31,427:INFO:_master_model_container: 4
2024-07-16 12:34:31,427:INFO:_display_container: 2
2024-07-16 12:34:31,427:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8129, splitter='best')
2024-07-16 12:34:31,427:INFO:create_model() successfully completed......................................
2024-07-16 12:34:31,492:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:31,492:INFO:Creating metrics dataframe
2024-07-16 12:34:31,498:INFO:Initializing SVM - Linear Kernel
2024-07-16 12:34:31,498:INFO:Total runtime is 0.14895900090535483 minutes
2024-07-16 12:34:31,499:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:31,500:INFO:Initializing create_model()
2024-07-16 12:34:31,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:31,500:INFO:Checking exceptions
2024-07-16 12:34:31,500:INFO:Importing libraries
2024-07-16 12:34:31,500:INFO:Copying training dataset
2024-07-16 12:34:31,502:INFO:Defining folds
2024-07-16 12:34:31,502:INFO:Declaring metric variables
2024-07-16 12:34:31,504:INFO:Importing untrained model
2024-07-16 12:34:31,506:INFO:SVM - Linear Kernel Imported successfully
2024-07-16 12:34:31,510:INFO:Starting cross validation
2024-07-16 12:34:31,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:31,545:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:31,545:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:31,548:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:31,549:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:31,551:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:31,553:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:31,553:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:31,555:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:31,558:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:31,559:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,351:INFO:Calculating mean and std
2024-07-16 12:34:33,352:INFO:Creating metrics dataframe
2024-07-16 12:34:33,604:INFO:Uploading results into container
2024-07-16 12:34:33,605:INFO:Uploading model into container now
2024-07-16 12:34:33,605:INFO:_master_model_container: 5
2024-07-16 12:34:33,605:INFO:_display_container: 2
2024-07-16 12:34:33,605:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8129, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-16 12:34:33,605:INFO:create_model() successfully completed......................................
2024-07-16 12:34:33,674:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:33,674:INFO:Creating metrics dataframe
2024-07-16 12:34:33,679:INFO:Initializing Ridge Classifier
2024-07-16 12:34:33,679:INFO:Total runtime is 0.18530866305033367 minutes
2024-07-16 12:34:33,681:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:33,681:INFO:Initializing create_model()
2024-07-16 12:34:33,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:33,682:INFO:Checking exceptions
2024-07-16 12:34:33,682:INFO:Importing libraries
2024-07-16 12:34:33,682:INFO:Copying training dataset
2024-07-16 12:34:33,683:INFO:Defining folds
2024-07-16 12:34:33,683:INFO:Declaring metric variables
2024-07-16 12:34:33,685:INFO:Importing untrained model
2024-07-16 12:34:33,687:INFO:Ridge Classifier Imported successfully
2024-07-16 12:34:33,691:INFO:Starting cross validation
2024-07-16 12:34:33,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:33,721:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,721:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,724:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,725:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,726:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,732:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,733:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,734:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,736:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:33,736:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-16 12:34:35,520:INFO:Calculating mean and std
2024-07-16 12:34:35,520:INFO:Creating metrics dataframe
2024-07-16 12:34:35,775:INFO:Uploading results into container
2024-07-16 12:34:35,775:INFO:Uploading model into container now
2024-07-16 12:34:35,775:INFO:_master_model_container: 6
2024-07-16 12:34:35,775:INFO:_display_container: 2
2024-07-16 12:34:35,776:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8129, solver='auto',
                tol=0.0001)
2024-07-16 12:34:35,776:INFO:create_model() successfully completed......................................
2024-07-16 12:34:35,845:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:35,845:INFO:Creating metrics dataframe
2024-07-16 12:34:35,850:INFO:Initializing Random Forest Classifier
2024-07-16 12:34:35,850:INFO:Total runtime is 0.22149109840393066 minutes
2024-07-16 12:34:35,852:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:35,852:INFO:Initializing create_model()
2024-07-16 12:34:35,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:35,852:INFO:Checking exceptions
2024-07-16 12:34:35,852:INFO:Importing libraries
2024-07-16 12:34:35,852:INFO:Copying training dataset
2024-07-16 12:34:35,855:INFO:Defining folds
2024-07-16 12:34:35,855:INFO:Declaring metric variables
2024-07-16 12:34:35,857:INFO:Importing untrained model
2024-07-16 12:34:35,859:INFO:Random Forest Classifier Imported successfully
2024-07-16 12:34:35,863:INFO:Starting cross validation
2024-07-16 12:34:35,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:38,026:INFO:Calculating mean and std
2024-07-16 12:34:38,028:INFO:Creating metrics dataframe
2024-07-16 12:34:38,277:INFO:Uploading results into container
2024-07-16 12:34:38,277:INFO:Uploading model into container now
2024-07-16 12:34:38,277:INFO:_master_model_container: 7
2024-07-16 12:34:38,277:INFO:_display_container: 2
2024-07-16 12:34:38,278:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8129, verbose=0, warm_start=False)
2024-07-16 12:34:38,278:INFO:create_model() successfully completed......................................
2024-07-16 12:34:38,346:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:38,346:INFO:Creating metrics dataframe
2024-07-16 12:34:38,352:INFO:Initializing Quadratic Discriminant Analysis
2024-07-16 12:34:38,352:INFO:Total runtime is 0.2631911595662435 minutes
2024-07-16 12:34:38,354:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:38,354:INFO:Initializing create_model()
2024-07-16 12:34:38,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:38,354:INFO:Checking exceptions
2024-07-16 12:34:38,355:INFO:Importing libraries
2024-07-16 12:34:38,355:INFO:Copying training dataset
2024-07-16 12:34:38,356:INFO:Defining folds
2024-07-16 12:34:38,356:INFO:Declaring metric variables
2024-07-16 12:34:38,358:INFO:Importing untrained model
2024-07-16 12:34:38,360:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-16 12:34:38,363:INFO:Starting cross validation
2024-07-16 12:34:38,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:40,225:INFO:Calculating mean and std
2024-07-16 12:34:40,226:INFO:Creating metrics dataframe
2024-07-16 12:34:40,489:INFO:Uploading results into container
2024-07-16 12:34:40,490:INFO:Uploading model into container now
2024-07-16 12:34:40,490:INFO:_master_model_container: 8
2024-07-16 12:34:40,490:INFO:_display_container: 2
2024-07-16 12:34:40,491:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-16 12:34:40,491:INFO:create_model() successfully completed......................................
2024-07-16 12:34:40,565:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:40,565:INFO:Creating metrics dataframe
2024-07-16 12:34:40,571:INFO:Initializing Ada Boost Classifier
2024-07-16 12:34:40,571:INFO:Total runtime is 0.3001894553502401 minutes
2024-07-16 12:34:40,573:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:40,573:INFO:Initializing create_model()
2024-07-16 12:34:40,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:40,573:INFO:Checking exceptions
2024-07-16 12:34:40,574:INFO:Importing libraries
2024-07-16 12:34:40,574:INFO:Copying training dataset
2024-07-16 12:34:40,575:INFO:Defining folds
2024-07-16 12:34:40,575:INFO:Declaring metric variables
2024-07-16 12:34:40,577:INFO:Importing untrained model
2024-07-16 12:34:40,579:INFO:Ada Boost Classifier Imported successfully
2024-07-16 12:34:40,582:INFO:Starting cross validation
2024-07-16 12:34:40,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:42,520:INFO:Calculating mean and std
2024-07-16 12:34:42,520:INFO:Creating metrics dataframe
2024-07-16 12:34:42,787:INFO:Uploading results into container
2024-07-16 12:34:42,788:INFO:Uploading model into container now
2024-07-16 12:34:42,788:INFO:_master_model_container: 9
2024-07-16 12:34:42,788:INFO:_display_container: 2
2024-07-16 12:34:42,788:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8129)
2024-07-16 12:34:42,788:INFO:create_model() successfully completed......................................
2024-07-16 12:34:42,857:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:42,857:INFO:Creating metrics dataframe
2024-07-16 12:34:42,863:INFO:Initializing Gradient Boosting Classifier
2024-07-16 12:34:42,863:INFO:Total runtime is 0.338386082649231 minutes
2024-07-16 12:34:42,864:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:42,865:INFO:Initializing create_model()
2024-07-16 12:34:42,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:42,865:INFO:Checking exceptions
2024-07-16 12:34:42,865:INFO:Importing libraries
2024-07-16 12:34:42,865:INFO:Copying training dataset
2024-07-16 12:34:42,866:INFO:Defining folds
2024-07-16 12:34:42,867:INFO:Declaring metric variables
2024-07-16 12:34:42,868:INFO:Importing untrained model
2024-07-16 12:34:42,870:INFO:Gradient Boosting Classifier Imported successfully
2024-07-16 12:34:42,873:INFO:Starting cross validation
2024-07-16 12:34:42,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:44,805:INFO:Calculating mean and std
2024-07-16 12:34:44,805:INFO:Creating metrics dataframe
2024-07-16 12:34:45,076:INFO:Uploading results into container
2024-07-16 12:34:45,077:INFO:Uploading model into container now
2024-07-16 12:34:45,077:INFO:_master_model_container: 10
2024-07-16 12:34:45,077:INFO:_display_container: 2
2024-07-16 12:34:45,078:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8129, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-16 12:34:45,078:INFO:create_model() successfully completed......................................
2024-07-16 12:34:45,144:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:45,144:INFO:Creating metrics dataframe
2024-07-16 12:34:45,149:INFO:Initializing Linear Discriminant Analysis
2024-07-16 12:34:45,150:INFO:Total runtime is 0.37649497588475545 minutes
2024-07-16 12:34:45,151:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:45,152:INFO:Initializing create_model()
2024-07-16 12:34:45,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:45,152:INFO:Checking exceptions
2024-07-16 12:34:45,152:INFO:Importing libraries
2024-07-16 12:34:45,152:INFO:Copying training dataset
2024-07-16 12:34:45,153:INFO:Defining folds
2024-07-16 12:34:45,154:INFO:Declaring metric variables
2024-07-16 12:34:45,155:INFO:Importing untrained model
2024-07-16 12:34:45,158:INFO:Linear Discriminant Analysis Imported successfully
2024-07-16 12:34:45,162:INFO:Starting cross validation
2024-07-16 12:34:45,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:47,008:INFO:Calculating mean and std
2024-07-16 12:34:47,009:INFO:Creating metrics dataframe
2024-07-16 12:34:47,263:INFO:Uploading results into container
2024-07-16 12:34:47,264:INFO:Uploading model into container now
2024-07-16 12:34:47,264:INFO:_master_model_container: 11
2024-07-16 12:34:47,264:INFO:_display_container: 2
2024-07-16 12:34:47,265:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-16 12:34:47,265:INFO:create_model() successfully completed......................................
2024-07-16 12:34:47,330:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:47,330:INFO:Creating metrics dataframe
2024-07-16 12:34:47,336:INFO:Initializing Extra Trees Classifier
2024-07-16 12:34:47,336:INFO:Total runtime is 0.4129305124282837 minutes
2024-07-16 12:34:47,338:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:47,338:INFO:Initializing create_model()
2024-07-16 12:34:47,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:47,339:INFO:Checking exceptions
2024-07-16 12:34:47,339:INFO:Importing libraries
2024-07-16 12:34:47,339:INFO:Copying training dataset
2024-07-16 12:34:47,340:INFO:Defining folds
2024-07-16 12:34:47,340:INFO:Declaring metric variables
2024-07-16 12:34:47,342:INFO:Importing untrained model
2024-07-16 12:34:47,344:INFO:Extra Trees Classifier Imported successfully
2024-07-16 12:34:47,347:INFO:Starting cross validation
2024-07-16 12:34:47,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:49,444:INFO:Calculating mean and std
2024-07-16 12:34:49,445:INFO:Creating metrics dataframe
2024-07-16 12:34:49,700:INFO:Uploading results into container
2024-07-16 12:34:49,701:INFO:Uploading model into container now
2024-07-16 12:34:49,701:INFO:_master_model_container: 12
2024-07-16 12:34:49,701:INFO:_display_container: 2
2024-07-16 12:34:49,701:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8129, verbose=0, warm_start=False)
2024-07-16 12:34:49,701:INFO:create_model() successfully completed......................................
2024-07-16 12:34:49,769:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:49,769:INFO:Creating metrics dataframe
2024-07-16 12:34:49,776:INFO:Initializing Extreme Gradient Boosting
2024-07-16 12:34:49,777:INFO:Total runtime is 0.4536137461662293 minutes
2024-07-16 12:34:49,778:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:49,779:INFO:Initializing create_model()
2024-07-16 12:34:49,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:49,779:INFO:Checking exceptions
2024-07-16 12:34:49,779:INFO:Importing libraries
2024-07-16 12:34:49,779:INFO:Copying training dataset
2024-07-16 12:34:49,780:INFO:Defining folds
2024-07-16 12:34:49,781:INFO:Declaring metric variables
2024-07-16 12:34:49,782:INFO:Importing untrained model
2024-07-16 12:34:49,784:INFO:Extreme Gradient Boosting Imported successfully
2024-07-16 12:34:49,788:INFO:Starting cross validation
2024-07-16 12:34:49,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:51,684:INFO:Calculating mean and std
2024-07-16 12:34:51,685:INFO:Creating metrics dataframe
2024-07-16 12:34:51,937:INFO:Uploading results into container
2024-07-16 12:34:51,937:INFO:Uploading model into container now
2024-07-16 12:34:51,938:INFO:_master_model_container: 13
2024-07-16 12:34:51,938:INFO:_display_container: 2
2024-07-16 12:34:51,938:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-16 12:34:51,938:INFO:create_model() successfully completed......................................
2024-07-16 12:34:52,011:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:52,011:INFO:Creating metrics dataframe
2024-07-16 12:34:52,017:INFO:Initializing Light Gradient Boosting Machine
2024-07-16 12:34:52,017:INFO:Total runtime is 0.4909512003262838 minutes
2024-07-16 12:34:52,019:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:52,019:INFO:Initializing create_model()
2024-07-16 12:34:52,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:52,019:INFO:Checking exceptions
2024-07-16 12:34:52,019:INFO:Importing libraries
2024-07-16 12:34:52,019:INFO:Copying training dataset
2024-07-16 12:34:52,021:INFO:Defining folds
2024-07-16 12:34:52,021:INFO:Declaring metric variables
2024-07-16 12:34:52,023:INFO:Importing untrained model
2024-07-16 12:34:52,025:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-16 12:34:52,029:INFO:Starting cross validation
2024-07-16 12:34:52,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:54,449:INFO:Calculating mean and std
2024-07-16 12:34:54,450:INFO:Creating metrics dataframe
2024-07-16 12:34:54,716:INFO:Uploading results into container
2024-07-16 12:34:54,717:INFO:Uploading model into container now
2024-07-16 12:34:54,717:INFO:_master_model_container: 14
2024-07-16 12:34:54,717:INFO:_display_container: 2
2024-07-16 12:34:54,717:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8129, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-16 12:34:54,717:INFO:create_model() successfully completed......................................
2024-07-16 12:34:54,783:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:54,783:INFO:Creating metrics dataframe
2024-07-16 12:34:54,789:INFO:Initializing CatBoost Classifier
2024-07-16 12:34:54,789:INFO:Total runtime is 0.5371547182401022 minutes
2024-07-16 12:34:54,792:INFO:SubProcess create_model() called ==================================
2024-07-16 12:34:54,792:INFO:Initializing create_model()
2024-07-16 12:34:54,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022DA4E26090>, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:54,792:INFO:Checking exceptions
2024-07-16 12:34:54,792:INFO:Importing libraries
2024-07-16 12:34:54,792:INFO:Copying training dataset
2024-07-16 12:34:54,794:INFO:Defining folds
2024-07-16 12:34:54,794:INFO:Declaring metric variables
2024-07-16 12:34:54,796:INFO:Importing untrained model
2024-07-16 12:34:54,798:INFO:CatBoost Classifier Imported successfully
2024-07-16 12:34:54,801:INFO:Starting cross validation
2024-07-16 12:34:54,802:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-16 12:34:58,593:INFO:Calculating mean and std
2024-07-16 12:34:58,594:INFO:Creating metrics dataframe
2024-07-16 12:34:58,852:INFO:Uploading results into container
2024-07-16 12:34:58,853:INFO:Uploading model into container now
2024-07-16 12:34:58,853:INFO:_master_model_container: 15
2024-07-16 12:34:58,853:INFO:_display_container: 2
2024-07-16 12:34:58,853:INFO:<catboost.core.CatBoostClassifier object at 0x0000022DA4DED790>
2024-07-16 12:34:58,853:INFO:create_model() successfully completed......................................
2024-07-16 12:34:58,922:INFO:SubProcess create_model() end ==================================
2024-07-16 12:34:58,922:INFO:Creating metrics dataframe
2024-07-16 12:34:58,929:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-16 12:34:58,934:INFO:Initializing create_model()
2024-07-16 12:34:58,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022D50F46A50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8129, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-16 12:34:58,934:INFO:Checking exceptions
2024-07-16 12:34:58,935:INFO:Importing libraries
2024-07-16 12:34:58,935:INFO:Copying training dataset
2024-07-16 12:34:58,936:INFO:Defining folds
2024-07-16 12:34:58,936:INFO:Declaring metric variables
2024-07-16 12:34:58,937:INFO:Importing untrained model
2024-07-16 12:34:58,937:INFO:Declaring custom model
2024-07-16 12:34:58,937:INFO:Decision Tree Classifier Imported successfully
2024-07-16 12:34:58,937:INFO:Cross validation set to False
2024-07-16 12:34:58,937:INFO:Fitting Model
2024-07-16 12:34:59,147:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8129, splitter='best')
2024-07-16 12:34:59,147:INFO:create_model() successfully completed......................................
2024-07-16 12:34:59,224:INFO:_master_model_container: 15
2024-07-16 12:34:59,224:INFO:_display_container: 2
2024-07-16 12:34:59,225:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8129, splitter='best')
2024-07-16 12:34:59,225:INFO:compare_models() successfully completed......................................
2024-07-16 12:34:59,244:WARNING:C:\Users\JAL\AppData\Local\Temp\ipykernel_29900\796603356.py:82: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  best_model[best_model.select_dtypes(include=['number']).columns] *= 100

2024-07-18 11:00:42,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:00:42,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:00:42,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:00:42,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:00:42,594:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-07-18 11:14:56,730:INFO:PyCaret ClassificationExperiment
2024-07-18 11:14:56,730:INFO:Logging name: clf-default-name
2024-07-18 11:14:56,730:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-18 11:14:56,730:INFO:version 3.0.0
2024-07-18 11:14:56,730:INFO:Initializing setup()
2024-07-18 11:14:56,730:INFO:self.USI: 5c58
2024-07-18 11:14:56,730:INFO:self._variable_keys: {'n_jobs_param', 'fix_imbalance', 'exp_id', 'y_test', 'is_multiclass', '_ml_usecase', 'html_param', 'target_param', 'USI', 'gpu_param', 'log_plots_param', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'fold_generator', 'logging_param', 'y_train', 'fold_groups_param', 'seed', 'idx', 'X_test', 'X', 'data', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'y'}
2024-07-18 11:14:56,730:INFO:Checking environment
2024-07-18 11:14:56,730:INFO:python_version: 3.11.4
2024-07-18 11:14:56,730:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2024-07-18 11:14:56,730:INFO:machine: AMD64
2024-07-18 11:14:56,730:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-18 11:14:56,730:INFO:Memory: svmem(total=68659781632, available=53297102848, percent=22.4, used=15362678784, free=53297102848)
2024-07-18 11:14:56,730:INFO:Physical Core: 16
2024-07-18 11:14:56,730:INFO:Logical Core: 32
2024-07-18 11:14:56,730:INFO:Checking libraries
2024-07-18 11:14:56,730:INFO:System:
2024-07-18 11:14:56,730:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2024-07-18 11:14:56,730:INFO:executable: c:\Users\JAL\AppData\Local\Programs\Python\Python311\python.exe
2024-07-18 11:14:56,730:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-18 11:14:56,730:INFO:PyCaret required dependencies:
2024-07-18 11:14:56,760:INFO:                 pip: 24.1.2
2024-07-18 11:14:56,760:INFO:          setuptools: 70.3.0
2024-07-18 11:14:56,760:INFO:             pycaret: 3.0.0
2024-07-18 11:14:56,760:INFO:             IPython: 8.15.0
2024-07-18 11:14:56,760:INFO:          ipywidgets: 8.1.3
2024-07-18 11:14:56,760:INFO:                tqdm: 4.66.4
2024-07-18 11:14:56,760:INFO:               numpy: 1.24.4
2024-07-18 11:14:56,760:INFO:              pandas: 2.2.2
2024-07-18 11:14:56,760:INFO:              jinja2: 3.1.4
2024-07-18 11:14:56,760:INFO:               scipy: 1.11.4
2024-07-18 11:14:56,760:INFO:              joblib: 1.3.2
2024-07-18 11:14:56,760:INFO:             sklearn: 1.3.0
2024-07-18 11:14:56,760:INFO:                pyod: 2.0.1
2024-07-18 11:14:56,760:INFO:            imblearn: 0.12.3
2024-07-18 11:14:56,760:INFO:   category_encoders: 2.6.3
2024-07-18 11:14:56,760:INFO:            lightgbm: 4.3.0
2024-07-18 11:14:56,760:INFO:               numba: 0.60.0
2024-07-18 11:14:56,760:INFO:            requests: 2.32.3
2024-07-18 11:14:56,760:INFO:          matplotlib: 3.7.5
2024-07-18 11:14:56,760:INFO:          scikitplot: 0.3.7
2024-07-18 11:14:56,760:INFO:         yellowbrick: 1.5
2024-07-18 11:14:56,760:INFO:              plotly: 5.22.0
2024-07-18 11:14:56,760:INFO:             kaleido: 0.2.1
2024-07-18 11:14:56,760:INFO:         statsmodels: 0.14.2
2024-07-18 11:14:56,760:INFO:              sktime: 0.26.0
2024-07-18 11:14:56,760:INFO:               tbats: 1.1.3
2024-07-18 11:14:56,760:INFO:            pmdarima: 2.0.4
2024-07-18 11:14:56,760:INFO:              psutil: 5.9.5
2024-07-18 11:14:56,760:INFO:PyCaret optional dependencies:
2024-07-18 11:14:56,781:INFO:                shap: Not installed
2024-07-18 11:14:56,781:INFO:           interpret: Not installed
2024-07-18 11:14:56,781:INFO:                umap: Not installed
2024-07-18 11:14:56,781:INFO:    pandas_profiling: Not installed
2024-07-18 11:14:56,781:INFO:  explainerdashboard: Not installed
2024-07-18 11:14:56,781:INFO:             autoviz: Not installed
2024-07-18 11:14:56,781:INFO:           fairlearn: Not installed
2024-07-18 11:14:56,781:INFO:             xgboost: 2.0.3
2024-07-18 11:14:56,781:INFO:            catboost: 1.2.5
2024-07-18 11:14:56,781:INFO:              kmodes: Not installed
2024-07-18 11:14:56,781:INFO:             mlxtend: Not installed
2024-07-18 11:14:56,781:INFO:       statsforecast: 1.4.0
2024-07-18 11:14:56,781:INFO:        tune_sklearn: Not installed
2024-07-18 11:14:56,781:INFO:                 ray: 2.10.0
2024-07-18 11:14:56,781:INFO:            hyperopt: 0.2.7
2024-07-18 11:14:56,781:INFO:              optuna: Not installed
2024-07-18 11:14:56,781:INFO:               skopt: Not installed
2024-07-18 11:14:56,781:INFO:              mlflow: Not installed
2024-07-18 11:14:56,781:INFO:              gradio: Not installed
2024-07-18 11:14:56,781:INFO:             fastapi: Not installed
2024-07-18 11:14:56,781:INFO:             uvicorn: Not installed
2024-07-18 11:14:56,781:INFO:              m2cgen: Not installed
2024-07-18 11:14:56,781:INFO:           evidently: Not installed
2024-07-18 11:14:56,781:INFO:               fugue: Not installed
2024-07-18 11:14:56,781:INFO:           streamlit: 1.31.0
2024-07-18 11:14:56,781:INFO:             prophet: Not installed
2024-07-18 11:14:56,781:INFO:None
2024-07-18 11:14:56,781:INFO:Set up GPU usage.
2024-07-18 11:14:56,781:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:56,781:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2024-07-18 11:14:56,781:INFO:Set up data.
2024-07-18 11:14:56,781:INFO:Set up train/test split.
2024-07-18 11:14:56,792:INFO:Set up index.
2024-07-18 11:14:56,792:INFO:Set up folding strategy.
2024-07-18 11:14:56,792:INFO:Assigning column types.
2024-07-18 11:14:56,793:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-18 11:14:56,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:56,820:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 11:14:56,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:56,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:56,820:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:14:56,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:56,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:56,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:56,843:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:14:57,077:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:14:57,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 11:14:57,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,120:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:14:57,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,148:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:14:57,251:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:14:57,251:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-18 11:14:57,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,281:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:14:57,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,301:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:14:57,401:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:14:57,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:14:57,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,457:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:14:57,557:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:14:57,557:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-18 11:14:57,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,613:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:14:57,700:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:14:57,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,756:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:14:57,844:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:14:57,844:INFO:Preparing preprocessing pipeline...
2024-07-18 11:14:57,844:INFO:Set up simple imputation.
2024-07-18 11:14:57,851:INFO:Finished creating preprocessing pipeline.
2024-07-18 11:14:57,859:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-18 11:14:57,859:INFO:Creating final display dataframe.
2024-07-18 11:14:57,880:INFO:Setup _display_container:                     Description             Value
0                    Session id              1393
1                        Target       PlacedOrNot
2                   Target type            Binary
3           Original data shape         (2224, 4)
4        Transformed data shape         (2224, 4)
5   Transformed train set shape         (1668, 4)
6    Transformed test set shape          (556, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              5c58
2024-07-18 11:14:57,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,929:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,929:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,930:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:57,942:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:14:58,046:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:14:58,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:58,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:58,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:58,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:58,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:58,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:14:58,091:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:14:58,194:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:14:58,194:INFO:setup() successfully completed in 1.85s...............
2024-07-18 11:14:58,194:INFO:Initializing compare_models()
2024-07-18 11:14:58,194:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-18 11:14:58,194:INFO:Checking exceptions
2024-07-18 11:14:58,194:INFO:Preparing display monitor
2024-07-18 11:14:58,210:INFO:Initializing Logistic Regression
2024-07-18 11:14:58,210:INFO:Total runtime is 0.0 minutes
2024-07-18 11:14:58,210:INFO:SubProcess create_model() called ==================================
2024-07-18 11:14:58,210:INFO:Initializing create_model()
2024-07-18 11:14:58,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:14:58,210:INFO:Checking exceptions
2024-07-18 11:14:58,210:INFO:Importing libraries
2024-07-18 11:14:58,210:INFO:Copying training dataset
2024-07-18 11:14:58,219:INFO:Defining folds
2024-07-18 11:14:58,219:INFO:Declaring metric variables
2024-07-18 11:14:58,221:INFO:Importing untrained model
2024-07-18 11:14:58,221:INFO:Logistic Regression Imported successfully
2024-07-18 11:14:58,228:INFO:Starting cross validation
2024-07-18 11:14:58,228:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:02,160:INFO:Calculating mean and std
2024-07-18 11:15:02,160:INFO:Creating metrics dataframe
2024-07-18 11:15:02,510:INFO:Uploading results into container
2024-07-18 11:15:02,510:INFO:Uploading model into container now
2024-07-18 11:15:02,510:INFO:_master_model_container: 1
2024-07-18 11:15:02,510:INFO:_display_container: 2
2024-07-18 11:15:02,510:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1393, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:15:02,510:INFO:create_model() successfully completed......................................
2024-07-18 11:15:02,578:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:02,578:INFO:Creating metrics dataframe
2024-07-18 11:15:02,580:INFO:Initializing K Neighbors Classifier
2024-07-18 11:15:02,580:INFO:Total runtime is 0.07283316453297933 minutes
2024-07-18 11:15:02,580:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:02,580:INFO:Initializing create_model()
2024-07-18 11:15:02,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:02,580:INFO:Checking exceptions
2024-07-18 11:15:02,580:INFO:Importing libraries
2024-07-18 11:15:02,580:INFO:Copying training dataset
2024-07-18 11:15:02,580:INFO:Defining folds
2024-07-18 11:15:02,580:INFO:Declaring metric variables
2024-07-18 11:15:02,580:INFO:Importing untrained model
2024-07-18 11:15:02,580:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:15:02,590:INFO:Starting cross validation
2024-07-18 11:15:02,594:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:06,810:INFO:Calculating mean and std
2024-07-18 11:15:06,810:INFO:Creating metrics dataframe
2024-07-18 11:15:07,165:INFO:Uploading results into container
2024-07-18 11:15:07,165:INFO:Uploading model into container now
2024-07-18 11:15:07,170:INFO:_master_model_container: 2
2024-07-18 11:15:07,170:INFO:_display_container: 2
2024-07-18 11:15:07,170:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:15:07,170:INFO:create_model() successfully completed......................................
2024-07-18 11:15:07,224:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:07,224:INFO:Creating metrics dataframe
2024-07-18 11:15:07,231:INFO:Initializing Naive Bayes
2024-07-18 11:15:07,231:INFO:Total runtime is 0.1503348668416341 minutes
2024-07-18 11:15:07,231:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:07,231:INFO:Initializing create_model()
2024-07-18 11:15:07,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:07,231:INFO:Checking exceptions
2024-07-18 11:15:07,231:INFO:Importing libraries
2024-07-18 11:15:07,231:INFO:Copying training dataset
2024-07-18 11:15:07,231:INFO:Defining folds
2024-07-18 11:15:07,231:INFO:Declaring metric variables
2024-07-18 11:15:07,231:INFO:Importing untrained model
2024-07-18 11:15:07,241:INFO:Naive Bayes Imported successfully
2024-07-18 11:15:07,241:INFO:Starting cross validation
2024-07-18 11:15:07,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:11,218:INFO:Calculating mean and std
2024-07-18 11:15:11,219:INFO:Creating metrics dataframe
2024-07-18 11:15:11,607:INFO:Uploading results into container
2024-07-18 11:15:11,608:INFO:Uploading model into container now
2024-07-18 11:15:11,608:INFO:_master_model_container: 3
2024-07-18 11:15:11,608:INFO:_display_container: 2
2024-07-18 11:15:11,608:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:15:11,609:INFO:create_model() successfully completed......................................
2024-07-18 11:15:11,670:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:11,670:INFO:Creating metrics dataframe
2024-07-18 11:15:11,674:INFO:Initializing Decision Tree Classifier
2024-07-18 11:15:11,674:INFO:Total runtime is 0.2243963917096456 minutes
2024-07-18 11:15:11,676:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:11,676:INFO:Initializing create_model()
2024-07-18 11:15:11,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:11,676:INFO:Checking exceptions
2024-07-18 11:15:11,676:INFO:Importing libraries
2024-07-18 11:15:11,676:INFO:Copying training dataset
2024-07-18 11:15:11,678:INFO:Defining folds
2024-07-18 11:15:11,678:INFO:Declaring metric variables
2024-07-18 11:15:11,680:INFO:Importing untrained model
2024-07-18 11:15:11,682:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:15:11,685:INFO:Starting cross validation
2024-07-18 11:15:11,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:15,789:INFO:Calculating mean and std
2024-07-18 11:15:15,790:INFO:Creating metrics dataframe
2024-07-18 11:15:16,175:INFO:Uploading results into container
2024-07-18 11:15:16,175:INFO:Uploading model into container now
2024-07-18 11:15:16,176:INFO:_master_model_container: 4
2024-07-18 11:15:16,176:INFO:_display_container: 2
2024-07-18 11:15:16,176:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1393, splitter='best')
2024-07-18 11:15:16,176:INFO:create_model() successfully completed......................................
2024-07-18 11:15:16,241:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:16,242:INFO:Creating metrics dataframe
2024-07-18 11:15:16,246:INFO:Initializing SVM - Linear Kernel
2024-07-18 11:15:16,246:INFO:Total runtime is 0.3005971908569336 minutes
2024-07-18 11:15:16,249:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:16,249:INFO:Initializing create_model()
2024-07-18 11:15:16,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:16,249:INFO:Checking exceptions
2024-07-18 11:15:16,249:INFO:Importing libraries
2024-07-18 11:15:16,249:INFO:Copying training dataset
2024-07-18 11:15:16,251:INFO:Defining folds
2024-07-18 11:15:16,251:INFO:Declaring metric variables
2024-07-18 11:15:16,253:INFO:Importing untrained model
2024-07-18 11:15:16,256:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:15:16,259:INFO:Starting cross validation
2024-07-18 11:15:16,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:16,286:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:16,717:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:17,136:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:17,550:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:17,969:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:18,387:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:18,796:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:19,197:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:19,603:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:20,008:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:20,389:INFO:Calculating mean and std
2024-07-18 11:15:20,389:INFO:Creating metrics dataframe
2024-07-18 11:15:20,769:INFO:Uploading results into container
2024-07-18 11:15:20,769:INFO:Uploading model into container now
2024-07-18 11:15:20,770:INFO:_master_model_container: 5
2024-07-18 11:15:20,770:INFO:_display_container: 2
2024-07-18 11:15:20,770:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1393, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:15:20,770:INFO:create_model() successfully completed......................................
2024-07-18 11:15:20,838:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:20,838:INFO:Creating metrics dataframe
2024-07-18 11:15:20,844:INFO:Initializing Ridge Classifier
2024-07-18 11:15:20,844:INFO:Total runtime is 0.37722145318984984 minutes
2024-07-18 11:15:20,846:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:20,847:INFO:Initializing create_model()
2024-07-18 11:15:20,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:20,847:INFO:Checking exceptions
2024-07-18 11:15:20,847:INFO:Importing libraries
2024-07-18 11:15:20,847:INFO:Copying training dataset
2024-07-18 11:15:20,849:INFO:Defining folds
2024-07-18 11:15:20,849:INFO:Declaring metric variables
2024-07-18 11:15:20,850:INFO:Importing untrained model
2024-07-18 11:15:20,852:INFO:Ridge Classifier Imported successfully
2024-07-18 11:15:20,856:INFO:Starting cross validation
2024-07-18 11:15:20,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:20,878:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:21,279:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:21,686:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:22,099:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:22,511:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:22,921:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:23,320:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:23,715:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:24,113:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:24,519:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:15:24,921:INFO:Calculating mean and std
2024-07-18 11:15:24,921:INFO:Creating metrics dataframe
2024-07-18 11:15:25,315:INFO:Uploading results into container
2024-07-18 11:15:25,315:INFO:Uploading model into container now
2024-07-18 11:15:25,316:INFO:_master_model_container: 6
2024-07-18 11:15:25,316:INFO:_display_container: 2
2024-07-18 11:15:25,316:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1393, solver='auto',
                tol=0.0001)
2024-07-18 11:15:25,316:INFO:create_model() successfully completed......................................
2024-07-18 11:15:25,393:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:25,393:INFO:Creating metrics dataframe
2024-07-18 11:15:25,398:INFO:Initializing Random Forest Classifier
2024-07-18 11:15:25,398:INFO:Total runtime is 0.45312114953994753 minutes
2024-07-18 11:15:25,400:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:25,400:INFO:Initializing create_model()
2024-07-18 11:15:25,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:25,400:INFO:Checking exceptions
2024-07-18 11:15:25,400:INFO:Importing libraries
2024-07-18 11:15:25,400:INFO:Copying training dataset
2024-07-18 11:15:25,402:INFO:Defining folds
2024-07-18 11:15:25,402:INFO:Declaring metric variables
2024-07-18 11:15:25,404:INFO:Importing untrained model
2024-07-18 11:15:25,407:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:15:25,412:INFO:Starting cross validation
2024-07-18 11:15:25,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:31,374:INFO:Calculating mean and std
2024-07-18 11:15:31,375:INFO:Creating metrics dataframe
2024-07-18 11:15:31,749:INFO:Uploading results into container
2024-07-18 11:15:31,750:INFO:Uploading model into container now
2024-07-18 11:15:31,750:INFO:_master_model_container: 7
2024-07-18 11:15:31,750:INFO:_display_container: 2
2024-07-18 11:15:31,750:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1393, verbose=0, warm_start=False)
2024-07-18 11:15:31,750:INFO:create_model() successfully completed......................................
2024-07-18 11:15:31,814:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:31,814:INFO:Creating metrics dataframe
2024-07-18 11:15:31,819:INFO:Initializing Quadratic Discriminant Analysis
2024-07-18 11:15:31,819:INFO:Total runtime is 0.5601380268732707 minutes
2024-07-18 11:15:31,820:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:31,820:INFO:Initializing create_model()
2024-07-18 11:15:31,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:31,821:INFO:Checking exceptions
2024-07-18 11:15:31,821:INFO:Importing libraries
2024-07-18 11:15:31,821:INFO:Copying training dataset
2024-07-18 11:15:31,822:INFO:Defining folds
2024-07-18 11:15:31,822:INFO:Declaring metric variables
2024-07-18 11:15:31,824:INFO:Importing untrained model
2024-07-18 11:15:31,826:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:15:31,830:INFO:Starting cross validation
2024-07-18 11:15:31,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:35,876:INFO:Calculating mean and std
2024-07-18 11:15:35,877:INFO:Creating metrics dataframe
2024-07-18 11:15:36,253:INFO:Uploading results into container
2024-07-18 11:15:36,253:INFO:Uploading model into container now
2024-07-18 11:15:36,253:INFO:_master_model_container: 8
2024-07-18 11:15:36,253:INFO:_display_container: 2
2024-07-18 11:15:36,254:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:15:36,254:INFO:create_model() successfully completed......................................
2024-07-18 11:15:36,316:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:36,316:INFO:Creating metrics dataframe
2024-07-18 11:15:36,322:INFO:Initializing Ada Boost Classifier
2024-07-18 11:15:36,322:INFO:Total runtime is 0.6351871490478517 minutes
2024-07-18 11:15:36,324:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:36,324:INFO:Initializing create_model()
2024-07-18 11:15:36,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:36,324:INFO:Checking exceptions
2024-07-18 11:15:36,324:INFO:Importing libraries
2024-07-18 11:15:36,325:INFO:Copying training dataset
2024-07-18 11:15:36,326:INFO:Defining folds
2024-07-18 11:15:36,326:INFO:Declaring metric variables
2024-07-18 11:15:36,328:INFO:Importing untrained model
2024-07-18 11:15:36,330:INFO:Ada Boost Classifier Imported successfully
2024-07-18 11:15:36,333:INFO:Starting cross validation
2024-07-18 11:15:36,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:41,338:INFO:Calculating mean and std
2024-07-18 11:15:41,338:INFO:Creating metrics dataframe
2024-07-18 11:15:41,761:INFO:Uploading results into container
2024-07-18 11:15:41,761:INFO:Uploading model into container now
2024-07-18 11:15:41,762:INFO:_master_model_container: 9
2024-07-18 11:15:41,762:INFO:_display_container: 2
2024-07-18 11:15:41,762:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1393)
2024-07-18 11:15:41,762:INFO:create_model() successfully completed......................................
2024-07-18 11:15:41,851:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:41,851:INFO:Creating metrics dataframe
2024-07-18 11:15:41,857:INFO:Initializing Gradient Boosting Classifier
2024-07-18 11:15:41,857:INFO:Total runtime is 0.7274434606234234 minutes
2024-07-18 11:15:41,860:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:41,861:INFO:Initializing create_model()
2024-07-18 11:15:41,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:41,861:INFO:Checking exceptions
2024-07-18 11:15:41,861:INFO:Importing libraries
2024-07-18 11:15:41,861:INFO:Copying training dataset
2024-07-18 11:15:41,863:INFO:Defining folds
2024-07-18 11:15:41,863:INFO:Declaring metric variables
2024-07-18 11:15:41,866:INFO:Importing untrained model
2024-07-18 11:15:41,867:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:15:41,871:INFO:Starting cross validation
2024-07-18 11:15:41,871:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:47,452:INFO:Calculating mean and std
2024-07-18 11:15:47,453:INFO:Creating metrics dataframe
2024-07-18 11:15:47,878:INFO:Uploading results into container
2024-07-18 11:15:47,880:INFO:Uploading model into container now
2024-07-18 11:15:47,880:INFO:_master_model_container: 10
2024-07-18 11:15:47,880:INFO:_display_container: 2
2024-07-18 11:15:47,880:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1393, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:15:47,881:INFO:create_model() successfully completed......................................
2024-07-18 11:15:47,974:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:47,974:INFO:Creating metrics dataframe
2024-07-18 11:15:47,981:INFO:Initializing Linear Discriminant Analysis
2024-07-18 11:15:47,981:INFO:Total runtime is 0.8295043110847474 minutes
2024-07-18 11:15:47,983:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:47,983:INFO:Initializing create_model()
2024-07-18 11:15:47,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:47,984:INFO:Checking exceptions
2024-07-18 11:15:47,984:INFO:Importing libraries
2024-07-18 11:15:47,984:INFO:Copying training dataset
2024-07-18 11:15:47,986:INFO:Defining folds
2024-07-18 11:15:47,986:INFO:Declaring metric variables
2024-07-18 11:15:47,989:INFO:Importing untrained model
2024-07-18 11:15:47,990:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:15:47,996:INFO:Starting cross validation
2024-07-18 11:15:47,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:52,447:INFO:Calculating mean and std
2024-07-18 11:15:52,448:INFO:Creating metrics dataframe
2024-07-18 11:15:52,864:INFO:Uploading results into container
2024-07-18 11:15:52,864:INFO:Uploading model into container now
2024-07-18 11:15:52,864:INFO:_master_model_container: 11
2024-07-18 11:15:52,865:INFO:_display_container: 2
2024-07-18 11:15:52,865:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:15:52,865:INFO:create_model() successfully completed......................................
2024-07-18 11:15:52,960:INFO:SubProcess create_model() end ==================================
2024-07-18 11:15:52,961:INFO:Creating metrics dataframe
2024-07-18 11:15:52,967:INFO:Initializing Extra Trees Classifier
2024-07-18 11:15:52,967:INFO:Total runtime is 0.9126144806543988 minutes
2024-07-18 11:15:52,970:INFO:SubProcess create_model() called ==================================
2024-07-18 11:15:52,970:INFO:Initializing create_model()
2024-07-18 11:15:52,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:15:52,971:INFO:Checking exceptions
2024-07-18 11:15:52,971:INFO:Importing libraries
2024-07-18 11:15:52,971:INFO:Copying training dataset
2024-07-18 11:15:52,974:INFO:Defining folds
2024-07-18 11:15:52,974:INFO:Declaring metric variables
2024-07-18 11:15:52,976:INFO:Importing untrained model
2024-07-18 11:15:52,979:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:15:52,983:INFO:Starting cross validation
2024-07-18 11:15:52,983:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:15:59,636:INFO:Calculating mean and std
2024-07-18 11:15:59,637:INFO:Creating metrics dataframe
2024-07-18 11:16:00,051:INFO:Uploading results into container
2024-07-18 11:16:00,052:INFO:Uploading model into container now
2024-07-18 11:16:00,052:INFO:_master_model_container: 12
2024-07-18 11:16:00,052:INFO:_display_container: 2
2024-07-18 11:16:00,053:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1393, verbose=0, warm_start=False)
2024-07-18 11:16:00,053:INFO:create_model() successfully completed......................................
2024-07-18 11:16:00,136:INFO:SubProcess create_model() end ==================================
2024-07-18 11:16:00,136:INFO:Creating metrics dataframe
2024-07-18 11:16:00,144:INFO:Initializing Extreme Gradient Boosting
2024-07-18 11:16:00,144:INFO:Total runtime is 1.0322296341260275 minutes
2024-07-18 11:16:00,146:INFO:SubProcess create_model() called ==================================
2024-07-18 11:16:00,147:INFO:Initializing create_model()
2024-07-18 11:16:00,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:16:00,147:INFO:Checking exceptions
2024-07-18 11:16:00,147:INFO:Importing libraries
2024-07-18 11:16:00,147:INFO:Copying training dataset
2024-07-18 11:16:00,150:INFO:Defining folds
2024-07-18 11:16:00,150:INFO:Declaring metric variables
2024-07-18 11:16:00,152:INFO:Importing untrained model
2024-07-18 11:16:00,155:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:16:00,160:INFO:Starting cross validation
2024-07-18 11:16:00,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:16:00,601:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:00] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:01,337:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:01] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:02,088:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:02] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:02,825:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:02] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:03,560:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:03] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:04,289:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:04] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:05,026:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:05] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:05,758:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:05] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:06,488:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:06] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:07,270:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:16:07] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:16:07,769:INFO:Calculating mean and std
2024-07-18 11:16:07,771:INFO:Creating metrics dataframe
2024-07-18 11:16:08,184:INFO:Uploading results into container
2024-07-18 11:16:08,185:INFO:Uploading model into container now
2024-07-18 11:16:08,185:INFO:_master_model_container: 13
2024-07-18 11:16:08,185:INFO:_display_container: 2
2024-07-18 11:16:08,186:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:16:08,186:INFO:create_model() successfully completed......................................
2024-07-18 11:16:08,280:INFO:SubProcess create_model() end ==================================
2024-07-18 11:16:08,280:INFO:Creating metrics dataframe
2024-07-18 11:16:08,287:INFO:Initializing Light Gradient Boosting Machine
2024-07-18 11:16:08,287:INFO:Total runtime is 1.167946219444275 minutes
2024-07-18 11:16:08,289:INFO:SubProcess create_model() called ==================================
2024-07-18 11:16:08,289:INFO:Initializing create_model()
2024-07-18 11:16:08,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:16:08,289:INFO:Checking exceptions
2024-07-18 11:16:08,290:INFO:Importing libraries
2024-07-18 11:16:08,290:INFO:Copying training dataset
2024-07-18 11:16:08,294:INFO:Defining folds
2024-07-18 11:16:08,294:INFO:Declaring metric variables
2024-07-18 11:16:08,297:INFO:Importing untrained model
2024-07-18 11:16:08,300:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:16:08,305:INFO:Starting cross validation
2024-07-18 11:16:08,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:16:08,320:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-18 11:16:08,320:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:08,320:INFO:[LightGBM] [Info] Total Bins 21
2024-07-18 11:16:08,321:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 3
2024-07-18 11:16:08,425:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:08,425:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:08,436:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:08,437:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:08,438:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000445 secs. 0 sparse feature groups
2024-07-18 11:16:08,438:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-18 11:16:08,438:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-18 11:16:08,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:08,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,561:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-18 11:16:09,561:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:09,562:INFO:[LightGBM] [Info] Total Bins 21
2024-07-18 11:16:09,562:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 3
2024-07-18 11:16:09,652:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:09,652:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:09,662:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:09,664:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:09,665:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000536 secs. 0 sparse feature groups
2024-07-18 11:16:09,665:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-18 11:16:09,665:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-18 11:16:09,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:09,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,785:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-18 11:16:10,785:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:10,786:INFO:[LightGBM] [Info] Total Bins 21
2024-07-18 11:16:10,786:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 3
2024-07-18 11:16:10,874:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:10,874:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:10,886:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:10,888:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:10,888:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000466 secs. 0 sparse feature groups
2024-07-18 11:16:10,888:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-18 11:16:10,888:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-18 11:16:10,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:10,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:11,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,062:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-18 11:16:12,062:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:12,063:INFO:[LightGBM] [Info] Total Bins 21
2024-07-18 11:16:12,063:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 3
2024-07-18 11:16:12,148:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:12,148:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:12,160:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:12,162:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:12,163:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000485 secs. 0 sparse feature groups
2024-07-18 11:16:12,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-18 11:16:12,163:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-18 11:16:12,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:12,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,283:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-18 11:16:13,283:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:13,283:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:16:13,283:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 3
2024-07-18 11:16:13,375:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:13,376:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:13,386:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:13,388:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:13,388:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000467 secs. 0 sparse feature groups
2024-07-18 11:16:13,389:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-18 11:16:13,389:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-18 11:16:13,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:13,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,502:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-18 11:16:14,502:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:14,502:INFO:[LightGBM] [Info] Total Bins 21
2024-07-18 11:16:14,502:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 3
2024-07-18 11:16:14,595:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:14,595:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:14,607:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:14,608:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:14,609:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000510 secs. 0 sparse feature groups
2024-07-18 11:16:14,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-18 11:16:14,609:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-18 11:16:14,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:14,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,740:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 663
2024-07-18 11:16:15,740:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:15,741:INFO:[LightGBM] [Info] Total Bins 21
2024-07-18 11:16:15,741:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 3
2024-07-18 11:16:15,834:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:15,834:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:15,846:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:15,847:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:15,848:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000470 secs. 0 sparse feature groups
2024-07-18 11:16:15,848:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558294 -> initscore=0.234243
2024-07-18 11:16:15,848:INFO:[LightGBM] [Info] Start training from score 0.234243
2024-07-18 11:16:15,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:15,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:16,966:INFO:[LightGBM] [Info] Number of positive: 837, number of negative: 664
2024-07-18 11:16:16,966:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:16,966:INFO:[LightGBM] [Info] Total Bins 21
2024-07-18 11:16:16,966:INFO:[LightGBM] [Info] Number of data points in the train set: 1501, number of used features: 3
2024-07-18 11:16:17,054:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:17,054:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:17,064:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:17,066:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:17,067:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000453 secs. 0 sparse feature groups
2024-07-18 11:16:17,067:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557628 -> initscore=0.231542
2024-07-18 11:16:17,067:INFO:[LightGBM] [Info] Start training from score 0.231542
2024-07-18 11:16:17,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:17,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,186:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 664
2024-07-18 11:16:18,186:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:18,186:INFO:[LightGBM] [Info] Total Bins 21
2024-07-18 11:16:18,186:INFO:[LightGBM] [Info] Number of data points in the train set: 1502, number of used features: 3
2024-07-18 11:16:18,279:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:18,280:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:18,290:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:18,292:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:18,292:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000520 secs. 0 sparse feature groups
2024-07-18 11:16:18,293:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557923 -> initscore=0.232736
2024-07-18 11:16:18,293:INFO:[LightGBM] [Info] Start training from score 0.232736
2024-07-18 11:16:18,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:18,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,461:INFO:[LightGBM] [Info] Number of positive: 838, number of negative: 664
2024-07-18 11:16:19,461:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:16:19,462:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:16:19,462:INFO:[LightGBM] [Info] Number of data points in the train set: 1502, number of used features: 3
2024-07-18 11:16:19,555:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:16:19,555:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:16:19,567:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:16:19,569:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:16:19,570:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000445 secs. 0 sparse feature groups
2024-07-18 11:16:19,570:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.557923 -> initscore=0.232736
2024-07-18 11:16:19,570:INFO:[LightGBM] [Info] Start training from score 0.232736
2024-07-18 11:16:19,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:19,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:16:20,679:INFO:Calculating mean and std
2024-07-18 11:16:20,680:INFO:Creating metrics dataframe
2024-07-18 11:16:21,110:INFO:Uploading results into container
2024-07-18 11:16:21,111:INFO:Uploading model into container now
2024-07-18 11:16:21,111:INFO:_master_model_container: 14
2024-07-18 11:16:21,111:INFO:_display_container: 2
2024-07-18 11:16:21,112:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1393, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:16:21,112:INFO:create_model() successfully completed......................................
2024-07-18 11:16:21,197:INFO:SubProcess create_model() end ==================================
2024-07-18 11:16:21,197:INFO:Creating metrics dataframe
2024-07-18 11:16:21,203:INFO:Initializing CatBoost Classifier
2024-07-18 11:16:21,203:INFO:Total runtime is 1.383211600780487 minutes
2024-07-18 11:16:21,206:INFO:SubProcess create_model() called ==================================
2024-07-18 11:16:21,206:INFO:Initializing create_model()
2024-07-18 11:16:21,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA939A110>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:16:21,206:INFO:Checking exceptions
2024-07-18 11:16:21,206:INFO:Importing libraries
2024-07-18 11:16:21,206:INFO:Copying training dataset
2024-07-18 11:16:21,208:INFO:Defining folds
2024-07-18 11:16:21,208:INFO:Declaring metric variables
2024-07-18 11:16:21,211:INFO:Importing untrained model
2024-07-18 11:16:21,213:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:16:21,219:INFO:Starting cross validation
2024-07-18 11:16:21,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:20:08,386:INFO:Calculating mean and std
2024-07-18 11:20:08,386:INFO:Creating metrics dataframe
2024-07-18 11:20:08,782:INFO:Uploading results into container
2024-07-18 11:20:08,783:INFO:Uploading model into container now
2024-07-18 11:20:08,783:INFO:_master_model_container: 15
2024-07-18 11:20:08,783:INFO:_display_container: 2
2024-07-18 11:20:08,783:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DB1E98890>
2024-07-18 11:20:08,783:INFO:create_model() successfully completed......................................
2024-07-18 11:20:08,849:INFO:SubProcess create_model() end ==================================
2024-07-18 11:20:08,849:INFO:Creating metrics dataframe
2024-07-18 11:20:08,855:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-18 11:20:08,860:INFO:Initializing create_model()
2024-07-18 11:20:08,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1393, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:08,860:INFO:Checking exceptions
2024-07-18 11:20:08,860:INFO:Importing libraries
2024-07-18 11:20:08,860:INFO:Copying training dataset
2024-07-18 11:20:08,860:INFO:Defining folds
2024-07-18 11:20:08,860:INFO:Declaring metric variables
2024-07-18 11:20:08,860:INFO:Importing untrained model
2024-07-18 11:20:08,860:INFO:Declaring custom model
2024-07-18 11:20:08,860:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:20:08,865:INFO:Cross validation set to False
2024-07-18 11:20:08,865:INFO:Fitting Model
2024-07-18 11:20:08,876:INFO:[LightGBM] [Info] Number of positive: 931, number of negative: 737
2024-07-18 11:20:08,876:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:20:08,876:INFO:[LightGBM] [Info] Total Bins 21
2024-07-18 11:20:08,876:INFO:[LightGBM] [Info] Number of data points in the train set: 1668, number of used features: 3
2024-07-18 11:20:08,955:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:20:08,955:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:20:08,966:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:20:08,970:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:20:08,970:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000554 secs. 0 sparse feature groups
2024-07-18 11:20:08,970:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558153 -> initscore=0.233671
2024-07-18 11:20:08,971:INFO:[LightGBM] [Info] Start training from score 0.233671
2024-07-18 11:20:09,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:20:09,944:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1393, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:20:09,944:INFO:create_model() successfully completed......................................
2024-07-18 11:20:10,009:INFO:Initializing create_model()
2024-07-18 11:20:10,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1393, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:10,009:INFO:Checking exceptions
2024-07-18 11:20:10,010:INFO:Importing libraries
2024-07-18 11:20:10,010:INFO:Copying training dataset
2024-07-18 11:20:10,011:INFO:Defining folds
2024-07-18 11:20:10,012:INFO:Declaring metric variables
2024-07-18 11:20:10,012:INFO:Importing untrained model
2024-07-18 11:20:10,012:INFO:Declaring custom model
2024-07-18 11:20:10,012:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:20:10,013:INFO:Cross validation set to False
2024-07-18 11:20:10,013:INFO:Fitting Model
2024-07-18 11:20:10,475:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1393, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:20:10,475:INFO:create_model() successfully completed......................................
2024-07-18 11:20:10,538:INFO:Initializing create_model()
2024-07-18 11:20:10,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:10,538:INFO:Checking exceptions
2024-07-18 11:20:10,539:INFO:Importing libraries
2024-07-18 11:20:10,539:INFO:Copying training dataset
2024-07-18 11:20:10,541:INFO:Defining folds
2024-07-18 11:20:10,541:INFO:Declaring metric variables
2024-07-18 11:20:10,541:INFO:Importing untrained model
2024-07-18 11:20:10,541:INFO:Declaring custom model
2024-07-18 11:20:10,542:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:20:10,542:INFO:Cross validation set to False
2024-07-18 11:20:10,542:INFO:Fitting Model
2024-07-18 11:20:10,751:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:20:10] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:20:11,177:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:20:11,177:INFO:create_model() successfully completed......................................
2024-07-18 11:20:11,240:INFO:Initializing create_model()
2024-07-18 11:20:11,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1393, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:11,241:INFO:Checking exceptions
2024-07-18 11:20:11,242:INFO:Importing libraries
2024-07-18 11:20:11,242:INFO:Copying training dataset
2024-07-18 11:20:11,244:INFO:Defining folds
2024-07-18 11:20:11,244:INFO:Declaring metric variables
2024-07-18 11:20:11,244:INFO:Importing untrained model
2024-07-18 11:20:11,244:INFO:Declaring custom model
2024-07-18 11:20:11,244:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:20:11,244:INFO:Cross validation set to False
2024-07-18 11:20:11,244:INFO:Fitting Model
2024-07-18 11:20:11,725:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1393, verbose=0, warm_start=False)
2024-07-18 11:20:11,725:INFO:create_model() successfully completed......................................
2024-07-18 11:20:11,786:INFO:Initializing create_model()
2024-07-18 11:20:11,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021DB1E98890>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:11,786:INFO:Checking exceptions
2024-07-18 11:20:11,786:INFO:Importing libraries
2024-07-18 11:20:11,786:INFO:Copying training dataset
2024-07-18 11:20:11,786:INFO:Defining folds
2024-07-18 11:20:11,786:INFO:Declaring metric variables
2024-07-18 11:20:11,786:INFO:Importing untrained model
2024-07-18 11:20:11,786:INFO:Declaring custom model
2024-07-18 11:20:11,786:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:20:11,786:INFO:Cross validation set to False
2024-07-18 11:20:11,786:INFO:Fitting Model
2024-07-18 11:20:32,895:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DB1EEA510>
2024-07-18 11:20:32,895:INFO:create_model() successfully completed......................................
2024-07-18 11:20:32,960:INFO:Initializing create_model()
2024-07-18 11:20:32,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1393, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:32,960:INFO:Checking exceptions
2024-07-18 11:20:32,965:INFO:Importing libraries
2024-07-18 11:20:32,965:INFO:Copying training dataset
2024-07-18 11:20:32,965:INFO:Defining folds
2024-07-18 11:20:32,965:INFO:Declaring metric variables
2024-07-18 11:20:32,965:INFO:Importing untrained model
2024-07-18 11:20:32,965:INFO:Declaring custom model
2024-07-18 11:20:32,965:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:20:32,968:INFO:Cross validation set to False
2024-07-18 11:20:32,968:INFO:Fitting Model
2024-07-18 11:20:33,371:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1393, splitter='best')
2024-07-18 11:20:33,371:INFO:create_model() successfully completed......................................
2024-07-18 11:20:33,425:INFO:Initializing create_model()
2024-07-18 11:20:33,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1393, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:33,425:INFO:Checking exceptions
2024-07-18 11:20:33,425:INFO:Importing libraries
2024-07-18 11:20:33,425:INFO:Copying training dataset
2024-07-18 11:20:33,436:INFO:Defining folds
2024-07-18 11:20:33,436:INFO:Declaring metric variables
2024-07-18 11:20:33,436:INFO:Importing untrained model
2024-07-18 11:20:33,436:INFO:Declaring custom model
2024-07-18 11:20:33,436:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:20:33,437:INFO:Cross validation set to False
2024-07-18 11:20:33,437:INFO:Fitting Model
2024-07-18 11:20:33,930:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1393, verbose=0, warm_start=False)
2024-07-18 11:20:33,930:INFO:create_model() successfully completed......................................
2024-07-18 11:20:33,995:INFO:Initializing create_model()
2024-07-18 11:20:33,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1393), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:33,995:INFO:Checking exceptions
2024-07-18 11:20:34,001:INFO:Importing libraries
2024-07-18 11:20:34,001:INFO:Copying training dataset
2024-07-18 11:20:34,001:INFO:Defining folds
2024-07-18 11:20:34,001:INFO:Declaring metric variables
2024-07-18 11:20:34,001:INFO:Importing untrained model
2024-07-18 11:20:34,001:INFO:Declaring custom model
2024-07-18 11:20:34,001:INFO:str Imported successfully
2024-07-18 11:20:34,001:INFO:Cross validation set to False
2024-07-18 11:20:34,001:INFO:Fitting Model
2024-07-18 11:20:34,465:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1393)
2024-07-18 11:20:34,465:INFO:create_model() successfully completed......................................
2024-07-18 11:20:34,556:INFO:Initializing create_model()
2024-07-18 11:20:34,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:34,556:INFO:Checking exceptions
2024-07-18 11:20:34,561:INFO:Importing libraries
2024-07-18 11:20:34,561:INFO:Copying training dataset
2024-07-18 11:20:34,563:INFO:Defining folds
2024-07-18 11:20:34,563:INFO:Declaring metric variables
2024-07-18 11:20:34,563:INFO:Importing untrained model
2024-07-18 11:20:34,563:INFO:Declaring custom model
2024-07-18 11:20:34,564:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:20:34,564:INFO:Cross validation set to False
2024-07-18 11:20:34,564:INFO:Fitting Model
2024-07-18 11:20:34,986:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:20:34,986:INFO:create_model() successfully completed......................................
2024-07-18 11:20:35,059:INFO:Initializing create_model()
2024-07-18 11:20:35,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:35,059:INFO:Checking exceptions
2024-07-18 11:20:35,060:INFO:Importing libraries
2024-07-18 11:20:35,060:INFO:Copying training dataset
2024-07-18 11:20:35,062:INFO:Defining folds
2024-07-18 11:20:35,062:INFO:Declaring metric variables
2024-07-18 11:20:35,062:INFO:Importing untrained model
2024-07-18 11:20:35,062:INFO:Declaring custom model
2024-07-18 11:20:35,062:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:20:35,063:INFO:Cross validation set to False
2024-07-18 11:20:35,063:INFO:Fitting Model
2024-07-18 11:20:35,455:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:20:35,455:INFO:create_model() successfully completed......................................
2024-07-18 11:20:35,525:INFO:Initializing create_model()
2024-07-18 11:20:35,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:35,525:INFO:Checking exceptions
2024-07-18 11:20:35,525:INFO:Importing libraries
2024-07-18 11:20:35,525:INFO:Copying training dataset
2024-07-18 11:20:35,525:INFO:Defining folds
2024-07-18 11:20:35,525:INFO:Declaring metric variables
2024-07-18 11:20:35,525:INFO:Importing untrained model
2024-07-18 11:20:35,525:INFO:Declaring custom model
2024-07-18 11:20:35,525:INFO:Naive Bayes Imported successfully
2024-07-18 11:20:35,525:INFO:Cross validation set to False
2024-07-18 11:20:35,525:INFO:Fitting Model
2024-07-18 11:20:35,931:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:20:35,931:INFO:create_model() successfully completed......................................
2024-07-18 11:20:35,995:INFO:Initializing create_model()
2024-07-18 11:20:35,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1393, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:35,995:INFO:Checking exceptions
2024-07-18 11:20:35,995:INFO:Importing libraries
2024-07-18 11:20:35,995:INFO:Copying training dataset
2024-07-18 11:20:36,002:INFO:Defining folds
2024-07-18 11:20:36,002:INFO:Declaring metric variables
2024-07-18 11:20:36,002:INFO:Importing untrained model
2024-07-18 11:20:36,002:INFO:Declaring custom model
2024-07-18 11:20:36,002:INFO:Ridge Classifier Imported successfully
2024-07-18 11:20:36,002:INFO:Cross validation set to False
2024-07-18 11:20:36,003:INFO:Fitting Model
2024-07-18 11:20:36,402:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1393, solver='auto',
                tol=0.0001)
2024-07-18 11:20:36,402:INFO:create_model() successfully completed......................................
2024-07-18 11:20:36,465:INFO:Initializing create_model()
2024-07-18 11:20:36,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:36,465:INFO:Checking exceptions
2024-07-18 11:20:36,465:INFO:Importing libraries
2024-07-18 11:20:36,465:INFO:Copying training dataset
2024-07-18 11:20:36,468:INFO:Defining folds
2024-07-18 11:20:36,468:INFO:Declaring metric variables
2024-07-18 11:20:36,469:INFO:Importing untrained model
2024-07-18 11:20:36,469:INFO:Declaring custom model
2024-07-18 11:20:36,469:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:20:36,469:INFO:Cross validation set to False
2024-07-18 11:20:36,469:INFO:Fitting Model
2024-07-18 11:20:36,865:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:20:36,865:INFO:create_model() successfully completed......................................
2024-07-18 11:20:36,925:INFO:Initializing create_model()
2024-07-18 11:20:36,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1393, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:36,925:INFO:Checking exceptions
2024-07-18 11:20:36,925:INFO:Importing libraries
2024-07-18 11:20:36,925:INFO:Copying training dataset
2024-07-18 11:20:36,925:INFO:Defining folds
2024-07-18 11:20:36,925:INFO:Declaring metric variables
2024-07-18 11:20:36,925:INFO:Importing untrained model
2024-07-18 11:20:36,925:INFO:Declaring custom model
2024-07-18 11:20:36,925:INFO:Logistic Regression Imported successfully
2024-07-18 11:20:36,935:INFO:Cross validation set to False
2024-07-18 11:20:36,935:INFO:Fitting Model
2024-07-18 11:20:37,336:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1393, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:20:37,336:INFO:create_model() successfully completed......................................
2024-07-18 11:20:37,401:INFO:Initializing create_model()
2024-07-18 11:20:37,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1393, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:37,402:INFO:Checking exceptions
2024-07-18 11:20:37,402:INFO:Importing libraries
2024-07-18 11:20:37,402:INFO:Copying training dataset
2024-07-18 11:20:37,405:INFO:Defining folds
2024-07-18 11:20:37,405:INFO:Declaring metric variables
2024-07-18 11:20:37,405:INFO:Importing untrained model
2024-07-18 11:20:37,405:INFO:Declaring custom model
2024-07-18 11:20:37,405:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:20:37,406:INFO:Cross validation set to False
2024-07-18 11:20:37,406:INFO:Fitting Model
2024-07-18 11:20:37,803:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1393, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:20:37,803:INFO:create_model() successfully completed......................................
2024-07-18 11:20:37,875:INFO:_master_model_container: 15
2024-07-18 11:20:37,875:INFO:_display_container: 2
2024-07-18 11:20:37,875:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1393, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1393, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1393, verbose=0, warm_start=False), <catboost.core.CatBoostClassifier object at 0x0000021DB1EEA510>, DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1393, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1393, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1393), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1393, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1393, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1393, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-07-18 11:20:37,875:INFO:compare_models() successfully completed......................................
2024-07-18 11:20:37,886:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\codecarbon\output_methods\file.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  df = pd.concat([df, pd.DataFrame.from_records([dict(total.values)])])

2024-07-18 11:20:37,886:INFO:Initializing compare_models()
2024-07-18 11:20:37,886:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-18 11:20:37,886:INFO:Checking exceptions
2024-07-18 11:20:37,886:INFO:Preparing display monitor
2024-07-18 11:20:37,903:INFO:Initializing Logistic Regression
2024-07-18 11:20:37,905:INFO:Total runtime is 4.172722498575847e-05 minutes
2024-07-18 11:20:37,905:INFO:SubProcess create_model() called ==================================
2024-07-18 11:20:37,905:INFO:Initializing create_model()
2024-07-18 11:20:37,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:37,905:INFO:Checking exceptions
2024-07-18 11:20:37,905:INFO:Importing libraries
2024-07-18 11:20:37,905:INFO:Copying training dataset
2024-07-18 11:20:37,905:INFO:Defining folds
2024-07-18 11:20:37,905:INFO:Declaring metric variables
2024-07-18 11:20:37,905:INFO:Importing untrained model
2024-07-18 11:20:37,905:INFO:Logistic Regression Imported successfully
2024-07-18 11:20:37,916:INFO:Starting cross validation
2024-07-18 11:20:37,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:20:42,126:INFO:Calculating mean and std
2024-07-18 11:20:42,126:INFO:Creating metrics dataframe
2024-07-18 11:20:42,517:INFO:Uploading results into container
2024-07-18 11:20:42,517:INFO:Uploading model into container now
2024-07-18 11:20:42,517:INFO:_master_model_container: 16
2024-07-18 11:20:42,517:INFO:_display_container: 3
2024-07-18 11:20:42,518:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1393, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:20:42,518:INFO:create_model() successfully completed......................................
2024-07-18 11:20:42,575:INFO:SubProcess create_model() end ==================================
2024-07-18 11:20:42,575:INFO:Creating metrics dataframe
2024-07-18 11:20:42,586:INFO:Initializing K Neighbors Classifier
2024-07-18 11:20:42,586:INFO:Total runtime is 0.0780524214108785 minutes
2024-07-18 11:20:42,586:INFO:SubProcess create_model() called ==================================
2024-07-18 11:20:42,586:INFO:Initializing create_model()
2024-07-18 11:20:42,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:42,586:INFO:Checking exceptions
2024-07-18 11:20:42,586:INFO:Importing libraries
2024-07-18 11:20:42,586:INFO:Copying training dataset
2024-07-18 11:20:42,586:INFO:Defining folds
2024-07-18 11:20:42,586:INFO:Declaring metric variables
2024-07-18 11:20:42,586:INFO:Importing untrained model
2024-07-18 11:20:42,586:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:20:42,595:INFO:Starting cross validation
2024-07-18 11:20:42,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:20:47,186:INFO:Calculating mean and std
2024-07-18 11:20:47,195:INFO:Creating metrics dataframe
2024-07-18 11:20:47,575:INFO:Uploading results into container
2024-07-18 11:20:47,575:INFO:Uploading model into container now
2024-07-18 11:20:47,575:INFO:_master_model_container: 17
2024-07-18 11:20:47,575:INFO:_display_container: 3
2024-07-18 11:20:47,575:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:20:47,575:INFO:create_model() successfully completed......................................
2024-07-18 11:20:47,655:INFO:SubProcess create_model() end ==================================
2024-07-18 11:20:47,655:INFO:Creating metrics dataframe
2024-07-18 11:20:47,660:INFO:Initializing Naive Bayes
2024-07-18 11:20:47,660:INFO:Total runtime is 0.16261628071467082 minutes
2024-07-18 11:20:47,663:INFO:SubProcess create_model() called ==================================
2024-07-18 11:20:47,663:INFO:Initializing create_model()
2024-07-18 11:20:47,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:47,663:INFO:Checking exceptions
2024-07-18 11:20:47,663:INFO:Importing libraries
2024-07-18 11:20:47,663:INFO:Copying training dataset
2024-07-18 11:20:47,665:INFO:Defining folds
2024-07-18 11:20:47,665:INFO:Declaring metric variables
2024-07-18 11:20:47,667:INFO:Importing untrained model
2024-07-18 11:20:47,669:INFO:Naive Bayes Imported successfully
2024-07-18 11:20:47,674:INFO:Starting cross validation
2024-07-18 11:20:47,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:20:51,855:INFO:Calculating mean and std
2024-07-18 11:20:51,855:INFO:Creating metrics dataframe
2024-07-18 11:20:52,252:INFO:Uploading results into container
2024-07-18 11:20:52,252:INFO:Uploading model into container now
2024-07-18 11:20:52,252:INFO:_master_model_container: 18
2024-07-18 11:20:52,252:INFO:_display_container: 3
2024-07-18 11:20:52,252:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:20:52,252:INFO:create_model() successfully completed......................................
2024-07-18 11:20:52,315:INFO:SubProcess create_model() end ==================================
2024-07-18 11:20:52,316:INFO:Creating metrics dataframe
2024-07-18 11:20:52,319:INFO:Initializing Decision Tree Classifier
2024-07-18 11:20:52,319:INFO:Total runtime is 0.2402715524037679 minutes
2024-07-18 11:20:52,319:INFO:SubProcess create_model() called ==================================
2024-07-18 11:20:52,319:INFO:Initializing create_model()
2024-07-18 11:20:52,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:52,319:INFO:Checking exceptions
2024-07-18 11:20:52,319:INFO:Importing libraries
2024-07-18 11:20:52,319:INFO:Copying training dataset
2024-07-18 11:20:52,319:INFO:Defining folds
2024-07-18 11:20:52,319:INFO:Declaring metric variables
2024-07-18 11:20:52,325:INFO:Importing untrained model
2024-07-18 11:20:52,325:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:20:52,325:INFO:Starting cross validation
2024-07-18 11:20:52,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:20:56,483:INFO:Calculating mean and std
2024-07-18 11:20:56,485:INFO:Creating metrics dataframe
2024-07-18 11:20:56,870:INFO:Uploading results into container
2024-07-18 11:20:56,870:INFO:Uploading model into container now
2024-07-18 11:20:56,870:INFO:_master_model_container: 19
2024-07-18 11:20:56,871:INFO:_display_container: 3
2024-07-18 11:20:56,871:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1393, splitter='best')
2024-07-18 11:20:56,871:INFO:create_model() successfully completed......................................
2024-07-18 11:20:56,925:INFO:SubProcess create_model() end ==================================
2024-07-18 11:20:56,925:INFO:Creating metrics dataframe
2024-07-18 11:20:56,938:INFO:Initializing SVM - Linear Kernel
2024-07-18 11:20:56,939:INFO:Total runtime is 0.31726749340693156 minutes
2024-07-18 11:20:56,941:INFO:SubProcess create_model() called ==================================
2024-07-18 11:20:56,941:INFO:Initializing create_model()
2024-07-18 11:20:56,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:20:56,941:INFO:Checking exceptions
2024-07-18 11:20:56,941:INFO:Importing libraries
2024-07-18 11:20:56,941:INFO:Copying training dataset
2024-07-18 11:20:56,943:INFO:Defining folds
2024-07-18 11:20:56,943:INFO:Declaring metric variables
2024-07-18 11:20:56,944:INFO:Importing untrained model
2024-07-18 11:20:56,946:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:20:56,950:INFO:Starting cross validation
2024-07-18 11:20:56,950:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:20:56,973:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:20:57,386:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:20:57,795:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:20:58,209:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:20:58,619:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:20:59,025:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:20:59,445:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:20:59,855:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:00,272:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:00,683:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:01,075:INFO:Calculating mean and std
2024-07-18 11:21:01,076:INFO:Creating metrics dataframe
2024-07-18 11:21:01,465:INFO:Uploading results into container
2024-07-18 11:21:01,465:INFO:Uploading model into container now
2024-07-18 11:21:01,465:INFO:_master_model_container: 20
2024-07-18 11:21:01,465:INFO:_display_container: 3
2024-07-18 11:21:01,468:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1393, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:21:01,468:INFO:create_model() successfully completed......................................
2024-07-18 11:21:01,525:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:01,525:INFO:Creating metrics dataframe
2024-07-18 11:21:01,537:INFO:Initializing Ridge Classifier
2024-07-18 11:21:01,538:INFO:Total runtime is 0.3939146002133687 minutes
2024-07-18 11:21:01,540:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:01,540:INFO:Initializing create_model()
2024-07-18 11:21:01,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:01,540:INFO:Checking exceptions
2024-07-18 11:21:01,540:INFO:Importing libraries
2024-07-18 11:21:01,540:INFO:Copying training dataset
2024-07-18 11:21:01,542:INFO:Defining folds
2024-07-18 11:21:01,542:INFO:Declaring metric variables
2024-07-18 11:21:01,544:INFO:Importing untrained model
2024-07-18 11:21:01,545:INFO:Ridge Classifier Imported successfully
2024-07-18 11:21:01,549:INFO:Starting cross validation
2024-07-18 11:21:01,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:01,569:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:01,987:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:02,395:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:02,807:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:03,221:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:03,635:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:04,045:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:04,452:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:04,855:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:05,273:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:21:05,668:INFO:Calculating mean and std
2024-07-18 11:21:05,669:INFO:Creating metrics dataframe
2024-07-18 11:21:06,055:INFO:Uploading results into container
2024-07-18 11:21:06,055:INFO:Uploading model into container now
2024-07-18 11:21:06,055:INFO:_master_model_container: 21
2024-07-18 11:21:06,055:INFO:_display_container: 3
2024-07-18 11:21:06,055:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1393, solver='auto',
                tol=0.0001)
2024-07-18 11:21:06,055:INFO:create_model() successfully completed......................................
2024-07-18 11:21:06,119:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:06,119:INFO:Creating metrics dataframe
2024-07-18 11:21:06,125:INFO:Initializing Random Forest Classifier
2024-07-18 11:21:06,125:INFO:Total runtime is 0.47036816279093424 minutes
2024-07-18 11:21:06,125:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:06,125:INFO:Initializing create_model()
2024-07-18 11:21:06,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:06,125:INFO:Checking exceptions
2024-07-18 11:21:06,125:INFO:Importing libraries
2024-07-18 11:21:06,125:INFO:Copying training dataset
2024-07-18 11:21:06,125:INFO:Defining folds
2024-07-18 11:21:06,125:INFO:Declaring metric variables
2024-07-18 11:21:06,125:INFO:Importing untrained model
2024-07-18 11:21:06,125:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:21:06,135:INFO:Starting cross validation
2024-07-18 11:21:06,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:12,075:INFO:Calculating mean and std
2024-07-18 11:21:12,075:INFO:Creating metrics dataframe
2024-07-18 11:21:12,465:INFO:Uploading results into container
2024-07-18 11:21:12,465:INFO:Uploading model into container now
2024-07-18 11:21:12,465:INFO:_master_model_container: 22
2024-07-18 11:21:12,465:INFO:_display_container: 3
2024-07-18 11:21:12,465:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1393, verbose=0, warm_start=False)
2024-07-18 11:21:12,465:INFO:create_model() successfully completed......................................
2024-07-18 11:21:12,529:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:12,529:INFO:Creating metrics dataframe
2024-07-18 11:21:12,535:INFO:Initializing Quadratic Discriminant Analysis
2024-07-18 11:21:12,535:INFO:Total runtime is 0.5771999835968018 minutes
2024-07-18 11:21:12,536:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:12,536:INFO:Initializing create_model()
2024-07-18 11:21:12,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:12,537:INFO:Checking exceptions
2024-07-18 11:21:12,537:INFO:Importing libraries
2024-07-18 11:21:12,537:INFO:Copying training dataset
2024-07-18 11:21:12,538:INFO:Defining folds
2024-07-18 11:21:12,538:INFO:Declaring metric variables
2024-07-18 11:21:12,540:INFO:Importing untrained model
2024-07-18 11:21:12,542:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:21:12,546:INFO:Starting cross validation
2024-07-18 11:21:12,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:16,700:INFO:Calculating mean and std
2024-07-18 11:21:16,701:INFO:Creating metrics dataframe
2024-07-18 11:21:17,086:INFO:Uploading results into container
2024-07-18 11:21:17,087:INFO:Uploading model into container now
2024-07-18 11:21:17,087:INFO:_master_model_container: 23
2024-07-18 11:21:17,087:INFO:_display_container: 3
2024-07-18 11:21:17,087:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:21:17,088:INFO:create_model() successfully completed......................................
2024-07-18 11:21:17,151:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:17,151:INFO:Creating metrics dataframe
2024-07-18 11:21:17,155:INFO:Initializing Ada Boost Classifier
2024-07-18 11:21:17,155:INFO:Total runtime is 0.6542132019996644 minutes
2024-07-18 11:21:17,158:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:17,158:INFO:Initializing create_model()
2024-07-18 11:21:17,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:17,158:INFO:Checking exceptions
2024-07-18 11:21:17,159:INFO:Importing libraries
2024-07-18 11:21:17,159:INFO:Copying training dataset
2024-07-18 11:21:17,160:INFO:Defining folds
2024-07-18 11:21:17,160:INFO:Declaring metric variables
2024-07-18 11:21:17,162:INFO:Importing untrained model
2024-07-18 11:21:17,164:INFO:Ada Boost Classifier Imported successfully
2024-07-18 11:21:17,169:INFO:Starting cross validation
2024-07-18 11:21:17,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:22,255:INFO:Calculating mean and std
2024-07-18 11:21:22,255:INFO:Creating metrics dataframe
2024-07-18 11:21:22,650:INFO:Uploading results into container
2024-07-18 11:21:22,651:INFO:Uploading model into container now
2024-07-18 11:21:22,651:INFO:_master_model_container: 24
2024-07-18 11:21:22,651:INFO:_display_container: 3
2024-07-18 11:21:22,651:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1393)
2024-07-18 11:21:22,651:INFO:create_model() successfully completed......................................
2024-07-18 11:21:22,715:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:22,715:INFO:Creating metrics dataframe
2024-07-18 11:21:22,719:INFO:Initializing Gradient Boosting Classifier
2024-07-18 11:21:22,719:INFO:Total runtime is 0.7469325065612794 minutes
2024-07-18 11:21:22,719:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:22,719:INFO:Initializing create_model()
2024-07-18 11:21:22,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:22,719:INFO:Checking exceptions
2024-07-18 11:21:22,719:INFO:Importing libraries
2024-07-18 11:21:22,719:INFO:Copying training dataset
2024-07-18 11:21:22,725:INFO:Defining folds
2024-07-18 11:21:22,725:INFO:Declaring metric variables
2024-07-18 11:21:22,725:INFO:Importing untrained model
2024-07-18 11:21:22,725:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:21:22,725:INFO:Starting cross validation
2024-07-18 11:21:22,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:27,854:INFO:Calculating mean and std
2024-07-18 11:21:27,857:INFO:Creating metrics dataframe
2024-07-18 11:21:28,235:INFO:Uploading results into container
2024-07-18 11:21:28,235:INFO:Uploading model into container now
2024-07-18 11:21:28,235:INFO:_master_model_container: 25
2024-07-18 11:21:28,235:INFO:_display_container: 3
2024-07-18 11:21:28,245:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1393, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:21:28,245:INFO:create_model() successfully completed......................................
2024-07-18 11:21:28,304:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:28,304:INFO:Creating metrics dataframe
2024-07-18 11:21:28,304:INFO:Initializing Linear Discriminant Analysis
2024-07-18 11:21:28,304:INFO:Total runtime is 0.8400272250175477 minutes
2024-07-18 11:21:28,315:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:28,315:INFO:Initializing create_model()
2024-07-18 11:21:28,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:28,315:INFO:Checking exceptions
2024-07-18 11:21:28,315:INFO:Importing libraries
2024-07-18 11:21:28,315:INFO:Copying training dataset
2024-07-18 11:21:28,318:INFO:Defining folds
2024-07-18 11:21:28,318:INFO:Declaring metric variables
2024-07-18 11:21:28,319:INFO:Importing untrained model
2024-07-18 11:21:28,319:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:21:28,325:INFO:Starting cross validation
2024-07-18 11:21:28,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:32,557:INFO:Calculating mean and std
2024-07-18 11:21:32,557:INFO:Creating metrics dataframe
2024-07-18 11:21:32,955:INFO:Uploading results into container
2024-07-18 11:21:32,955:INFO:Uploading model into container now
2024-07-18 11:21:32,956:INFO:_master_model_container: 26
2024-07-18 11:21:32,956:INFO:_display_container: 3
2024-07-18 11:21:32,956:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:21:32,956:INFO:create_model() successfully completed......................................
2024-07-18 11:21:33,025:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:33,025:INFO:Creating metrics dataframe
2024-07-18 11:21:33,034:INFO:Initializing Extra Trees Classifier
2024-07-18 11:21:33,034:INFO:Total runtime is 0.9188622951507569 minutes
2024-07-18 11:21:33,035:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:33,035:INFO:Initializing create_model()
2024-07-18 11:21:33,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:33,035:INFO:Checking exceptions
2024-07-18 11:21:33,035:INFO:Importing libraries
2024-07-18 11:21:33,035:INFO:Copying training dataset
2024-07-18 11:21:33,035:INFO:Defining folds
2024-07-18 11:21:33,035:INFO:Declaring metric variables
2024-07-18 11:21:33,035:INFO:Importing untrained model
2024-07-18 11:21:33,035:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:21:33,044:INFO:Starting cross validation
2024-07-18 11:21:33,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:38,568:INFO:Calculating mean and std
2024-07-18 11:21:38,568:INFO:Creating metrics dataframe
2024-07-18 11:21:38,959:INFO:Uploading results into container
2024-07-18 11:21:38,959:INFO:Uploading model into container now
2024-07-18 11:21:38,959:INFO:_master_model_container: 27
2024-07-18 11:21:38,959:INFO:_display_container: 3
2024-07-18 11:21:38,959:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1393, verbose=0, warm_start=False)
2024-07-18 11:21:38,959:INFO:create_model() successfully completed......................................
2024-07-18 11:21:39,026:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:39,026:INFO:Creating metrics dataframe
2024-07-18 11:21:39,031:INFO:Initializing Extreme Gradient Boosting
2024-07-18 11:21:39,031:INFO:Total runtime is 1.0188082536061605 minutes
2024-07-18 11:21:39,034:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:39,034:INFO:Initializing create_model()
2024-07-18 11:21:39,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:39,034:INFO:Checking exceptions
2024-07-18 11:21:39,034:INFO:Importing libraries
2024-07-18 11:21:39,034:INFO:Copying training dataset
2024-07-18 11:21:39,035:INFO:Defining folds
2024-07-18 11:21:39,035:INFO:Declaring metric variables
2024-07-18 11:21:39,035:INFO:Importing untrained model
2024-07-18 11:21:39,040:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:21:39,044:INFO:Starting cross validation
2024-07-18 11:21:39,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:39,074:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:39,559:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:40,035:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:40] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:40,525:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:40] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:41,004:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:41] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:41,494:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:41] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:41,974:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:41] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:42,460:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:42] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:42,935:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:42] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:43,424:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:21:43] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:21:43,885:INFO:Calculating mean and std
2024-07-18 11:21:43,885:INFO:Creating metrics dataframe
2024-07-18 11:21:44,274:INFO:Uploading results into container
2024-07-18 11:21:44,274:INFO:Uploading model into container now
2024-07-18 11:21:44,274:INFO:_master_model_container: 28
2024-07-18 11:21:44,274:INFO:_display_container: 3
2024-07-18 11:21:44,274:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:21:44,274:INFO:create_model() successfully completed......................................
2024-07-18 11:21:44,335:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:44,335:INFO:Creating metrics dataframe
2024-07-18 11:21:44,344:INFO:Initializing Light Gradient Boosting Machine
2024-07-18 11:21:44,344:INFO:Total runtime is 1.1073590437571208 minutes
2024-07-18 11:21:44,344:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:44,344:INFO:Initializing create_model()
2024-07-18 11:21:44,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:44,344:INFO:Checking exceptions
2024-07-18 11:21:44,344:INFO:Importing libraries
2024-07-18 11:21:44,344:INFO:Copying training dataset
2024-07-18 11:21:44,344:INFO:Defining folds
2024-07-18 11:21:44,344:INFO:Declaring metric variables
2024-07-18 11:21:44,351:INFO:Importing untrained model
2024-07-18 11:21:44,352:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:21:44,354:INFO:Starting cross validation
2024-07-18 11:21:44,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:49,044:INFO:Calculating mean and std
2024-07-18 11:21:49,044:INFO:Creating metrics dataframe
2024-07-18 11:21:49,435:INFO:Uploading results into container
2024-07-18 11:21:49,435:INFO:Uploading model into container now
2024-07-18 11:21:49,435:INFO:_master_model_container: 29
2024-07-18 11:21:49,435:INFO:_display_container: 3
2024-07-18 11:21:49,435:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1393, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:21:49,435:INFO:create_model() successfully completed......................................
2024-07-18 11:21:49,494:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:49,494:INFO:Creating metrics dataframe
2024-07-18 11:21:49,504:INFO:Initializing CatBoost Classifier
2024-07-18 11:21:49,504:INFO:Total runtime is 1.1933552304903667 minutes
2024-07-18 11:21:49,504:INFO:SubProcess create_model() called ==================================
2024-07-18 11:21:49,504:INFO:Initializing create_model()
2024-07-18 11:21:49,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB806CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:49,504:INFO:Checking exceptions
2024-07-18 11:21:49,504:INFO:Importing libraries
2024-07-18 11:21:49,504:INFO:Copying training dataset
2024-07-18 11:21:49,504:INFO:Defining folds
2024-07-18 11:21:49,504:INFO:Declaring metric variables
2024-07-18 11:21:49,504:INFO:Importing untrained model
2024-07-18 11:21:49,514:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:21:49,517:INFO:Starting cross validation
2024-07-18 11:21:49,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:21:53,746:INFO:Calculating mean and std
2024-07-18 11:21:53,746:INFO:Creating metrics dataframe
2024-07-18 11:21:54,135:INFO:Uploading results into container
2024-07-18 11:21:54,135:INFO:Uploading model into container now
2024-07-18 11:21:54,135:INFO:_master_model_container: 30
2024-07-18 11:21:54,135:INFO:_display_container: 3
2024-07-18 11:21:54,135:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DB2038D50>
2024-07-18 11:21:54,135:INFO:create_model() successfully completed......................................
2024-07-18 11:21:54,199:INFO:SubProcess create_model() end ==================================
2024-07-18 11:21:54,199:INFO:Creating metrics dataframe
2024-07-18 11:21:54,204:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-18 11:21:54,204:INFO:Initializing create_model()
2024-07-18 11:21:54,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DA7927D10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1393, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:21:54,204:INFO:Checking exceptions
2024-07-18 11:21:54,204:INFO:Importing libraries
2024-07-18 11:21:54,204:INFO:Copying training dataset
2024-07-18 11:21:54,204:INFO:Defining folds
2024-07-18 11:21:54,204:INFO:Declaring metric variables
2024-07-18 11:21:54,204:INFO:Importing untrained model
2024-07-18 11:21:54,204:INFO:Declaring custom model
2024-07-18 11:21:54,204:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:21:54,204:INFO:Cross validation set to False
2024-07-18 11:21:54,204:INFO:Fitting Model
2024-07-18 11:21:54,636:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1393, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:21:54,636:INFO:create_model() successfully completed......................................
2024-07-18 11:21:54,718:INFO:_master_model_container: 30
2024-07-18 11:21:54,718:INFO:_display_container: 3
2024-07-18 11:21:54,718:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1393, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:21:54,718:INFO:compare_models() successfully completed......................................
2024-07-18 11:21:54,718:INFO:Initializing save_model()
2024-07-18 11:21:54,718:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=1393, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=GPU_1_EPPD_ML_VALIDATION_7525/LGBMClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:54,718:INFO:Adding model into prep_pipe
2024-07-18 11:21:54,724:INFO:GPU_1_EPPD_ML_VALIDATION_7525/LGBMClassifier.pkl saved in current working directory
2024-07-18 11:21:54,735:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, device='gpu',
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=20,
                                min_child_weight=0.001, min_split_gain=0.0,
                                n_estimators=100, n_jobs=-1, num_leaves=31,
                                objective=None, random_state=1393,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-18 11:21:54,735:INFO:save_model() successfully completed......................................
2024-07-18 11:21:55,204:INFO:Initializing save_model()
2024-07-18 11:21:55,204:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1393, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_7525/GradientBoostingClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:55,204:INFO:Adding model into prep_pipe
2024-07-18 11:21:55,209:INFO:GPU_1_EPPD_ML_VALIDATION_7525/GradientBoostingClassifier.pkl saved in current working directory
2024-07-18 11:21:55,209:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=1393, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:21:55,209:INFO:save_model() successfully completed......................................
2024-07-18 11:21:55,661:INFO:Initializing save_model()
2024-07-18 11:21:55,661:INFO:save_model(model=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), model_name=GPU_1_EPPD_ML_VALIDATION_7525/XGBClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:55,661:INFO:Adding model into prep_pipe
2024-07-18 11:21:55,668:INFO:GPU_1_EPPD_ML_VALIDATION_7525/XGBClassifier.pkl saved in current working directory
2024-07-18 11:21:55,674:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-07-18 11:21:55,674:INFO:save_model() successfully completed......................................
2024-07-18 11:21:56,149:INFO:Initializing save_model()
2024-07-18 11:21:56,149:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1393, verbose=0, warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_7525/ExtraTreesClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:56,149:INFO:Adding model into prep_pipe
2024-07-18 11:21:56,168:INFO:GPU_1_EPPD_ML_VALIDATION_7525/ExtraTreesClassifier.pkl saved in current working directory
2024-07-18 11:21:56,168:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=1393,
                                      verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:21:56,168:INFO:save_model() successfully completed......................................
2024-07-18 11:21:56,618:INFO:Initializing save_model()
2024-07-18 11:21:56,618:INFO:save_model(model=<catboost.core.CatBoostClassifier object at 0x0000021DB1EEA510>, model_name=GPU_1_EPPD_ML_VALIDATION_7525/CatBoostClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:56,618:INFO:Adding model into prep_pipe
2024-07-18 11:21:56,618:INFO:GPU_1_EPPD_ML_VALIDATION_7525/CatBoostClassifier.pkl saved in current working directory
2024-07-18 11:21:56,624:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x0000021DB1EEA510>)],
         verbose=False)
2024-07-18 11:21:56,624:INFO:save_model() successfully completed......................................
2024-07-18 11:21:57,074:INFO:Initializing save_model()
2024-07-18 11:21:57,074:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1393, splitter='best'), model_name=GPU_1_EPPD_ML_VALIDATION_7525/DecisionTreeClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:57,074:INFO:Adding model into prep_pipe
2024-07-18 11:21:57,074:INFO:GPU_1_EPPD_ML_VALIDATION_7525/DecisionTreeClassifier.pkl saved in current working directory
2024-07-18 11:21:57,074:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=1393, splitter='best'))],
         verbose=False)
2024-07-18 11:21:57,074:INFO:save_model() successfully completed......................................
2024-07-18 11:21:57,529:INFO:Initializing save_model()
2024-07-18 11:21:57,529:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1393, verbose=0, warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_7525/RandomForestClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:57,529:INFO:Adding model into prep_pipe
2024-07-18 11:21:57,549:INFO:GPU_1_EPPD_ML_VALIDATION_7525/RandomForestClassifier.pkl saved in current working directory
2024-07-18 11:21:57,551:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=1393,
                                        verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:21:57,551:INFO:save_model() successfully completed......................................
2024-07-18 11:21:58,001:INFO:Initializing save_model()
2024-07-18 11:21:58,001:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1393), model_name=GPU_1_EPPD_ML_VALIDATION_7525/AdaBoostClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:58,001:INFO:Adding model into prep_pipe
2024-07-18 11:21:58,004:INFO:GPU_1_EPPD_ML_VALIDATION_7525/AdaBoostClassifier.pkl saved in current working directory
2024-07-18 11:21:58,014:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=1393))],
         verbose=False)
2024-07-18 11:21:58,014:INFO:save_model() successfully completed......................................
2024-07-18 11:21:58,464:INFO:Initializing save_model()
2024-07-18 11:21:58,464:INFO:save_model(model=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), model_name=GPU_1_EPPD_ML_VALIDATION_7525/KNeighborsClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:58,464:INFO:Adding model into prep_pipe
2024-07-18 11:21:58,464:INFO:GPU_1_EPPD_ML_VALIDATION_7525/KNeighborsClassifier.pkl saved in current working directory
2024-07-18 11:21:58,468:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False)
2024-07-18 11:21:58,468:INFO:save_model() successfully completed......................................
2024-07-18 11:21:58,918:INFO:Initializing save_model()
2024-07-18 11:21:58,918:INFO:save_model(model=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), model_name=GPU_1_EPPD_ML_VALIDATION_7525/QuadraticDiscriminantAnalysis, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:58,918:INFO:Adding model into prep_pipe
2024-07-18 11:21:58,918:INFO:GPU_1_EPPD_ML_VALIDATION_7525/QuadraticDiscriminantAnalysis.pkl saved in current working directory
2024-07-18 11:21:58,918:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False)
2024-07-18 11:21:58,918:INFO:save_model() successfully completed......................................
2024-07-18 11:21:59,373:INFO:Initializing save_model()
2024-07-18 11:21:59,373:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=GPU_1_EPPD_ML_VALIDATION_7525/GaussianNB, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:59,373:INFO:Adding model into prep_pipe
2024-07-18 11:21:59,374:INFO:GPU_1_EPPD_ML_VALIDATION_7525/GaussianNB.pkl saved in current working directory
2024-07-18 11:21:59,377:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2024-07-18 11:21:59,377:INFO:save_model() successfully completed......................................
2024-07-18 11:21:59,824:INFO:Initializing save_model()
2024-07-18 11:21:59,824:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1393, solver='auto',
                tol=0.0001), model_name=GPU_1_EPPD_ML_VALIDATION_7525/RidgeClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:21:59,824:INFO:Adding model into prep_pipe
2024-07-18 11:21:59,824:INFO:GPU_1_EPPD_ML_VALIDATION_7525/RidgeClassifier.pkl saved in current working directory
2024-07-18 11:21:59,824:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=1393,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2024-07-18 11:21:59,824:INFO:save_model() successfully completed......................................
2024-07-18 11:22:00,285:INFO:Initializing save_model()
2024-07-18 11:22:00,285:INFO:save_model(model=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), model_name=GPU_1_EPPD_ML_VALIDATION_7525/LinearDiscriminantAnalysis, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:22:00,285:INFO:Adding model into prep_pipe
2024-07-18 11:22:00,285:INFO:GPU_1_EPPD_ML_VALIDATION_7525/LinearDiscriminantAnalysis.pkl saved in current working directory
2024-07-18 11:22:00,285:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2024-07-18 11:22:00,285:INFO:save_model() successfully completed......................................
2024-07-18 11:22:00,735:INFO:Initializing save_model()
2024-07-18 11:22:00,735:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1393, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_7525/LogisticRegression, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:22:00,735:INFO:Adding model into prep_pipe
2024-07-18 11:22:00,735:INFO:GPU_1_EPPD_ML_VALIDATION_7525/LogisticRegression.pkl saved in current working directory
2024-07-18 11:22:00,744:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1393,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-07-18 11:22:00,744:INFO:save_model() successfully completed......................................
2024-07-18 11:22:01,194:INFO:Initializing save_model()
2024-07-18 11:22:01,194:INFO:save_model(model=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1393, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_7525/SGDClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:22:01,194:INFO:Adding model into prep_pipe
2024-07-18 11:22:01,199:INFO:GPU_1_EPPD_ML_VALIDATION_7525/SGDClassifier.pkl saved in current working directory
2024-07-18 11:22:01,201:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=1393,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:22:01,201:INFO:save_model() successfully completed......................................
2024-07-18 11:22:01,651:WARNING:C:\Users\JAL\AppData\Local\Temp\ipykernel_17160\2873217847.py:105: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  best_model[best_model.select_dtypes(include=['number']).columns] *= 100

2024-07-18 11:22:02,435:INFO:PyCaret ClassificationExperiment
2024-07-18 11:22:02,435:INFO:Logging name: clf-default-name
2024-07-18 11:22:02,435:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-18 11:22:02,435:INFO:version 3.0.0
2024-07-18 11:22:02,435:INFO:Initializing setup()
2024-07-18 11:22:02,435:INFO:self.USI: 87c4
2024-07-18 11:22:02,435:INFO:self._variable_keys: {'n_jobs_param', 'fix_imbalance', 'exp_id', 'y_test', 'is_multiclass', '_ml_usecase', 'html_param', 'target_param', 'USI', 'gpu_param', 'log_plots_param', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'fold_generator', 'logging_param', 'y_train', 'fold_groups_param', 'seed', 'idx', 'X_test', 'X', 'data', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'y'}
2024-07-18 11:22:02,435:INFO:Checking environment
2024-07-18 11:22:02,435:INFO:python_version: 3.11.4
2024-07-18 11:22:02,435:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2024-07-18 11:22:02,435:INFO:machine: AMD64
2024-07-18 11:22:02,435:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-18 11:22:02,435:INFO:Memory: svmem(total=68659781632, available=52874829824, percent=23.0, used=15784951808, free=52874829824)
2024-07-18 11:22:02,435:INFO:Physical Core: 16
2024-07-18 11:22:02,435:INFO:Logical Core: 32
2024-07-18 11:22:02,435:INFO:Checking libraries
2024-07-18 11:22:02,435:INFO:System:
2024-07-18 11:22:02,435:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2024-07-18 11:22:02,435:INFO:executable: c:\Users\JAL\AppData\Local\Programs\Python\Python311\python.exe
2024-07-18 11:22:02,435:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-18 11:22:02,435:INFO:PyCaret required dependencies:
2024-07-18 11:22:02,435:INFO:                 pip: 24.1.2
2024-07-18 11:22:02,435:INFO:          setuptools: 70.3.0
2024-07-18 11:22:02,435:INFO:             pycaret: 3.0.0
2024-07-18 11:22:02,435:INFO:             IPython: 8.15.0
2024-07-18 11:22:02,435:INFO:          ipywidgets: 8.1.3
2024-07-18 11:22:02,444:INFO:                tqdm: 4.66.4
2024-07-18 11:22:02,444:INFO:               numpy: 1.24.4
2024-07-18 11:22:02,444:INFO:              pandas: 2.2.2
2024-07-18 11:22:02,444:INFO:              jinja2: 3.1.4
2024-07-18 11:22:02,444:INFO:               scipy: 1.11.4
2024-07-18 11:22:02,444:INFO:              joblib: 1.3.2
2024-07-18 11:22:02,444:INFO:             sklearn: 1.3.0
2024-07-18 11:22:02,444:INFO:                pyod: 2.0.1
2024-07-18 11:22:02,444:INFO:            imblearn: 0.12.3
2024-07-18 11:22:02,444:INFO:   category_encoders: 2.6.3
2024-07-18 11:22:02,444:INFO:            lightgbm: 4.3.0
2024-07-18 11:22:02,444:INFO:               numba: 0.60.0
2024-07-18 11:22:02,444:INFO:            requests: 2.32.3
2024-07-18 11:22:02,444:INFO:          matplotlib: 3.7.5
2024-07-18 11:22:02,444:INFO:          scikitplot: 0.3.7
2024-07-18 11:22:02,444:INFO:         yellowbrick: 1.5
2024-07-18 11:22:02,444:INFO:              plotly: 5.22.0
2024-07-18 11:22:02,444:INFO:             kaleido: 0.2.1
2024-07-18 11:22:02,444:INFO:         statsmodels: 0.14.2
2024-07-18 11:22:02,444:INFO:              sktime: 0.26.0
2024-07-18 11:22:02,444:INFO:               tbats: 1.1.3
2024-07-18 11:22:02,444:INFO:            pmdarima: 2.0.4
2024-07-18 11:22:02,444:INFO:              psutil: 5.9.5
2024-07-18 11:22:02,444:INFO:PyCaret optional dependencies:
2024-07-18 11:22:02,444:INFO:                shap: Not installed
2024-07-18 11:22:02,444:INFO:           interpret: Not installed
2024-07-18 11:22:02,444:INFO:                umap: Not installed
2024-07-18 11:22:02,444:INFO:    pandas_profiling: Not installed
2024-07-18 11:22:02,444:INFO:  explainerdashboard: Not installed
2024-07-18 11:22:02,444:INFO:             autoviz: Not installed
2024-07-18 11:22:02,444:INFO:           fairlearn: Not installed
2024-07-18 11:22:02,444:INFO:             xgboost: 2.0.3
2024-07-18 11:22:02,444:INFO:            catboost: 1.2.5
2024-07-18 11:22:02,444:INFO:              kmodes: Not installed
2024-07-18 11:22:02,444:INFO:             mlxtend: Not installed
2024-07-18 11:22:02,444:INFO:       statsforecast: 1.4.0
2024-07-18 11:22:02,444:INFO:        tune_sklearn: Not installed
2024-07-18 11:22:02,444:INFO:                 ray: 2.10.0
2024-07-18 11:22:02,444:INFO:            hyperopt: 0.2.7
2024-07-18 11:22:02,444:INFO:              optuna: Not installed
2024-07-18 11:22:02,444:INFO:               skopt: Not installed
2024-07-18 11:22:02,444:INFO:              mlflow: Not installed
2024-07-18 11:22:02,444:INFO:              gradio: Not installed
2024-07-18 11:22:02,444:INFO:             fastapi: Not installed
2024-07-18 11:22:02,444:INFO:             uvicorn: Not installed
2024-07-18 11:22:02,444:INFO:              m2cgen: Not installed
2024-07-18 11:22:02,444:INFO:           evidently: Not installed
2024-07-18 11:22:02,444:INFO:               fugue: Not installed
2024-07-18 11:22:02,444:INFO:           streamlit: 1.31.0
2024-07-18 11:22:02,444:INFO:             prophet: Not installed
2024-07-18 11:22:02,444:INFO:None
2024-07-18 11:22:02,444:INFO:Set up GPU usage.
2024-07-18 11:22:02,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,444:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0
2024-07-18 11:22:02,444:INFO:Set up data.
2024-07-18 11:22:02,444:INFO:Set up train/test split.
2024-07-18 11:22:02,444:INFO:Set up index.
2024-07-18 11:22:02,444:INFO:Set up folding strategy.
2024-07-18 11:22:02,444:INFO:Assigning column types.
2024-07-18 11:22:02,450:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-18 11:22:02,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 11:22:02,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:22:02,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,501:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:22:02,618:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:22:02,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,664:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 11:22:02,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,664:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:22:02,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,685:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:22:02,785:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:22:02,785:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-18 11:22:02,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,816:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:22:02,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,835:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:22:02,935:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:22:02,935:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,968:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:22:02,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:02,985:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:22:03,096:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:22:03,096:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-18 11:22:03,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,178:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:22:03,296:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:22:03,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,371:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:22:03,478:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:22:03,479:INFO:Preparing preprocessing pipeline...
2024-07-18 11:22:03,480:INFO:Set up simple imputation.
2024-07-18 11:22:03,486:INFO:Finished creating preprocessing pipeline.
2024-07-18 11:22:03,494:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-18 11:22:03,494:INFO:Creating final display dataframe.
2024-07-18 11:22:03,524:INFO:Setup _display_container:                     Description             Value
0                    Session id              2656
1                        Target       PlacedOrNot
2                   Target type            Binary
3           Original data shape         (2966, 4)
4        Transformed data shape         (2966, 4)
5   Transformed train set shape         (2076, 4)
6    Transformed test set shape          (890, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              87c4
2024-07-18 11:22:03,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,594:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:22:03,696:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:22:03,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-18 11:22:03,754:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:22:03,854:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:22:03,854:INFO:setup() successfully completed in 1.82s...............
2024-07-18 11:22:03,854:INFO:Initializing compare_models()
2024-07-18 11:22:03,854:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-18 11:22:03,854:INFO:Checking exceptions
2024-07-18 11:22:03,854:INFO:Preparing display monitor
2024-07-18 11:22:03,874:INFO:Initializing Logistic Regression
2024-07-18 11:22:03,874:INFO:Total runtime is 0.0 minutes
2024-07-18 11:22:03,876:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:03,877:INFO:Initializing create_model()
2024-07-18 11:22:03,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:03,877:INFO:Checking exceptions
2024-07-18 11:22:03,877:INFO:Importing libraries
2024-07-18 11:22:03,877:INFO:Copying training dataset
2024-07-18 11:22:03,880:INFO:Defining folds
2024-07-18 11:22:03,880:INFO:Declaring metric variables
2024-07-18 11:22:03,882:INFO:Importing untrained model
2024-07-18 11:22:03,885:INFO:Logistic Regression Imported successfully
2024-07-18 11:22:03,885:INFO:Starting cross validation
2024-07-18 11:22:03,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:08,224:INFO:Calculating mean and std
2024-07-18 11:22:08,224:INFO:Creating metrics dataframe
2024-07-18 11:22:08,622:INFO:Uploading results into container
2024-07-18 11:22:08,623:INFO:Uploading model into container now
2024-07-18 11:22:08,623:INFO:_master_model_container: 1
2024-07-18 11:22:08,623:INFO:_display_container: 2
2024-07-18 11:22:08,624:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2656, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:22:08,624:INFO:create_model() successfully completed......................................
2024-07-18 11:22:08,687:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:08,687:INFO:Creating metrics dataframe
2024-07-18 11:22:08,691:INFO:Initializing K Neighbors Classifier
2024-07-18 11:22:08,691:INFO:Total runtime is 0.08026752869288127 minutes
2024-07-18 11:22:08,693:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:08,693:INFO:Initializing create_model()
2024-07-18 11:22:08,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:08,693:INFO:Checking exceptions
2024-07-18 11:22:08,693:INFO:Importing libraries
2024-07-18 11:22:08,693:INFO:Copying training dataset
2024-07-18 11:22:08,694:INFO:Defining folds
2024-07-18 11:22:08,695:INFO:Declaring metric variables
2024-07-18 11:22:08,696:INFO:Importing untrained model
2024-07-18 11:22:08,698:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:22:08,701:INFO:Starting cross validation
2024-07-18 11:22:08,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:13,284:INFO:Calculating mean and std
2024-07-18 11:22:13,286:INFO:Creating metrics dataframe
2024-07-18 11:22:13,673:INFO:Uploading results into container
2024-07-18 11:22:13,673:INFO:Uploading model into container now
2024-07-18 11:22:13,674:INFO:_master_model_container: 2
2024-07-18 11:22:13,674:INFO:_display_container: 2
2024-07-18 11:22:13,674:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:22:13,674:INFO:create_model() successfully completed......................................
2024-07-18 11:22:13,736:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:13,737:INFO:Creating metrics dataframe
2024-07-18 11:22:13,741:INFO:Initializing Naive Bayes
2024-07-18 11:22:13,741:INFO:Total runtime is 0.16443560123443604 minutes
2024-07-18 11:22:13,743:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:13,743:INFO:Initializing create_model()
2024-07-18 11:22:13,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:13,743:INFO:Checking exceptions
2024-07-18 11:22:13,743:INFO:Importing libraries
2024-07-18 11:22:13,743:INFO:Copying training dataset
2024-07-18 11:22:13,744:INFO:Defining folds
2024-07-18 11:22:13,744:INFO:Declaring metric variables
2024-07-18 11:22:13,746:INFO:Importing untrained model
2024-07-18 11:22:13,748:INFO:Naive Bayes Imported successfully
2024-07-18 11:22:13,751:INFO:Starting cross validation
2024-07-18 11:22:13,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:17,874:INFO:Calculating mean and std
2024-07-18 11:22:17,874:INFO:Creating metrics dataframe
2024-07-18 11:22:18,254:INFO:Uploading results into container
2024-07-18 11:22:18,254:INFO:Uploading model into container now
2024-07-18 11:22:18,255:INFO:_master_model_container: 3
2024-07-18 11:22:18,255:INFO:_display_container: 2
2024-07-18 11:22:18,255:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:22:18,255:INFO:create_model() successfully completed......................................
2024-07-18 11:22:18,314:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:18,314:INFO:Creating metrics dataframe
2024-07-18 11:22:18,318:INFO:Initializing Decision Tree Classifier
2024-07-18 11:22:18,318:INFO:Total runtime is 0.2407297412554423 minutes
2024-07-18 11:22:18,318:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:18,318:INFO:Initializing create_model()
2024-07-18 11:22:18,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:18,318:INFO:Checking exceptions
2024-07-18 11:22:18,318:INFO:Importing libraries
2024-07-18 11:22:18,318:INFO:Copying training dataset
2024-07-18 11:22:18,318:INFO:Defining folds
2024-07-18 11:22:18,318:INFO:Declaring metric variables
2024-07-18 11:22:18,324:INFO:Importing untrained model
2024-07-18 11:22:18,324:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:22:18,324:INFO:Starting cross validation
2024-07-18 11:22:18,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:22,320:INFO:Calculating mean and std
2024-07-18 11:22:22,324:INFO:Creating metrics dataframe
2024-07-18 11:22:22,719:INFO:Uploading results into container
2024-07-18 11:22:22,719:INFO:Uploading model into container now
2024-07-18 11:22:22,719:INFO:_master_model_container: 4
2024-07-18 11:22:22,719:INFO:_display_container: 2
2024-07-18 11:22:22,723:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2656, splitter='best')
2024-07-18 11:22:22,723:INFO:create_model() successfully completed......................................
2024-07-18 11:22:22,785:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:22,785:INFO:Creating metrics dataframe
2024-07-18 11:22:22,794:INFO:Initializing SVM - Linear Kernel
2024-07-18 11:22:22,794:INFO:Total runtime is 0.3153305689493815 minutes
2024-07-18 11:22:22,794:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:22,794:INFO:Initializing create_model()
2024-07-18 11:22:22,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:22,794:INFO:Checking exceptions
2024-07-18 11:22:22,794:INFO:Importing libraries
2024-07-18 11:22:22,794:INFO:Copying training dataset
2024-07-18 11:22:22,801:INFO:Defining folds
2024-07-18 11:22:22,801:INFO:Declaring metric variables
2024-07-18 11:22:22,802:INFO:Importing untrained model
2024-07-18 11:22:22,804:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:22:22,804:INFO:Starting cross validation
2024-07-18 11:22:22,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:22,824:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:23,227:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:23,617:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:24,014:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:24,404:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:24,794:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:25,186:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:25,584:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:25,976:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:26,364:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:26,734:INFO:Calculating mean and std
2024-07-18 11:22:26,734:INFO:Creating metrics dataframe
2024-07-18 11:22:27,104:INFO:Uploading results into container
2024-07-18 11:22:27,104:INFO:Uploading model into container now
2024-07-18 11:22:27,104:INFO:_master_model_container: 5
2024-07-18 11:22:27,104:INFO:_display_container: 2
2024-07-18 11:22:27,104:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2656, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:22:27,104:INFO:create_model() successfully completed......................................
2024-07-18 11:22:27,163:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:27,163:INFO:Creating metrics dataframe
2024-07-18 11:22:27,170:INFO:Initializing Ridge Classifier
2024-07-18 11:22:27,170:INFO:Total runtime is 0.3882622838020324 minutes
2024-07-18 11:22:27,174:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:27,174:INFO:Initializing create_model()
2024-07-18 11:22:27,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:27,174:INFO:Checking exceptions
2024-07-18 11:22:27,174:INFO:Importing libraries
2024-07-18 11:22:27,174:INFO:Copying training dataset
2024-07-18 11:22:27,177:INFO:Defining folds
2024-07-18 11:22:27,177:INFO:Declaring metric variables
2024-07-18 11:22:27,179:INFO:Importing untrained model
2024-07-18 11:22:27,181:INFO:Ridge Classifier Imported successfully
2024-07-18 11:22:27,184:INFO:Starting cross validation
2024-07-18 11:22:27,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:27,204:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:27,599:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:28,003:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:28,418:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:28,824:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:29,234:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:29,653:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:30,068:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:30,477:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:30,885:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:22:31,273:INFO:Calculating mean and std
2024-07-18 11:22:31,273:INFO:Creating metrics dataframe
2024-07-18 11:22:31,667:INFO:Uploading results into container
2024-07-18 11:22:31,667:INFO:Uploading model into container now
2024-07-18 11:22:31,667:INFO:_master_model_container: 6
2024-07-18 11:22:31,667:INFO:_display_container: 2
2024-07-18 11:22:31,667:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2656, solver='auto',
                tol=0.0001)
2024-07-18 11:22:31,667:INFO:create_model() successfully completed......................................
2024-07-18 11:22:31,734:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:31,734:INFO:Creating metrics dataframe
2024-07-18 11:22:31,739:INFO:Initializing Random Forest Classifier
2024-07-18 11:22:31,739:INFO:Total runtime is 0.46440482934315996 minutes
2024-07-18 11:22:31,742:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:31,742:INFO:Initializing create_model()
2024-07-18 11:22:31,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:31,742:INFO:Checking exceptions
2024-07-18 11:22:31,742:INFO:Importing libraries
2024-07-18 11:22:31,742:INFO:Copying training dataset
2024-07-18 11:22:31,744:INFO:Defining folds
2024-07-18 11:22:31,744:INFO:Declaring metric variables
2024-07-18 11:22:31,745:INFO:Importing untrained model
2024-07-18 11:22:31,747:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:22:31,751:INFO:Starting cross validation
2024-07-18 11:22:31,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:37,967:INFO:Calculating mean and std
2024-07-18 11:22:37,967:INFO:Creating metrics dataframe
2024-07-18 11:22:38,360:INFO:Uploading results into container
2024-07-18 11:22:38,361:INFO:Uploading model into container now
2024-07-18 11:22:38,361:INFO:_master_model_container: 7
2024-07-18 11:22:38,362:INFO:_display_container: 2
2024-07-18 11:22:38,362:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2656, verbose=0, warm_start=False)
2024-07-18 11:22:38,362:INFO:create_model() successfully completed......................................
2024-07-18 11:22:38,424:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:38,424:INFO:Creating metrics dataframe
2024-07-18 11:22:38,429:INFO:Initializing Quadratic Discriminant Analysis
2024-07-18 11:22:38,429:INFO:Total runtime is 0.5759072820345561 minutes
2024-07-18 11:22:38,431:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:38,431:INFO:Initializing create_model()
2024-07-18 11:22:38,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:38,431:INFO:Checking exceptions
2024-07-18 11:22:38,432:INFO:Importing libraries
2024-07-18 11:22:38,432:INFO:Copying training dataset
2024-07-18 11:22:38,433:INFO:Defining folds
2024-07-18 11:22:38,433:INFO:Declaring metric variables
2024-07-18 11:22:38,434:INFO:Importing untrained model
2024-07-18 11:22:38,434:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:22:38,439:INFO:Starting cross validation
2024-07-18 11:22:38,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:42,628:INFO:Calculating mean and std
2024-07-18 11:22:42,629:INFO:Creating metrics dataframe
2024-07-18 11:22:43,024:INFO:Uploading results into container
2024-07-18 11:22:43,024:INFO:Uploading model into container now
2024-07-18 11:22:43,024:INFO:_master_model_container: 8
2024-07-18 11:22:43,025:INFO:_display_container: 2
2024-07-18 11:22:43,025:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:22:43,025:INFO:create_model() successfully completed......................................
2024-07-18 11:22:43,084:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:43,084:INFO:Creating metrics dataframe
2024-07-18 11:22:43,093:INFO:Initializing Ada Boost Classifier
2024-07-18 11:22:43,093:INFO:Total runtime is 0.6536486784617106 minutes
2024-07-18 11:22:43,093:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:43,099:INFO:Initializing create_model()
2024-07-18 11:22:43,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:43,099:INFO:Checking exceptions
2024-07-18 11:22:43,099:INFO:Importing libraries
2024-07-18 11:22:43,099:INFO:Copying training dataset
2024-07-18 11:22:43,101:INFO:Defining folds
2024-07-18 11:22:43,101:INFO:Declaring metric variables
2024-07-18 11:22:43,103:INFO:Importing untrained model
2024-07-18 11:22:43,104:INFO:Ada Boost Classifier Imported successfully
2024-07-18 11:22:43,109:INFO:Starting cross validation
2024-07-18 11:22:43,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:48,189:INFO:Calculating mean and std
2024-07-18 11:22:48,190:INFO:Creating metrics dataframe
2024-07-18 11:22:48,583:INFO:Uploading results into container
2024-07-18 11:22:48,585:INFO:Uploading model into container now
2024-07-18 11:22:48,585:INFO:_master_model_container: 9
2024-07-18 11:22:48,585:INFO:_display_container: 2
2024-07-18 11:22:48,585:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2656)
2024-07-18 11:22:48,585:INFO:create_model() successfully completed......................................
2024-07-18 11:22:48,653:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:48,653:INFO:Creating metrics dataframe
2024-07-18 11:22:48,659:INFO:Initializing Gradient Boosting Classifier
2024-07-18 11:22:48,659:INFO:Total runtime is 0.7464106996854146 minutes
2024-07-18 11:22:48,661:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:48,661:INFO:Initializing create_model()
2024-07-18 11:22:48,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:48,662:INFO:Checking exceptions
2024-07-18 11:22:48,662:INFO:Importing libraries
2024-07-18 11:22:48,662:INFO:Copying training dataset
2024-07-18 11:22:48,663:INFO:Defining folds
2024-07-18 11:22:48,663:INFO:Declaring metric variables
2024-07-18 11:22:48,663:INFO:Importing untrained model
2024-07-18 11:22:48,663:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:22:48,670:INFO:Starting cross validation
2024-07-18 11:22:48,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:53,888:INFO:Calculating mean and std
2024-07-18 11:22:53,889:INFO:Creating metrics dataframe
2024-07-18 11:22:54,278:INFO:Uploading results into container
2024-07-18 11:22:54,278:INFO:Uploading model into container now
2024-07-18 11:22:54,278:INFO:_master_model_container: 10
2024-07-18 11:22:54,278:INFO:_display_container: 2
2024-07-18 11:22:54,278:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2656, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:22:54,278:INFO:create_model() successfully completed......................................
2024-07-18 11:22:54,338:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:54,343:INFO:Creating metrics dataframe
2024-07-18 11:22:54,344:INFO:Initializing Linear Discriminant Analysis
2024-07-18 11:22:54,344:INFO:Total runtime is 0.8411652366320292 minutes
2024-07-18 11:22:54,351:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:54,351:INFO:Initializing create_model()
2024-07-18 11:22:54,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:54,351:INFO:Checking exceptions
2024-07-18 11:22:54,351:INFO:Importing libraries
2024-07-18 11:22:54,351:INFO:Copying training dataset
2024-07-18 11:22:54,353:INFO:Defining folds
2024-07-18 11:22:54,353:INFO:Declaring metric variables
2024-07-18 11:22:54,353:INFO:Importing untrained model
2024-07-18 11:22:54,353:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:22:54,353:INFO:Starting cross validation
2024-07-18 11:22:54,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:22:58,546:INFO:Calculating mean and std
2024-07-18 11:22:58,546:INFO:Creating metrics dataframe
2024-07-18 11:22:58,938:INFO:Uploading results into container
2024-07-18 11:22:58,938:INFO:Uploading model into container now
2024-07-18 11:22:58,938:INFO:_master_model_container: 11
2024-07-18 11:22:58,938:INFO:_display_container: 2
2024-07-18 11:22:58,938:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:22:58,938:INFO:create_model() successfully completed......................................
2024-07-18 11:22:59,008:INFO:SubProcess create_model() end ==================================
2024-07-18 11:22:59,008:INFO:Creating metrics dataframe
2024-07-18 11:22:59,013:INFO:Initializing Extra Trees Classifier
2024-07-18 11:22:59,013:INFO:Total runtime is 0.9189752221107483 minutes
2024-07-18 11:22:59,016:INFO:SubProcess create_model() called ==================================
2024-07-18 11:22:59,016:INFO:Initializing create_model()
2024-07-18 11:22:59,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:22:59,016:INFO:Checking exceptions
2024-07-18 11:22:59,016:INFO:Importing libraries
2024-07-18 11:22:59,016:INFO:Copying training dataset
2024-07-18 11:22:59,017:INFO:Defining folds
2024-07-18 11:22:59,017:INFO:Declaring metric variables
2024-07-18 11:22:59,017:INFO:Importing untrained model
2024-07-18 11:22:59,017:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:22:59,023:INFO:Starting cross validation
2024-07-18 11:22:59,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:23:04,828:INFO:Calculating mean and std
2024-07-18 11:23:04,833:INFO:Creating metrics dataframe
2024-07-18 11:23:05,223:INFO:Uploading results into container
2024-07-18 11:23:05,228:INFO:Uploading model into container now
2024-07-18 11:23:05,228:INFO:_master_model_container: 12
2024-07-18 11:23:05,228:INFO:_display_container: 2
2024-07-18 11:23:05,228:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2656, verbose=0, warm_start=False)
2024-07-18 11:23:05,228:INFO:create_model() successfully completed......................................
2024-07-18 11:23:05,293:INFO:SubProcess create_model() end ==================================
2024-07-18 11:23:05,293:INFO:Creating metrics dataframe
2024-07-18 11:23:05,293:INFO:Initializing Extreme Gradient Boosting
2024-07-18 11:23:05,293:INFO:Total runtime is 1.0236460129419962 minutes
2024-07-18 11:23:05,301:INFO:SubProcess create_model() called ==================================
2024-07-18 11:23:05,301:INFO:Initializing create_model()
2024-07-18 11:23:05,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:23:05,301:INFO:Checking exceptions
2024-07-18 11:23:05,301:INFO:Importing libraries
2024-07-18 11:23:05,301:INFO:Copying training dataset
2024-07-18 11:23:05,303:INFO:Defining folds
2024-07-18 11:23:05,303:INFO:Declaring metric variables
2024-07-18 11:23:05,303:INFO:Importing untrained model
2024-07-18 11:23:05,308:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:23:05,308:INFO:Starting cross validation
2024-07-18 11:23:05,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:23:05,547:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:05] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:06,284:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:06] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:07,068:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:07] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:07,853:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:07] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:08,584:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:08] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:09,303:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:09] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:10,017:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:10] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:10,784:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:10] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:11,537:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:11] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:12,293:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:23:12] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:23:12,763:INFO:Calculating mean and std
2024-07-18 11:23:12,763:INFO:Creating metrics dataframe
2024-07-18 11:23:13,158:INFO:Uploading results into container
2024-07-18 11:23:13,158:INFO:Uploading model into container now
2024-07-18 11:23:13,158:INFO:_master_model_container: 13
2024-07-18 11:23:13,158:INFO:_display_container: 2
2024-07-18 11:23:13,158:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:23:13,158:INFO:create_model() successfully completed......................................
2024-07-18 11:23:13,223:INFO:SubProcess create_model() end ==================================
2024-07-18 11:23:13,223:INFO:Creating metrics dataframe
2024-07-18 11:23:13,228:INFO:Initializing Light Gradient Boosting Machine
2024-07-18 11:23:13,228:INFO:Total runtime is 1.1558912197748819 minutes
2024-07-18 11:23:13,228:INFO:SubProcess create_model() called ==================================
2024-07-18 11:23:13,228:INFO:Initializing create_model()
2024-07-18 11:23:13,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:23:13,228:INFO:Checking exceptions
2024-07-18 11:23:13,228:INFO:Importing libraries
2024-07-18 11:23:13,228:INFO:Copying training dataset
2024-07-18 11:23:13,234:INFO:Defining folds
2024-07-18 11:23:13,234:INFO:Declaring metric variables
2024-07-18 11:23:13,234:INFO:Importing untrained model
2024-07-18 11:23:13,234:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:23:13,234:INFO:Starting cross validation
2024-07-18 11:23:13,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:23:13,253:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-18 11:23:13,253:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:13,253:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:23:13,253:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 3
2024-07-18 11:23:13,338:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:13,338:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:13,348:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:13,350:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:13,350:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000408 secs. 0 sparse feature groups
2024-07-18 11:23:13,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-18 11:23:13,350:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-18 11:23:13,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:13,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,393:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-18 11:23:14,393:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:14,393:INFO:[LightGBM] [Info] Total Bins 19
2024-07-18 11:23:14,393:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 3
2024-07-18 11:23:14,467:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:14,467:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:14,473:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:14,478:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:14,478:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000412 secs. 0 sparse feature groups
2024-07-18 11:23:14,478:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-18 11:23:14,478:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-18 11:23:14,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:14,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,528:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-18 11:23:15,528:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:15,528:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:23:15,528:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 3
2024-07-18 11:23:15,603:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:15,603:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:15,613:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:15,614:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:15,614:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000394 secs. 0 sparse feature groups
2024-07-18 11:23:15,615:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-18 11:23:15,615:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-18 11:23:15,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:15,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:16,643:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-18 11:23:16,643:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:16,643:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:23:16,643:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 3
2024-07-18 11:23:16,717:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:16,717:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:16,723:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:16,728:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:16,728:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000401 secs. 0 sparse feature groups
2024-07-18 11:23:16,728:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-18 11:23:16,728:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-18 11:23:17,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,778:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-18 11:23:17,778:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:17,778:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:23:17,778:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 3
2024-07-18 11:23:17,854:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:17,854:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:17,863:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:17,866:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:17,866:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000399 secs. 0 sparse feature groups
2024-07-18 11:23:17,867:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-18 11:23:17,867:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-18 11:23:17,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:17,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:18,923:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 836
2024-07-18 11:23:18,923:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:18,923:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:23:18,923:INFO:[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 3
2024-07-18 11:23:19,000:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:19,000:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:19,008:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:19,008:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:19,008:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000417 secs. 0 sparse feature groups
2024-07-18 11:23:19,008:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552463 -> initscore=0.210625
2024-07-18 11:23:19,008:INFO:[LightGBM] [Info] Start training from score 0.210625
2024-07-18 11:23:19,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:19,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,078:INFO:[LightGBM] [Info] Number of positive: 1033, number of negative: 836
2024-07-18 11:23:20,078:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:20,078:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:23:20,078:INFO:[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 3
2024-07-18 11:23:20,154:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:20,155:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:20,163:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:20,165:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:20,166:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000521 secs. 0 sparse feature groups
2024-07-18 11:23:20,166:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552702 -> initscore=0.211594
2024-07-18 11:23:20,166:INFO:[LightGBM] [Info] Start training from score 0.211594
2024-07-18 11:23:20,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:20,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,233:INFO:[LightGBM] [Info] Number of positive: 1033, number of negative: 836
2024-07-18 11:23:21,233:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:21,233:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:23:21,233:INFO:[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 3
2024-07-18 11:23:21,308:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:21,308:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:21,317:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:21,317:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:21,317:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000402 secs. 0 sparse feature groups
2024-07-18 11:23:21,317:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552702 -> initscore=0.211594
2024-07-18 11:23:21,317:INFO:[LightGBM] [Info] Start training from score 0.211594
2024-07-18 11:23:21,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:21,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,373:INFO:[LightGBM] [Info] Number of positive: 1033, number of negative: 836
2024-07-18 11:23:22,373:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:22,373:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:23:22,373:INFO:[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 3
2024-07-18 11:23:22,443:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:22,443:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:22,454:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:22,454:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:22,454:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000404 secs. 0 sparse feature groups
2024-07-18 11:23:22,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552702 -> initscore=0.211594
2024-07-18 11:23:22,454:INFO:[LightGBM] [Info] Start training from score 0.211594
2024-07-18 11:23:22,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:22,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,513:INFO:[LightGBM] [Info] Number of positive: 1032, number of negative: 837
2024-07-18 11:23:23,513:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:23:23,513:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:23:23,513:INFO:[LightGBM] [Info] Number of data points in the train set: 1869, number of used features: 3
2024-07-18 11:23:23,588:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:23:23,588:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:23:23,593:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:23:23,593:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:23:23,599:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000410 secs. 0 sparse feature groups
2024-07-18 11:23:23,600:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552167 -> initscore=0.209430
2024-07-18 11:23:23,600:INFO:[LightGBM] [Info] Start training from score 0.209430
2024-07-18 11:23:23,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:23,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:23:24,628:INFO:Calculating mean and std
2024-07-18 11:23:24,628:INFO:Creating metrics dataframe
2024-07-18 11:23:25,028:INFO:Uploading results into container
2024-07-18 11:23:25,028:INFO:Uploading model into container now
2024-07-18 11:23:25,028:INFO:_master_model_container: 14
2024-07-18 11:23:25,028:INFO:_display_container: 2
2024-07-18 11:23:25,028:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=2656, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:23:25,028:INFO:create_model() successfully completed......................................
2024-07-18 11:23:25,093:INFO:SubProcess create_model() end ==================================
2024-07-18 11:23:25,093:INFO:Creating metrics dataframe
2024-07-18 11:23:25,100:INFO:Initializing CatBoost Classifier
2024-07-18 11:23:25,100:INFO:Total runtime is 1.353757325808207 minutes
2024-07-18 11:23:25,103:INFO:SubProcess create_model() called ==================================
2024-07-18 11:23:25,103:INFO:Initializing create_model()
2024-07-18 11:23:25,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1EB9050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:23:25,103:INFO:Checking exceptions
2024-07-18 11:23:25,103:INFO:Importing libraries
2024-07-18 11:23:25,103:INFO:Copying training dataset
2024-07-18 11:23:25,103:INFO:Defining folds
2024-07-18 11:23:25,103:INFO:Declaring metric variables
2024-07-18 11:23:25,103:INFO:Importing untrained model
2024-07-18 11:23:25,103:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:23:25,112:INFO:Starting cross validation
2024-07-18 11:23:25,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:27:10,088:INFO:Calculating mean and std
2024-07-18 11:27:10,089:INFO:Creating metrics dataframe
2024-07-18 11:27:10,489:INFO:Uploading results into container
2024-07-18 11:27:10,489:INFO:Uploading model into container now
2024-07-18 11:27:10,490:INFO:_master_model_container: 15
2024-07-18 11:27:10,490:INFO:_display_container: 2
2024-07-18 11:27:10,490:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DAB806510>
2024-07-18 11:27:10,490:INFO:create_model() successfully completed......................................
2024-07-18 11:27:10,558:INFO:SubProcess create_model() end ==================================
2024-07-18 11:27:10,558:INFO:Creating metrics dataframe
2024-07-18 11:27:10,564:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-18 11:27:10,570:INFO:Initializing create_model()
2024-07-18 11:27:10,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:10,570:INFO:Checking exceptions
2024-07-18 11:27:10,571:INFO:Importing libraries
2024-07-18 11:27:10,571:INFO:Copying training dataset
2024-07-18 11:27:10,573:INFO:Defining folds
2024-07-18 11:27:10,573:INFO:Declaring metric variables
2024-07-18 11:27:10,573:INFO:Importing untrained model
2024-07-18 11:27:10,573:INFO:Declaring custom model
2024-07-18 11:27:10,574:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:27:10,574:INFO:Cross validation set to False
2024-07-18 11:27:10,574:INFO:Fitting Model
2024-07-18 11:27:10,769:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:27:10] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:27:11,205:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:27:11,205:INFO:create_model() successfully completed......................................
2024-07-18 11:27:11,267:INFO:Initializing create_model()
2024-07-18 11:27:11,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=2656, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:11,267:INFO:Checking exceptions
2024-07-18 11:27:11,268:INFO:Importing libraries
2024-07-18 11:27:11,268:INFO:Copying training dataset
2024-07-18 11:27:11,269:INFO:Defining folds
2024-07-18 11:27:11,269:INFO:Declaring metric variables
2024-07-18 11:27:11,270:INFO:Importing untrained model
2024-07-18 11:27:11,270:INFO:Declaring custom model
2024-07-18 11:27:11,270:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:27:11,270:INFO:Cross validation set to False
2024-07-18 11:27:11,271:INFO:Fitting Model
2024-07-18 11:27:11,280:INFO:[LightGBM] [Info] Number of positive: 1147, number of negative: 929
2024-07-18 11:27:11,280:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-18 11:27:11,280:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:27:11,281:INFO:[LightGBM] [Info] Number of data points in the train set: 2076, number of used features: 3
2024-07-18 11:27:11,359:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation
2024-07-18 11:27:11,359:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...
2024-07-18 11:27:11,368:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-18 11:27:11,370:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-18 11:27:11,371:INFO:[LightGBM] [Info] 3 dense feature groups (0.01 MB) transferred to GPU in 0.000474 secs. 0 sparse feature groups
2024-07-18 11:27:11,371:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552505 -> initscore=0.210796
2024-07-18 11:27:11,371:INFO:[LightGBM] [Info] Start training from score 0.210796
2024-07-18 11:27:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:11,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:27:12,388:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=2656, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:27:12,389:INFO:create_model() successfully completed......................................
2024-07-18 11:27:12,451:INFO:Initializing create_model()
2024-07-18 11:27:12,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2656, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:12,452:INFO:Checking exceptions
2024-07-18 11:27:12,453:INFO:Importing libraries
2024-07-18 11:27:12,453:INFO:Copying training dataset
2024-07-18 11:27:12,455:INFO:Defining folds
2024-07-18 11:27:12,455:INFO:Declaring metric variables
2024-07-18 11:27:12,455:INFO:Importing untrained model
2024-07-18 11:27:12,455:INFO:Declaring custom model
2024-07-18 11:27:12,455:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:27:12,455:INFO:Cross validation set to False
2024-07-18 11:27:12,456:INFO:Fitting Model
2024-07-18 11:27:13,029:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2656, verbose=0, warm_start=False)
2024-07-18 11:27:13,029:INFO:create_model() successfully completed......................................
2024-07-18 11:27:13,092:INFO:Initializing create_model()
2024-07-18 11:27:13,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2656, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:13,092:INFO:Checking exceptions
2024-07-18 11:27:13,093:INFO:Importing libraries
2024-07-18 11:27:13,093:INFO:Copying training dataset
2024-07-18 11:27:13,095:INFO:Defining folds
2024-07-18 11:27:13,095:INFO:Declaring metric variables
2024-07-18 11:27:13,095:INFO:Importing untrained model
2024-07-18 11:27:13,095:INFO:Declaring custom model
2024-07-18 11:27:13,096:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:27:13,096:INFO:Cross validation set to False
2024-07-18 11:27:13,096:INFO:Fitting Model
2024-07-18 11:27:13,583:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2656, verbose=0, warm_start=False)
2024-07-18 11:27:13,583:INFO:create_model() successfully completed......................................
2024-07-18 11:27:13,646:INFO:Initializing create_model()
2024-07-18 11:27:13,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021DAB806510>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:13,646:INFO:Checking exceptions
2024-07-18 11:27:13,647:INFO:Importing libraries
2024-07-18 11:27:13,648:INFO:Copying training dataset
2024-07-18 11:27:13,649:INFO:Defining folds
2024-07-18 11:27:13,649:INFO:Declaring metric variables
2024-07-18 11:27:13,649:INFO:Importing untrained model
2024-07-18 11:27:13,649:INFO:Declaring custom model
2024-07-18 11:27:13,649:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:27:13,650:INFO:Cross validation set to False
2024-07-18 11:27:13,650:INFO:Fitting Model
2024-07-18 11:27:35,451:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DAB7EC390>
2024-07-18 11:27:35,451:INFO:create_model() successfully completed......................................
2024-07-18 11:27:35,524:INFO:Initializing create_model()
2024-07-18 11:27:35,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2656, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:35,524:INFO:Checking exceptions
2024-07-18 11:27:35,525:INFO:Importing libraries
2024-07-18 11:27:35,525:INFO:Copying training dataset
2024-07-18 11:27:35,528:INFO:Defining folds
2024-07-18 11:27:35,528:INFO:Declaring metric variables
2024-07-18 11:27:35,528:INFO:Importing untrained model
2024-07-18 11:27:35,528:INFO:Declaring custom model
2024-07-18 11:27:35,528:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:27:35,528:INFO:Cross validation set to False
2024-07-18 11:27:35,529:INFO:Fitting Model
2024-07-18 11:27:35,942:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2656, splitter='best')
2024-07-18 11:27:35,942:INFO:create_model() successfully completed......................................
2024-07-18 11:27:36,006:INFO:Initializing create_model()
2024-07-18 11:27:36,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2656, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:36,007:INFO:Checking exceptions
2024-07-18 11:27:36,008:INFO:Importing libraries
2024-07-18 11:27:36,008:INFO:Copying training dataset
2024-07-18 11:27:36,009:INFO:Defining folds
2024-07-18 11:27:36,009:INFO:Declaring metric variables
2024-07-18 11:27:36,009:INFO:Importing untrained model
2024-07-18 11:27:36,010:INFO:Declaring custom model
2024-07-18 11:27:36,010:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:27:36,010:INFO:Cross validation set to False
2024-07-18 11:27:36,010:INFO:Fitting Model
2024-07-18 11:27:36,499:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2656, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:27:36,499:INFO:create_model() successfully completed......................................
2024-07-18 11:27:36,571:INFO:Initializing create_model()
2024-07-18 11:27:36,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2656), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:36,571:INFO:Checking exceptions
2024-07-18 11:27:36,572:INFO:Importing libraries
2024-07-18 11:27:36,572:INFO:Copying training dataset
2024-07-18 11:27:36,574:INFO:Defining folds
2024-07-18 11:27:36,574:INFO:Declaring metric variables
2024-07-18 11:27:36,574:INFO:Importing untrained model
2024-07-18 11:27:36,574:INFO:Declaring custom model
2024-07-18 11:27:36,574:INFO:str Imported successfully
2024-07-18 11:27:36,575:INFO:Cross validation set to False
2024-07-18 11:27:36,575:INFO:Fitting Model
2024-07-18 11:27:37,052:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2656)
2024-07-18 11:27:37,052:INFO:create_model() successfully completed......................................
2024-07-18 11:27:37,117:INFO:Initializing create_model()
2024-07-18 11:27:37,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:37,117:INFO:Checking exceptions
2024-07-18 11:27:37,117:INFO:Importing libraries
2024-07-18 11:27:37,119:INFO:Copying training dataset
2024-07-18 11:27:37,120:INFO:Defining folds
2024-07-18 11:27:37,120:INFO:Declaring metric variables
2024-07-18 11:27:37,121:INFO:Importing untrained model
2024-07-18 11:27:37,121:INFO:Declaring custom model
2024-07-18 11:27:37,121:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:27:37,121:INFO:Cross validation set to False
2024-07-18 11:27:37,121:INFO:Fitting Model
2024-07-18 11:27:37,528:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:27:37,529:INFO:create_model() successfully completed......................................
2024-07-18 11:27:37,593:INFO:Initializing create_model()
2024-07-18 11:27:37,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:37,593:INFO:Checking exceptions
2024-07-18 11:27:37,594:INFO:Importing libraries
2024-07-18 11:27:37,594:INFO:Copying training dataset
2024-07-18 11:27:37,596:INFO:Defining folds
2024-07-18 11:27:37,596:INFO:Declaring metric variables
2024-07-18 11:27:37,597:INFO:Importing untrained model
2024-07-18 11:27:37,597:INFO:Declaring custom model
2024-07-18 11:27:37,597:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:27:37,597:INFO:Cross validation set to False
2024-07-18 11:27:37,597:INFO:Fitting Model
2024-07-18 11:27:38,011:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:27:38,011:INFO:create_model() successfully completed......................................
2024-07-18 11:27:38,072:INFO:Initializing create_model()
2024-07-18 11:27:38,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:38,073:INFO:Checking exceptions
2024-07-18 11:27:38,074:INFO:Importing libraries
2024-07-18 11:27:38,074:INFO:Copying training dataset
2024-07-18 11:27:38,076:INFO:Defining folds
2024-07-18 11:27:38,076:INFO:Declaring metric variables
2024-07-18 11:27:38,076:INFO:Importing untrained model
2024-07-18 11:27:38,076:INFO:Declaring custom model
2024-07-18 11:27:38,076:INFO:Naive Bayes Imported successfully
2024-07-18 11:27:38,076:INFO:Cross validation set to False
2024-07-18 11:27:38,076:INFO:Fitting Model
2024-07-18 11:27:38,490:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:27:38,490:INFO:create_model() successfully completed......................................
2024-07-18 11:27:38,551:INFO:Initializing create_model()
2024-07-18 11:27:38,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2656, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:38,551:INFO:Checking exceptions
2024-07-18 11:27:38,553:INFO:Importing libraries
2024-07-18 11:27:38,553:INFO:Copying training dataset
2024-07-18 11:27:38,554:INFO:Defining folds
2024-07-18 11:27:38,554:INFO:Declaring metric variables
2024-07-18 11:27:38,555:INFO:Importing untrained model
2024-07-18 11:27:38,555:INFO:Declaring custom model
2024-07-18 11:27:38,555:INFO:Logistic Regression Imported successfully
2024-07-18 11:27:38,555:INFO:Cross validation set to False
2024-07-18 11:27:38,555:INFO:Fitting Model
2024-07-18 11:27:38,975:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2656, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:27:38,976:INFO:create_model() successfully completed......................................
2024-07-18 11:27:39,043:INFO:Initializing create_model()
2024-07-18 11:27:39,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2656, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:39,043:INFO:Checking exceptions
2024-07-18 11:27:39,044:INFO:Importing libraries
2024-07-18 11:27:39,044:INFO:Copying training dataset
2024-07-18 11:27:39,046:INFO:Defining folds
2024-07-18 11:27:39,046:INFO:Declaring metric variables
2024-07-18 11:27:39,046:INFO:Importing untrained model
2024-07-18 11:27:39,046:INFO:Declaring custom model
2024-07-18 11:27:39,046:INFO:Ridge Classifier Imported successfully
2024-07-18 11:27:39,046:INFO:Cross validation set to False
2024-07-18 11:27:39,046:INFO:Fitting Model
2024-07-18 11:27:39,461:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2656, solver='auto',
                tol=0.0001)
2024-07-18 11:27:39,461:INFO:create_model() successfully completed......................................
2024-07-18 11:27:39,523:INFO:Initializing create_model()
2024-07-18 11:27:39,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:39,524:INFO:Checking exceptions
2024-07-18 11:27:39,525:INFO:Importing libraries
2024-07-18 11:27:39,525:INFO:Copying training dataset
2024-07-18 11:27:39,526:INFO:Defining folds
2024-07-18 11:27:39,526:INFO:Declaring metric variables
2024-07-18 11:27:39,527:INFO:Importing untrained model
2024-07-18 11:27:39,527:INFO:Declaring custom model
2024-07-18 11:27:39,527:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:27:39,527:INFO:Cross validation set to False
2024-07-18 11:27:39,527:INFO:Fitting Model
2024-07-18 11:27:39,944:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:27:39,944:INFO:create_model() successfully completed......................................
2024-07-18 11:27:40,010:INFO:Initializing create_model()
2024-07-18 11:27:40,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2656, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:40,010:INFO:Checking exceptions
2024-07-18 11:27:40,011:INFO:Importing libraries
2024-07-18 11:27:40,011:INFO:Copying training dataset
2024-07-18 11:27:40,013:INFO:Defining folds
2024-07-18 11:27:40,013:INFO:Declaring metric variables
2024-07-18 11:27:40,013:INFO:Importing untrained model
2024-07-18 11:27:40,013:INFO:Declaring custom model
2024-07-18 11:27:40,014:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:27:40,014:INFO:Cross validation set to False
2024-07-18 11:27:40,014:INFO:Fitting Model
2024-07-18 11:27:40,439:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2656, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:27:40,439:INFO:create_model() successfully completed......................................
2024-07-18 11:27:40,509:INFO:_master_model_container: 15
2024-07-18 11:27:40,509:INFO:_display_container: 2
2024-07-18 11:27:40,511:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=2656, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2656, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2656, verbose=0, warm_start=False), <catboost.core.CatBoostClassifier object at 0x0000021DAB7EC390>, DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2656, splitter='best'), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2656, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2656), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2656, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2656, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2656, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-07-18 11:27:40,511:INFO:compare_models() successfully completed......................................
2024-07-18 11:27:40,532:INFO:Initializing compare_models()
2024-07-18 11:27:40,532:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-18 11:27:40,532:INFO:Checking exceptions
2024-07-18 11:27:40,532:INFO:Preparing display monitor
2024-07-18 11:27:40,543:INFO:Initializing Logistic Regression
2024-07-18 11:27:40,544:INFO:Total runtime is 1.666545867919922e-05 minutes
2024-07-18 11:27:40,545:INFO:SubProcess create_model() called ==================================
2024-07-18 11:27:40,545:INFO:Initializing create_model()
2024-07-18 11:27:40,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:40,546:INFO:Checking exceptions
2024-07-18 11:27:40,546:INFO:Importing libraries
2024-07-18 11:27:40,546:INFO:Copying training dataset
2024-07-18 11:27:40,547:INFO:Defining folds
2024-07-18 11:27:40,547:INFO:Declaring metric variables
2024-07-18 11:27:40,550:INFO:Importing untrained model
2024-07-18 11:27:40,552:INFO:Logistic Regression Imported successfully
2024-07-18 11:27:40,555:INFO:Starting cross validation
2024-07-18 11:27:40,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:27:44,909:INFO:Calculating mean and std
2024-07-18 11:27:44,910:INFO:Creating metrics dataframe
2024-07-18 11:27:45,311:INFO:Uploading results into container
2024-07-18 11:27:45,312:INFO:Uploading model into container now
2024-07-18 11:27:45,312:INFO:_master_model_container: 16
2024-07-18 11:27:45,312:INFO:_display_container: 3
2024-07-18 11:27:45,313:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2656, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:27:45,313:INFO:create_model() successfully completed......................................
2024-07-18 11:27:45,375:INFO:SubProcess create_model() end ==================================
2024-07-18 11:27:45,375:INFO:Creating metrics dataframe
2024-07-18 11:27:45,379:INFO:Initializing K Neighbors Classifier
2024-07-18 11:27:45,379:INFO:Total runtime is 0.08060527642567954 minutes
2024-07-18 11:27:45,381:INFO:SubProcess create_model() called ==================================
2024-07-18 11:27:45,381:INFO:Initializing create_model()
2024-07-18 11:27:45,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:45,381:INFO:Checking exceptions
2024-07-18 11:27:45,381:INFO:Importing libraries
2024-07-18 11:27:45,381:INFO:Copying training dataset
2024-07-18 11:27:45,383:INFO:Defining folds
2024-07-18 11:27:45,383:INFO:Declaring metric variables
2024-07-18 11:27:45,385:INFO:Importing untrained model
2024-07-18 11:27:45,387:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:27:45,390:INFO:Starting cross validation
2024-07-18 11:27:45,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:27:50,131:INFO:Calculating mean and std
2024-07-18 11:27:50,132:INFO:Creating metrics dataframe
2024-07-18 11:27:50,533:INFO:Uploading results into container
2024-07-18 11:27:50,533:INFO:Uploading model into container now
2024-07-18 11:27:50,534:INFO:_master_model_container: 17
2024-07-18 11:27:50,534:INFO:_display_container: 3
2024-07-18 11:27:50,534:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:27:50,534:INFO:create_model() successfully completed......................................
2024-07-18 11:27:50,597:INFO:SubProcess create_model() end ==================================
2024-07-18 11:27:50,597:INFO:Creating metrics dataframe
2024-07-18 11:27:50,601:INFO:Initializing Naive Bayes
2024-07-18 11:27:50,601:INFO:Total runtime is 0.16763524611790975 minutes
2024-07-18 11:27:50,603:INFO:SubProcess create_model() called ==================================
2024-07-18 11:27:50,603:INFO:Initializing create_model()
2024-07-18 11:27:50,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:50,604:INFO:Checking exceptions
2024-07-18 11:27:50,604:INFO:Importing libraries
2024-07-18 11:27:50,604:INFO:Copying training dataset
2024-07-18 11:27:50,606:INFO:Defining folds
2024-07-18 11:27:50,606:INFO:Declaring metric variables
2024-07-18 11:27:50,607:INFO:Importing untrained model
2024-07-18 11:27:50,609:INFO:Naive Bayes Imported successfully
2024-07-18 11:27:50,612:INFO:Starting cross validation
2024-07-18 11:27:50,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:27:54,920:INFO:Calculating mean and std
2024-07-18 11:27:54,921:INFO:Creating metrics dataframe
2024-07-18 11:27:55,322:INFO:Uploading results into container
2024-07-18 11:27:55,323:INFO:Uploading model into container now
2024-07-18 11:27:55,323:INFO:_master_model_container: 18
2024-07-18 11:27:55,323:INFO:_display_container: 3
2024-07-18 11:27:55,323:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:27:55,323:INFO:create_model() successfully completed......................................
2024-07-18 11:27:55,386:INFO:SubProcess create_model() end ==================================
2024-07-18 11:27:55,386:INFO:Creating metrics dataframe
2024-07-18 11:27:55,390:INFO:Initializing Decision Tree Classifier
2024-07-18 11:27:55,390:INFO:Total runtime is 0.24744803508122762 minutes
2024-07-18 11:27:55,392:INFO:SubProcess create_model() called ==================================
2024-07-18 11:27:55,392:INFO:Initializing create_model()
2024-07-18 11:27:55,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:27:55,392:INFO:Checking exceptions
2024-07-18 11:27:55,392:INFO:Importing libraries
2024-07-18 11:27:55,393:INFO:Copying training dataset
2024-07-18 11:27:55,394:INFO:Defining folds
2024-07-18 11:27:55,394:INFO:Declaring metric variables
2024-07-18 11:27:55,396:INFO:Importing untrained model
2024-07-18 11:27:55,398:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:27:55,402:INFO:Starting cross validation
2024-07-18 11:27:55,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:27:59,696:INFO:Calculating mean and std
2024-07-18 11:27:59,698:INFO:Creating metrics dataframe
2024-07-18 11:28:00,120:INFO:Uploading results into container
2024-07-18 11:28:00,120:INFO:Uploading model into container now
2024-07-18 11:28:00,120:INFO:_master_model_container: 19
2024-07-18 11:28:00,120:INFO:_display_container: 3
2024-07-18 11:28:00,120:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2656, splitter='best')
2024-07-18 11:28:00,120:INFO:create_model() successfully completed......................................
2024-07-18 11:28:00,198:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:00,199:INFO:Creating metrics dataframe
2024-07-18 11:28:00,200:INFO:Initializing SVM - Linear Kernel
2024-07-18 11:28:00,200:INFO:Total runtime is 0.3276166121164958 minutes
2024-07-18 11:28:00,200:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:00,200:INFO:Initializing create_model()
2024-07-18 11:28:00,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:00,200:INFO:Checking exceptions
2024-07-18 11:28:00,200:INFO:Importing libraries
2024-07-18 11:28:00,200:INFO:Copying training dataset
2024-07-18 11:28:00,200:INFO:Defining folds
2024-07-18 11:28:00,200:INFO:Declaring metric variables
2024-07-18 11:28:00,209:INFO:Importing untrained model
2024-07-18 11:28:00,212:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:28:00,216:INFO:Starting cross validation
2024-07-18 11:28:00,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:00,239:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:00,673:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:01,094:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:01,534:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:01,982:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:02,409:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:02,832:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:03,268:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:03,694:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:04,132:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:04,518:INFO:Calculating mean and std
2024-07-18 11:28:04,519:INFO:Creating metrics dataframe
2024-07-18 11:28:04,920:INFO:Uploading results into container
2024-07-18 11:28:04,920:INFO:Uploading model into container now
2024-07-18 11:28:04,921:INFO:_master_model_container: 20
2024-07-18 11:28:04,921:INFO:_display_container: 3
2024-07-18 11:28:04,921:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2656, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:28:04,921:INFO:create_model() successfully completed......................................
2024-07-18 11:28:04,983:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:04,983:INFO:Creating metrics dataframe
2024-07-18 11:28:04,987:INFO:Initializing Ridge Classifier
2024-07-18 11:28:04,987:INFO:Total runtime is 0.4074040651321411 minutes
2024-07-18 11:28:04,990:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:04,990:INFO:Initializing create_model()
2024-07-18 11:28:04,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:04,990:INFO:Checking exceptions
2024-07-18 11:28:04,990:INFO:Importing libraries
2024-07-18 11:28:04,990:INFO:Copying training dataset
2024-07-18 11:28:04,992:INFO:Defining folds
2024-07-18 11:28:04,992:INFO:Declaring metric variables
2024-07-18 11:28:04,993:INFO:Importing untrained model
2024-07-18 11:28:04,995:INFO:Ridge Classifier Imported successfully
2024-07-18 11:28:04,998:INFO:Starting cross validation
2024-07-18 11:28:04,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:05,017:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:05,417:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:05,827:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:06,237:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:06,655:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:07,080:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:07,502:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:07,929:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:08,351:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:08,773:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:28:09,175:INFO:Calculating mean and std
2024-07-18 11:28:09,176:INFO:Creating metrics dataframe
2024-07-18 11:28:09,574:INFO:Uploading results into container
2024-07-18 11:28:09,575:INFO:Uploading model into container now
2024-07-18 11:28:09,575:INFO:_master_model_container: 21
2024-07-18 11:28:09,575:INFO:_display_container: 3
2024-07-18 11:28:09,576:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2656, solver='auto',
                tol=0.0001)
2024-07-18 11:28:09,576:INFO:create_model() successfully completed......................................
2024-07-18 11:28:09,639:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:09,639:INFO:Creating metrics dataframe
2024-07-18 11:28:09,644:INFO:Initializing Random Forest Classifier
2024-07-18 11:28:09,644:INFO:Total runtime is 0.4850130716959635 minutes
2024-07-18 11:28:09,646:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:09,646:INFO:Initializing create_model()
2024-07-18 11:28:09,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:09,646:INFO:Checking exceptions
2024-07-18 11:28:09,646:INFO:Importing libraries
2024-07-18 11:28:09,646:INFO:Copying training dataset
2024-07-18 11:28:09,648:INFO:Defining folds
2024-07-18 11:28:09,648:INFO:Declaring metric variables
2024-07-18 11:28:09,649:INFO:Importing untrained model
2024-07-18 11:28:09,651:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:28:09,655:INFO:Starting cross validation
2024-07-18 11:28:09,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:15,218:INFO:Calculating mean and std
2024-07-18 11:28:15,218:INFO:Creating metrics dataframe
2024-07-18 11:28:15,598:INFO:Uploading results into container
2024-07-18 11:28:15,598:INFO:Uploading model into container now
2024-07-18 11:28:15,598:INFO:_master_model_container: 22
2024-07-18 11:28:15,598:INFO:_display_container: 3
2024-07-18 11:28:15,599:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2656, verbose=0, warm_start=False)
2024-07-18 11:28:15,599:INFO:create_model() successfully completed......................................
2024-07-18 11:28:15,658:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:15,658:INFO:Creating metrics dataframe
2024-07-18 11:28:15,664:INFO:Initializing Quadratic Discriminant Analysis
2024-07-18 11:28:15,664:INFO:Total runtime is 0.5853493213653564 minutes
2024-07-18 11:28:15,664:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:15,664:INFO:Initializing create_model()
2024-07-18 11:28:15,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:15,664:INFO:Checking exceptions
2024-07-18 11:28:15,664:INFO:Importing libraries
2024-07-18 11:28:15,664:INFO:Copying training dataset
2024-07-18 11:28:15,668:INFO:Defining folds
2024-07-18 11:28:15,668:INFO:Declaring metric variables
2024-07-18 11:28:15,668:INFO:Importing untrained model
2024-07-18 11:28:15,668:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:28:15,673:INFO:Starting cross validation
2024-07-18 11:28:15,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:19,763:INFO:Calculating mean and std
2024-07-18 11:28:19,763:INFO:Creating metrics dataframe
2024-07-18 11:28:20,138:INFO:Uploading results into container
2024-07-18 11:28:20,145:INFO:Uploading model into container now
2024-07-18 11:28:20,145:INFO:_master_model_container: 23
2024-07-18 11:28:20,145:INFO:_display_container: 3
2024-07-18 11:28:20,145:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:28:20,145:INFO:create_model() successfully completed......................................
2024-07-18 11:28:20,198:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:20,198:INFO:Creating metrics dataframe
2024-07-18 11:28:20,208:INFO:Initializing Ada Boost Classifier
2024-07-18 11:28:20,208:INFO:Total runtime is 0.6610880851745605 minutes
2024-07-18 11:28:20,213:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:20,213:INFO:Initializing create_model()
2024-07-18 11:28:20,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:20,213:INFO:Checking exceptions
2024-07-18 11:28:20,213:INFO:Importing libraries
2024-07-18 11:28:20,213:INFO:Copying training dataset
2024-07-18 11:28:20,213:INFO:Defining folds
2024-07-18 11:28:20,213:INFO:Declaring metric variables
2024-07-18 11:28:20,215:INFO:Importing untrained model
2024-07-18 11:28:20,218:INFO:Ada Boost Classifier Imported successfully
2024-07-18 11:28:20,218:INFO:Starting cross validation
2024-07-18 11:28:20,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:25,212:INFO:Calculating mean and std
2024-07-18 11:28:25,213:INFO:Creating metrics dataframe
2024-07-18 11:28:25,609:INFO:Uploading results into container
2024-07-18 11:28:25,610:INFO:Uploading model into container now
2024-07-18 11:28:25,610:INFO:_master_model_container: 24
2024-07-18 11:28:25,610:INFO:_display_container: 3
2024-07-18 11:28:25,610:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2656)
2024-07-18 11:28:25,610:INFO:create_model() successfully completed......................................
2024-07-18 11:28:25,669:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:25,670:INFO:Creating metrics dataframe
2024-07-18 11:28:25,674:INFO:Initializing Gradient Boosting Classifier
2024-07-18 11:28:25,674:INFO:Total runtime is 0.7521899541219075 minutes
2024-07-18 11:28:25,676:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:25,676:INFO:Initializing create_model()
2024-07-18 11:28:25,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:25,676:INFO:Checking exceptions
2024-07-18 11:28:25,676:INFO:Importing libraries
2024-07-18 11:28:25,676:INFO:Copying training dataset
2024-07-18 11:28:25,679:INFO:Defining folds
2024-07-18 11:28:25,679:INFO:Declaring metric variables
2024-07-18 11:28:25,681:INFO:Importing untrained model
2024-07-18 11:28:25,683:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:28:25,686:INFO:Starting cross validation
2024-07-18 11:28:25,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:30,724:INFO:Calculating mean and std
2024-07-18 11:28:30,725:INFO:Creating metrics dataframe
2024-07-18 11:28:31,113:INFO:Uploading results into container
2024-07-18 11:28:31,114:INFO:Uploading model into container now
2024-07-18 11:28:31,114:INFO:_master_model_container: 25
2024-07-18 11:28:31,114:INFO:_display_container: 3
2024-07-18 11:28:31,115:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2656, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:28:31,115:INFO:create_model() successfully completed......................................
2024-07-18 11:28:31,182:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:31,183:INFO:Creating metrics dataframe
2024-07-18 11:28:31,189:INFO:Initializing Linear Discriminant Analysis
2024-07-18 11:28:31,189:INFO:Total runtime is 0.8440938194592793 minutes
2024-07-18 11:28:31,191:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:31,191:INFO:Initializing create_model()
2024-07-18 11:28:31,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:31,191:INFO:Checking exceptions
2024-07-18 11:28:31,191:INFO:Importing libraries
2024-07-18 11:28:31,191:INFO:Copying training dataset
2024-07-18 11:28:31,193:INFO:Defining folds
2024-07-18 11:28:31,193:INFO:Declaring metric variables
2024-07-18 11:28:31,195:INFO:Importing untrained model
2024-07-18 11:28:31,196:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:28:31,199:INFO:Starting cross validation
2024-07-18 11:28:31,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:35,333:INFO:Calculating mean and std
2024-07-18 11:28:35,334:INFO:Creating metrics dataframe
2024-07-18 11:28:35,710:INFO:Uploading results into container
2024-07-18 11:28:35,711:INFO:Uploading model into container now
2024-07-18 11:28:35,711:INFO:_master_model_container: 26
2024-07-18 11:28:35,711:INFO:_display_container: 3
2024-07-18 11:28:35,711:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:28:35,712:INFO:create_model() successfully completed......................................
2024-07-18 11:28:35,771:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:35,772:INFO:Creating metrics dataframe
2024-07-18 11:28:35,777:INFO:Initializing Extra Trees Classifier
2024-07-18 11:28:35,777:INFO:Total runtime is 0.920561134815216 minutes
2024-07-18 11:28:35,778:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:35,778:INFO:Initializing create_model()
2024-07-18 11:28:35,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:35,778:INFO:Checking exceptions
2024-07-18 11:28:35,780:INFO:Importing libraries
2024-07-18 11:28:35,780:INFO:Copying training dataset
2024-07-18 11:28:35,781:INFO:Defining folds
2024-07-18 11:28:35,781:INFO:Declaring metric variables
2024-07-18 11:28:35,783:INFO:Importing untrained model
2024-07-18 11:28:35,785:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:28:35,788:INFO:Starting cross validation
2024-07-18 11:28:35,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:41,478:INFO:Calculating mean and std
2024-07-18 11:28:41,479:INFO:Creating metrics dataframe
2024-07-18 11:28:41,861:INFO:Uploading results into container
2024-07-18 11:28:41,861:INFO:Uploading model into container now
2024-07-18 11:28:41,862:INFO:_master_model_container: 27
2024-07-18 11:28:41,862:INFO:_display_container: 3
2024-07-18 11:28:41,862:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2656, verbose=0, warm_start=False)
2024-07-18 11:28:41,862:INFO:create_model() successfully completed......................................
2024-07-18 11:28:41,929:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:41,929:INFO:Creating metrics dataframe
2024-07-18 11:28:41,935:INFO:Initializing Extreme Gradient Boosting
2024-07-18 11:28:41,935:INFO:Total runtime is 1.0232069810231526 minutes
2024-07-18 11:28:41,936:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:41,936:INFO:Initializing create_model()
2024-07-18 11:28:41,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:41,936:INFO:Checking exceptions
2024-07-18 11:28:41,936:INFO:Importing libraries
2024-07-18 11:28:41,938:INFO:Copying training dataset
2024-07-18 11:28:41,939:INFO:Defining folds
2024-07-18 11:28:41,939:INFO:Declaring metric variables
2024-07-18 11:28:41,941:INFO:Importing untrained model
2024-07-18 11:28:41,943:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:28:41,947:INFO:Starting cross validation
2024-07-18 11:28:41,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:41,978:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:41] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:42,457:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:42] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:42,928:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:42] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:43,411:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:43] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:43,891:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:43] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:44,374:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:44] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:44,852:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:44] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:45,334:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:45] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:45,823:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:45] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:46,308:WARNING:c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\xgboost\core.py:160: UserWarning: [11:28:46] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\xgboost\xgboost-ci-windows\src\common\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)

2024-07-18 11:28:46,761:INFO:Calculating mean and std
2024-07-18 11:28:46,762:INFO:Creating metrics dataframe
2024-07-18 11:28:47,151:INFO:Uploading results into container
2024-07-18 11:28:47,151:INFO:Uploading model into container now
2024-07-18 11:28:47,152:INFO:_master_model_container: 28
2024-07-18 11:28:47,152:INFO:_display_container: 3
2024-07-18 11:28:47,152:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:28:47,152:INFO:create_model() successfully completed......................................
2024-07-18 11:28:47,212:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:47,213:INFO:Creating metrics dataframe
2024-07-18 11:28:47,218:INFO:Initializing Light Gradient Boosting Machine
2024-07-18 11:28:47,218:INFO:Total runtime is 1.111243406931559 minutes
2024-07-18 11:28:47,220:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:47,220:INFO:Initializing create_model()
2024-07-18 11:28:47,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:47,220:INFO:Checking exceptions
2024-07-18 11:28:47,220:INFO:Importing libraries
2024-07-18 11:28:47,220:INFO:Copying training dataset
2024-07-18 11:28:47,222:INFO:Defining folds
2024-07-18 11:28:47,222:INFO:Declaring metric variables
2024-07-18 11:28:47,224:INFO:Importing untrained model
2024-07-18 11:28:47,226:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:28:47,229:INFO:Starting cross validation
2024-07-18 11:28:47,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:51,964:INFO:Calculating mean and std
2024-07-18 11:28:51,965:INFO:Creating metrics dataframe
2024-07-18 11:28:52,353:INFO:Uploading results into container
2024-07-18 11:28:52,353:INFO:Uploading model into container now
2024-07-18 11:28:52,353:INFO:_master_model_container: 29
2024-07-18 11:28:52,354:INFO:_display_container: 3
2024-07-18 11:28:52,354:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=2656, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:28:52,354:INFO:create_model() successfully completed......................................
2024-07-18 11:28:52,414:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:52,414:INFO:Creating metrics dataframe
2024-07-18 11:28:52,419:INFO:Initializing CatBoost Classifier
2024-07-18 11:28:52,420:INFO:Total runtime is 1.1979467272758482 minutes
2024-07-18 11:28:52,421:INFO:SubProcess create_model() called ==================================
2024-07-18 11:28:52,422:INFO:Initializing create_model()
2024-07-18 11:28:52,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DAB72C150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:52,422:INFO:Checking exceptions
2024-07-18 11:28:52,422:INFO:Importing libraries
2024-07-18 11:28:52,422:INFO:Copying training dataset
2024-07-18 11:28:52,423:INFO:Defining folds
2024-07-18 11:28:52,424:INFO:Declaring metric variables
2024-07-18 11:28:52,425:INFO:Importing untrained model
2024-07-18 11:28:52,427:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:28:52,430:INFO:Starting cross validation
2024-07-18 11:28:52,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-18 11:28:56,648:INFO:Calculating mean and std
2024-07-18 11:28:56,649:INFO:Creating metrics dataframe
2024-07-18 11:28:57,029:INFO:Uploading results into container
2024-07-18 11:28:57,030:INFO:Uploading model into container now
2024-07-18 11:28:57,030:INFO:_master_model_container: 30
2024-07-18 11:28:57,030:INFO:_display_container: 3
2024-07-18 11:28:57,030:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DB1E89210>
2024-07-18 11:28:57,030:INFO:create_model() successfully completed......................................
2024-07-18 11:28:57,090:INFO:SubProcess create_model() end ==================================
2024-07-18 11:28:57,090:INFO:Creating metrics dataframe
2024-07-18 11:28:57,095:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-18 11:28:57,100:INFO:Initializing create_model()
2024-07-18 11:28:57,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAECE350>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:28:57,100:INFO:Checking exceptions
2024-07-18 11:28:57,101:INFO:Importing libraries
2024-07-18 11:28:57,101:INFO:Copying training dataset
2024-07-18 11:28:57,102:INFO:Defining folds
2024-07-18 11:28:57,102:INFO:Declaring metric variables
2024-07-18 11:28:57,102:INFO:Importing untrained model
2024-07-18 11:28:57,103:INFO:Declaring custom model
2024-07-18 11:28:57,103:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:28:57,104:INFO:Cross validation set to False
2024-07-18 11:28:57,104:INFO:Fitting Model
2024-07-18 11:28:57,536:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:28:57,536:INFO:create_model() successfully completed......................................
2024-07-18 11:28:57,612:INFO:_master_model_container: 30
2024-07-18 11:28:57,612:INFO:_display_container: 3
2024-07-18 11:28:57,613:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:28:57,613:INFO:compare_models() successfully completed......................................
2024-07-18 11:28:57,615:INFO:Initializing save_model()
2024-07-18 11:28:57,615:INFO:save_model(model=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/XGBClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:28:57,615:INFO:Adding model into prep_pipe
2024-07-18 11:28:57,620:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/XGBClassifier.pkl saved in current working directory
2024-07-18 11:28:57,625:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-07-18 11:28:57,625:INFO:save_model() successfully completed......................................
2024-07-18 11:28:58,095:INFO:Initializing save_model()
2024-07-18 11:28:58,095:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=2656, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/LGBMClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:28:58,095:INFO:Adding model into prep_pipe
2024-07-18 11:28:58,103:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/LGBMClassifier.pkl saved in current working directory
2024-07-18 11:28:58,107:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, device='gpu',
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=20,
                                min_child_weight=0.001, min_split_gain=0.0,
                                n_estimators=100, n_jobs=-1, num_leaves=31,
                                objective=None, random_state=2656,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-18 11:28:58,107:INFO:save_model() successfully completed......................................
2024-07-18 11:28:58,575:INFO:Initializing save_model()
2024-07-18 11:28:58,575:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2656, verbose=0, warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/RandomForestClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:28:58,575:INFO:Adding model into prep_pipe
2024-07-18 11:28:58,594:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/RandomForestClassifier.pkl saved in current working directory
2024-07-18 11:28:58,596:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=2656,
                                        verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:28:58,596:INFO:save_model() successfully completed......................................
2024-07-18 11:28:59,036:INFO:Initializing save_model()
2024-07-18 11:28:59,036:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2656, verbose=0, warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/ExtraTreesClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:28:59,036:INFO:Adding model into prep_pipe
2024-07-18 11:28:59,056:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/ExtraTreesClassifier.pkl saved in current working directory
2024-07-18 11:28:59,058:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=2656,
                                      verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:28:59,058:INFO:save_model() successfully completed......................................
2024-07-18 11:28:59,498:INFO:Initializing save_model()
2024-07-18 11:28:59,498:INFO:save_model(model=<catboost.core.CatBoostClassifier object at 0x0000021DAB7EC390>, model_name=GPU_1_EPPD_ML_VALIDATION_kfold/CatBoostClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:28:59,498:INFO:Adding model into prep_pipe
2024-07-18 11:28:59,499:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/CatBoostClassifier.pkl saved in current working directory
2024-07-18 11:28:59,501:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x0000021DAB7EC390>)],
         verbose=False)
2024-07-18 11:28:59,501:INFO:save_model() successfully completed......................................
2024-07-18 11:28:59,938:INFO:Initializing save_model()
2024-07-18 11:28:59,938:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2656, splitter='best'), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/DecisionTreeClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:28:59,938:INFO:Adding model into prep_pipe
2024-07-18 11:28:59,938:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/DecisionTreeClassifier.pkl saved in current working directory
2024-07-18 11:28:59,945:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=2656, splitter='best'))],
         verbose=False)
2024-07-18 11:28:59,945:INFO:save_model() successfully completed......................................
2024-07-18 11:29:00,395:INFO:Initializing save_model()
2024-07-18 11:29:00,395:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2656, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/GradientBoostingClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:29:00,395:INFO:Adding model into prep_pipe
2024-07-18 11:29:00,397:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/GradientBoostingClassifier.pkl saved in current working directory
2024-07-18 11:29:00,397:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=2656, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:29:00,397:INFO:save_model() successfully completed......................................
2024-07-18 11:29:00,847:INFO:Initializing save_model()
2024-07-18 11:29:00,847:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2656), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/AdaBoostClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:29:00,847:INFO:Adding model into prep_pipe
2024-07-18 11:29:00,862:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/AdaBoostClassifier.pkl saved in current working directory
2024-07-18 11:29:00,862:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=2656))],
         verbose=False)
2024-07-18 11:29:00,862:INFO:save_model() successfully completed......................................
2024-07-18 11:29:01,309:INFO:Initializing save_model()
2024-07-18 11:29:01,309:INFO:save_model(model=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/KNeighborsClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:29:01,309:INFO:Adding model into prep_pipe
2024-07-18 11:29:01,311:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/KNeighborsClassifier.pkl saved in current working directory
2024-07-18 11:29:01,314:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False)
2024-07-18 11:29:01,314:INFO:save_model() successfully completed......................................
2024-07-18 11:29:01,757:INFO:Initializing save_model()
2024-07-18 11:29:01,757:INFO:save_model(model=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/QuadraticDiscriminantAnalysis, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:29:01,757:INFO:Adding model into prep_pipe
2024-07-18 11:29:01,757:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/QuadraticDiscriminantAnalysis.pkl saved in current working directory
2024-07-18 11:29:01,762:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False)
2024-07-18 11:29:01,762:INFO:save_model() successfully completed......................................
2024-07-18 11:29:02,212:INFO:Initializing save_model()
2024-07-18 11:29:02,212:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/GaussianNB, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:29:02,212:INFO:Adding model into prep_pipe
2024-07-18 11:29:02,212:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/GaussianNB.pkl saved in current working directory
2024-07-18 11:29:02,212:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2024-07-18 11:29:02,212:INFO:save_model() successfully completed......................................
2024-07-18 11:29:02,662:INFO:Initializing save_model()
2024-07-18 11:29:02,662:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2656, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/LogisticRegression, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:29:02,662:INFO:Adding model into prep_pipe
2024-07-18 11:29:02,662:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/LogisticRegression.pkl saved in current working directory
2024-07-18 11:29:02,668:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2656,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-07-18 11:29:02,668:INFO:save_model() successfully completed......................................
2024-07-18 11:29:03,118:INFO:Initializing save_model()
2024-07-18 11:29:03,118:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2656, solver='auto',
                tol=0.0001), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/RidgeClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:29:03,118:INFO:Adding model into prep_pipe
2024-07-18 11:29:03,118:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/RidgeClassifier.pkl saved in current working directory
2024-07-18 11:29:03,123:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=2656,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2024-07-18 11:29:03,123:INFO:save_model() successfully completed......................................
2024-07-18 11:29:03,568:INFO:Initializing save_model()
2024-07-18 11:29:03,568:INFO:save_model(model=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/LinearDiscriminantAnalysis, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:29:03,568:INFO:Adding model into prep_pipe
2024-07-18 11:29:03,568:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/LinearDiscriminantAnalysis.pkl saved in current working directory
2024-07-18 11:29:03,573:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2024-07-18 11:29:03,573:INFO:save_model() successfully completed......................................
2024-07-18 11:29:04,018:INFO:Initializing save_model()
2024-07-18 11:29:04,018:INFO:save_model(model=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2656, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), model_name=GPU_1_EPPD_ML_VALIDATION_kfold/SGDClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:29:04,018:INFO:Adding model into prep_pipe
2024-07-18 11:29:04,023:INFO:GPU_1_EPPD_ML_VALIDATION_kfold/SGDClassifier.pkl saved in current working directory
2024-07-18 11:29:04,023:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=2656,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:29:04,023:INFO:save_model() successfully completed......................................
2024-07-18 11:29:04,473:WARNING:C:\Users\JAL\AppData\Local\Temp\ipykernel_17160\2873217847.py:105: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  best_model[best_model.select_dtypes(include=['number']).columns] *= 100

2024-07-18 11:29:05,248:INFO:PyCaret ClassificationExperiment
2024-07-18 11:29:05,248:INFO:Logging name: clf-default-name
2024-07-18 11:29:05,248:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-18 11:29:05,248:INFO:version 3.0.0
2024-07-18 11:29:05,248:INFO:Initializing setup()
2024-07-18 11:29:05,248:INFO:self.USI: bee9
2024-07-18 11:29:05,248:INFO:self._variable_keys: {'n_jobs_param', 'fix_imbalance', 'exp_id', 'y_test', 'is_multiclass', '_ml_usecase', 'html_param', 'target_param', 'USI', 'gpu_param', 'log_plots_param', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'fold_generator', 'logging_param', 'y_train', 'fold_groups_param', 'seed', 'idx', 'X_test', 'X', 'data', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'y'}
2024-07-18 11:29:05,248:INFO:Checking environment
2024-07-18 11:29:05,248:INFO:python_version: 3.11.4
2024-07-18 11:29:05,248:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2024-07-18 11:29:05,248:INFO:machine: AMD64
2024-07-18 11:29:05,248:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-18 11:29:05,257:INFO:Memory: svmem(total=68659781632, available=52331491328, percent=23.8, used=16328290304, free=52331491328)
2024-07-18 11:29:05,257:INFO:Physical Core: 16
2024-07-18 11:29:05,257:INFO:Logical Core: 32
2024-07-18 11:29:05,257:INFO:Checking libraries
2024-07-18 11:29:05,257:INFO:System:
2024-07-18 11:29:05,257:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2024-07-18 11:29:05,257:INFO:executable: c:\Users\JAL\AppData\Local\Programs\Python\Python311\python.exe
2024-07-18 11:29:05,257:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-18 11:29:05,257:INFO:PyCaret required dependencies:
2024-07-18 11:29:05,257:INFO:                 pip: 24.1.2
2024-07-18 11:29:05,257:INFO:          setuptools: 70.3.0
2024-07-18 11:29:05,257:INFO:             pycaret: 3.0.0
2024-07-18 11:29:05,257:INFO:             IPython: 8.15.0
2024-07-18 11:29:05,257:INFO:          ipywidgets: 8.1.3
2024-07-18 11:29:05,257:INFO:                tqdm: 4.66.4
2024-07-18 11:29:05,257:INFO:               numpy: 1.24.4
2024-07-18 11:29:05,257:INFO:              pandas: 2.2.2
2024-07-18 11:29:05,257:INFO:              jinja2: 3.1.4
2024-07-18 11:29:05,257:INFO:               scipy: 1.11.4
2024-07-18 11:29:05,257:INFO:              joblib: 1.3.2
2024-07-18 11:29:05,257:INFO:             sklearn: 1.3.0
2024-07-18 11:29:05,257:INFO:                pyod: 2.0.1
2024-07-18 11:29:05,257:INFO:            imblearn: 0.12.3
2024-07-18 11:29:05,257:INFO:   category_encoders: 2.6.3
2024-07-18 11:29:05,257:INFO:            lightgbm: 4.3.0
2024-07-18 11:29:05,257:INFO:               numba: 0.60.0
2024-07-18 11:29:05,257:INFO:            requests: 2.32.3
2024-07-18 11:29:05,257:INFO:          matplotlib: 3.7.5
2024-07-18 11:29:05,257:INFO:          scikitplot: 0.3.7
2024-07-18 11:29:05,257:INFO:         yellowbrick: 1.5
2024-07-18 11:29:05,257:INFO:              plotly: 5.22.0
2024-07-18 11:29:05,257:INFO:             kaleido: 0.2.1
2024-07-18 11:29:05,257:INFO:         statsmodels: 0.14.2
2024-07-18 11:29:05,257:INFO:              sktime: 0.26.0
2024-07-18 11:29:05,257:INFO:               tbats: 1.1.3
2024-07-18 11:29:05,257:INFO:            pmdarima: 2.0.4
2024-07-18 11:29:05,257:INFO:              psutil: 5.9.5
2024-07-18 11:29:05,257:INFO:PyCaret optional dependencies:
2024-07-18 11:29:05,257:INFO:                shap: Not installed
2024-07-18 11:29:05,257:INFO:           interpret: Not installed
2024-07-18 11:29:05,257:INFO:                umap: Not installed
2024-07-18 11:29:05,257:INFO:    pandas_profiling: Not installed
2024-07-18 11:29:05,257:INFO:  explainerdashboard: Not installed
2024-07-18 11:29:05,257:INFO:             autoviz: Not installed
2024-07-18 11:29:05,257:INFO:           fairlearn: Not installed
2024-07-18 11:29:05,257:INFO:             xgboost: 2.0.3
2024-07-18 11:29:05,257:INFO:            catboost: 1.2.5
2024-07-18 11:29:05,257:INFO:              kmodes: Not installed
2024-07-18 11:29:05,257:INFO:             mlxtend: Not installed
2024-07-18 11:29:05,257:INFO:       statsforecast: 1.4.0
2024-07-18 11:29:05,257:INFO:        tune_sklearn: Not installed
2024-07-18 11:29:05,257:INFO:                 ray: 2.10.0
2024-07-18 11:29:05,257:INFO:            hyperopt: 0.2.7
2024-07-18 11:29:05,257:INFO:              optuna: Not installed
2024-07-18 11:29:05,257:INFO:               skopt: Not installed
2024-07-18 11:29:05,257:INFO:              mlflow: Not installed
2024-07-18 11:29:05,257:INFO:              gradio: Not installed
2024-07-18 11:29:05,257:INFO:             fastapi: Not installed
2024-07-18 11:29:05,257:INFO:             uvicorn: Not installed
2024-07-18 11:29:05,257:INFO:              m2cgen: Not installed
2024-07-18 11:29:05,261:INFO:           evidently: Not installed
2024-07-18 11:29:05,261:INFO:               fugue: Not installed
2024-07-18 11:29:05,261:INFO:           streamlit: 1.31.0
2024-07-18 11:29:05,261:INFO:             prophet: Not installed
2024-07-18 11:29:05,261:INFO:None
2024-07-18 11:29:05,261:INFO:Set up data.
2024-07-18 11:29:05,263:INFO:Set up train/test split.
2024-07-18 11:29:05,263:INFO:Set up index.
2024-07-18 11:29:05,263:INFO:Set up folding strategy.
2024-07-18 11:29:05,263:INFO:Assigning column types.
2024-07-18 11:29:05,263:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-18 11:29:05,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 11:29:05,295:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:29:05,312:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:29:05,312:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:29:05,343:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 11:29:05,343:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:29:05,361:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:29:05,362:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:29:05,362:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-18 11:29:05,388:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:29:05,408:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:29:05,408:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:29:05,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:29:05,452:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:29:05,457:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:29:05,457:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-18 11:29:05,502:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:29:05,502:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:29:05,547:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:29:05,552:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:29:05,552:INFO:Preparing preprocessing pipeline...
2024-07-18 11:29:05,552:INFO:Set up simple imputation.
2024-07-18 11:29:05,561:INFO:Finished creating preprocessing pipeline.
2024-07-18 11:29:05,562:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-18 11:29:05,562:INFO:Creating final display dataframe.
2024-07-18 11:29:05,588:INFO:Setup _display_container:                     Description             Value
0                    Session id              7173
1                        Target       PlacedOrNot
2                   Target type            Binary
3           Original data shape         (2224, 4)
4        Transformed data shape         (2224, 4)
5   Transformed train set shape         (1668, 4)
6    Transformed test set shape          (556, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              bee9
2024-07-18 11:29:05,637:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:29:05,637:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:29:05,688:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:29:05,688:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:29:05,688:INFO:setup() successfully completed in 0.82s...............
2024-07-18 11:29:05,688:INFO:Initializing compare_models()
2024-07-18 11:29:05,688:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-18 11:29:05,688:INFO:Checking exceptions
2024-07-18 11:29:05,693:INFO:Preparing display monitor
2024-07-18 11:29:05,697:INFO:Initializing Logistic Regression
2024-07-18 11:29:05,697:INFO:Total runtime is 0.0 minutes
2024-07-18 11:29:05,697:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:05,697:INFO:Initializing create_model()
2024-07-18 11:29:05,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:05,697:INFO:Checking exceptions
2024-07-18 11:29:05,697:INFO:Importing libraries
2024-07-18 11:29:05,697:INFO:Copying training dataset
2024-07-18 11:29:05,707:INFO:Defining folds
2024-07-18 11:29:05,707:INFO:Declaring metric variables
2024-07-18 11:29:05,707:INFO:Importing untrained model
2024-07-18 11:29:05,711:INFO:Logistic Regression Imported successfully
2024-07-18 11:29:05,715:INFO:Starting cross validation
2024-07-18 11:29:05,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:11,194:INFO:Calculating mean and std
2024-07-18 11:29:11,195:INFO:Creating metrics dataframe
2024-07-18 11:29:11,688:INFO:Uploading results into container
2024-07-18 11:29:11,688:INFO:Uploading model into container now
2024-07-18 11:29:11,688:INFO:_master_model_container: 1
2024-07-18 11:29:11,688:INFO:_display_container: 2
2024-07-18 11:29:11,688:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7173, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:29:11,688:INFO:create_model() successfully completed......................................
2024-07-18 11:29:11,752:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:11,752:INFO:Creating metrics dataframe
2024-07-18 11:29:11,752:INFO:Initializing K Neighbors Classifier
2024-07-18 11:29:11,752:INFO:Total runtime is 0.10091646909713745 minutes
2024-07-18 11:29:11,757:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:11,757:INFO:Initializing create_model()
2024-07-18 11:29:11,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:11,757:INFO:Checking exceptions
2024-07-18 11:29:11,757:INFO:Importing libraries
2024-07-18 11:29:11,757:INFO:Copying training dataset
2024-07-18 11:29:11,757:INFO:Defining folds
2024-07-18 11:29:11,757:INFO:Declaring metric variables
2024-07-18 11:29:11,761:INFO:Importing untrained model
2024-07-18 11:29:11,763:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:29:11,767:INFO:Starting cross validation
2024-07-18 11:29:11,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:16,926:INFO:Calculating mean and std
2024-07-18 11:29:16,926:INFO:Creating metrics dataframe
2024-07-18 11:29:17,423:INFO:Uploading results into container
2024-07-18 11:29:17,423:INFO:Uploading model into container now
2024-07-18 11:29:17,423:INFO:_master_model_container: 2
2024-07-18 11:29:17,424:INFO:_display_container: 2
2024-07-18 11:29:17,424:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:29:17,424:INFO:create_model() successfully completed......................................
2024-07-18 11:29:17,479:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:17,479:INFO:Creating metrics dataframe
2024-07-18 11:29:17,488:INFO:Initializing Naive Bayes
2024-07-18 11:29:17,488:INFO:Total runtime is 0.19650322198867798 minutes
2024-07-18 11:29:17,488:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:17,488:INFO:Initializing create_model()
2024-07-18 11:29:17,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:17,488:INFO:Checking exceptions
2024-07-18 11:29:17,488:INFO:Importing libraries
2024-07-18 11:29:17,488:INFO:Copying training dataset
2024-07-18 11:29:17,494:INFO:Defining folds
2024-07-18 11:29:17,494:INFO:Declaring metric variables
2024-07-18 11:29:17,495:INFO:Importing untrained model
2024-07-18 11:29:17,497:INFO:Naive Bayes Imported successfully
2024-07-18 11:29:17,497:INFO:Starting cross validation
2024-07-18 11:29:17,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:22,582:INFO:Calculating mean and std
2024-07-18 11:29:22,582:INFO:Creating metrics dataframe
2024-07-18 11:29:23,067:INFO:Uploading results into container
2024-07-18 11:29:23,067:INFO:Uploading model into container now
2024-07-18 11:29:23,067:INFO:_master_model_container: 3
2024-07-18 11:29:23,067:INFO:_display_container: 2
2024-07-18 11:29:23,067:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:29:23,067:INFO:create_model() successfully completed......................................
2024-07-18 11:29:23,137:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:23,137:INFO:Creating metrics dataframe
2024-07-18 11:29:23,137:INFO:Initializing Decision Tree Classifier
2024-07-18 11:29:23,137:INFO:Total runtime is 0.2906613866488139 minutes
2024-07-18 11:29:23,146:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:23,146:INFO:Initializing create_model()
2024-07-18 11:29:23,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:23,146:INFO:Checking exceptions
2024-07-18 11:29:23,146:INFO:Importing libraries
2024-07-18 11:29:23,146:INFO:Copying training dataset
2024-07-18 11:29:23,147:INFO:Defining folds
2024-07-18 11:29:23,147:INFO:Declaring metric variables
2024-07-18 11:29:23,147:INFO:Importing untrained model
2024-07-18 11:29:23,147:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:29:23,147:INFO:Starting cross validation
2024-07-18 11:29:23,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:26,828:INFO:Calculating mean and std
2024-07-18 11:29:26,829:INFO:Creating metrics dataframe
2024-07-18 11:29:27,332:INFO:Uploading results into container
2024-07-18 11:29:27,332:INFO:Uploading model into container now
2024-07-18 11:29:27,332:INFO:_master_model_container: 4
2024-07-18 11:29:27,332:INFO:_display_container: 2
2024-07-18 11:29:27,333:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7173, splitter='best')
2024-07-18 11:29:27,333:INFO:create_model() successfully completed......................................
2024-07-18 11:29:27,393:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:27,393:INFO:Creating metrics dataframe
2024-07-18 11:29:27,397:INFO:Initializing SVM - Linear Kernel
2024-07-18 11:29:27,397:INFO:Total runtime is 0.3616642951965332 minutes
2024-07-18 11:29:27,399:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:27,399:INFO:Initializing create_model()
2024-07-18 11:29:27,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:27,399:INFO:Checking exceptions
2024-07-18 11:29:27,399:INFO:Importing libraries
2024-07-18 11:29:27,399:INFO:Copying training dataset
2024-07-18 11:29:27,401:INFO:Defining folds
2024-07-18 11:29:27,401:INFO:Declaring metric variables
2024-07-18 11:29:27,403:INFO:Importing untrained model
2024-07-18 11:29:27,405:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:29:27,408:INFO:Starting cross validation
2024-07-18 11:29:27,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:27,443:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:27,444:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:27,446:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:27,449:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:27,450:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:27,451:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:27,451:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:27,454:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:27,456:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:27,458:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,108:INFO:Calculating mean and std
2024-07-18 11:29:31,108:INFO:Creating metrics dataframe
2024-07-18 11:29:31,602:INFO:Uploading results into container
2024-07-18 11:29:31,602:INFO:Uploading model into container now
2024-07-18 11:29:31,603:INFO:_master_model_container: 5
2024-07-18 11:29:31,603:INFO:_display_container: 2
2024-07-18 11:29:31,603:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7173, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:29:31,603:INFO:create_model() successfully completed......................................
2024-07-18 11:29:31,660:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:31,660:INFO:Creating metrics dataframe
2024-07-18 11:29:31,665:INFO:Initializing Ridge Classifier
2024-07-18 11:29:31,665:INFO:Total runtime is 0.4328004439671834 minutes
2024-07-18 11:29:31,667:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:31,667:INFO:Initializing create_model()
2024-07-18 11:29:31,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:31,667:INFO:Checking exceptions
2024-07-18 11:29:31,667:INFO:Importing libraries
2024-07-18 11:29:31,667:INFO:Copying training dataset
2024-07-18 11:29:31,669:INFO:Defining folds
2024-07-18 11:29:31,669:INFO:Declaring metric variables
2024-07-18 11:29:31,671:INFO:Importing untrained model
2024-07-18 11:29:31,672:INFO:Ridge Classifier Imported successfully
2024-07-18 11:29:31,676:INFO:Starting cross validation
2024-07-18 11:29:31,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:31,705:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,706:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,708:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,710:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,712:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,712:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,714:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,716:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,718:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:31,719:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:29:35,434:INFO:Calculating mean and std
2024-07-18 11:29:35,435:INFO:Creating metrics dataframe
2024-07-18 11:29:35,921:INFO:Uploading results into container
2024-07-18 11:29:35,922:INFO:Uploading model into container now
2024-07-18 11:29:35,922:INFO:_master_model_container: 6
2024-07-18 11:29:35,922:INFO:_display_container: 2
2024-07-18 11:29:35,922:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7173, solver='auto',
                tol=0.0001)
2024-07-18 11:29:35,923:INFO:create_model() successfully completed......................................
2024-07-18 11:29:35,982:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:35,982:INFO:Creating metrics dataframe
2024-07-18 11:29:35,987:INFO:Initializing Random Forest Classifier
2024-07-18 11:29:35,987:INFO:Total runtime is 0.5048217097918193 minutes
2024-07-18 11:29:35,989:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:35,989:INFO:Initializing create_model()
2024-07-18 11:29:35,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:35,989:INFO:Checking exceptions
2024-07-18 11:29:35,989:INFO:Importing libraries
2024-07-18 11:29:35,989:INFO:Copying training dataset
2024-07-18 11:29:35,991:INFO:Defining folds
2024-07-18 11:29:35,991:INFO:Declaring metric variables
2024-07-18 11:29:35,992:INFO:Importing untrained model
2024-07-18 11:29:35,994:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:29:35,998:INFO:Starting cross validation
2024-07-18 11:29:35,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:40,060:INFO:Calculating mean and std
2024-07-18 11:29:40,060:INFO:Creating metrics dataframe
2024-07-18 11:29:40,555:INFO:Uploading results into container
2024-07-18 11:29:40,555:INFO:Uploading model into container now
2024-07-18 11:29:40,555:INFO:_master_model_container: 7
2024-07-18 11:29:40,555:INFO:_display_container: 2
2024-07-18 11:29:40,556:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7173, verbose=0, warm_start=False)
2024-07-18 11:29:40,556:INFO:create_model() successfully completed......................................
2024-07-18 11:29:40,616:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:40,616:INFO:Creating metrics dataframe
2024-07-18 11:29:40,621:INFO:Initializing Quadratic Discriminant Analysis
2024-07-18 11:29:40,621:INFO:Total runtime is 0.582059129079183 minutes
2024-07-18 11:29:40,623:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:40,623:INFO:Initializing create_model()
2024-07-18 11:29:40,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:40,623:INFO:Checking exceptions
2024-07-18 11:29:40,623:INFO:Importing libraries
2024-07-18 11:29:40,623:INFO:Copying training dataset
2024-07-18 11:29:40,625:INFO:Defining folds
2024-07-18 11:29:40,625:INFO:Declaring metric variables
2024-07-18 11:29:40,627:INFO:Importing untrained model
2024-07-18 11:29:40,628:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:29:40,632:INFO:Starting cross validation
2024-07-18 11:29:40,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:44,412:INFO:Calculating mean and std
2024-07-18 11:29:44,412:INFO:Creating metrics dataframe
2024-07-18 11:29:44,919:INFO:Uploading results into container
2024-07-18 11:29:44,919:INFO:Uploading model into container now
2024-07-18 11:29:44,920:INFO:_master_model_container: 8
2024-07-18 11:29:44,920:INFO:_display_container: 2
2024-07-18 11:29:44,920:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:29:44,920:INFO:create_model() successfully completed......................................
2024-07-18 11:29:44,979:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:44,980:INFO:Creating metrics dataframe
2024-07-18 11:29:44,984:INFO:Initializing Ada Boost Classifier
2024-07-18 11:29:44,985:INFO:Total runtime is 0.6547998348871867 minutes
2024-07-18 11:29:44,987:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:44,987:INFO:Initializing create_model()
2024-07-18 11:29:44,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:44,987:INFO:Checking exceptions
2024-07-18 11:29:44,987:INFO:Importing libraries
2024-07-18 11:29:44,987:INFO:Copying training dataset
2024-07-18 11:29:44,989:INFO:Defining folds
2024-07-18 11:29:44,989:INFO:Declaring metric variables
2024-07-18 11:29:44,991:INFO:Importing untrained model
2024-07-18 11:29:44,993:INFO:Ada Boost Classifier Imported successfully
2024-07-18 11:29:44,996:INFO:Starting cross validation
2024-07-18 11:29:44,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:48,932:INFO:Calculating mean and std
2024-07-18 11:29:48,932:INFO:Creating metrics dataframe
2024-07-18 11:29:49,453:INFO:Uploading results into container
2024-07-18 11:29:49,454:INFO:Uploading model into container now
2024-07-18 11:29:49,454:INFO:_master_model_container: 9
2024-07-18 11:29:49,454:INFO:_display_container: 2
2024-07-18 11:29:49,455:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7173)
2024-07-18 11:29:49,455:INFO:create_model() successfully completed......................................
2024-07-18 11:29:49,520:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:49,520:INFO:Creating metrics dataframe
2024-07-18 11:29:49,525:INFO:Initializing Gradient Boosting Classifier
2024-07-18 11:29:49,526:INFO:Total runtime is 0.7304730653762818 minutes
2024-07-18 11:29:49,527:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:49,527:INFO:Initializing create_model()
2024-07-18 11:29:49,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:49,527:INFO:Checking exceptions
2024-07-18 11:29:49,527:INFO:Importing libraries
2024-07-18 11:29:49,527:INFO:Copying training dataset
2024-07-18 11:29:49,529:INFO:Defining folds
2024-07-18 11:29:49,529:INFO:Declaring metric variables
2024-07-18 11:29:49,529:INFO:Importing untrained model
2024-07-18 11:29:49,529:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:29:49,529:INFO:Starting cross validation
2024-07-18 11:29:49,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:53,588:INFO:Calculating mean and std
2024-07-18 11:29:53,588:INFO:Creating metrics dataframe
2024-07-18 11:29:54,094:INFO:Uploading results into container
2024-07-18 11:29:54,094:INFO:Uploading model into container now
2024-07-18 11:29:54,094:INFO:_master_model_container: 10
2024-07-18 11:29:54,094:INFO:_display_container: 2
2024-07-18 11:29:54,094:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7173, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:29:54,094:INFO:create_model() successfully completed......................................
2024-07-18 11:29:54,159:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:54,159:INFO:Creating metrics dataframe
2024-07-18 11:29:54,164:INFO:Initializing Linear Discriminant Analysis
2024-07-18 11:29:54,164:INFO:Total runtime is 0.8077722390492758 minutes
2024-07-18 11:29:54,164:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:54,164:INFO:Initializing create_model()
2024-07-18 11:29:54,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:54,164:INFO:Checking exceptions
2024-07-18 11:29:54,164:INFO:Importing libraries
2024-07-18 11:29:54,164:INFO:Copying training dataset
2024-07-18 11:29:54,170:INFO:Defining folds
2024-07-18 11:29:54,170:INFO:Declaring metric variables
2024-07-18 11:29:54,170:INFO:Importing untrained model
2024-07-18 11:29:54,170:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:29:54,175:INFO:Starting cross validation
2024-07-18 11:29:54,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:29:58,071:INFO:Calculating mean and std
2024-07-18 11:29:58,072:INFO:Creating metrics dataframe
2024-07-18 11:29:58,579:INFO:Uploading results into container
2024-07-18 11:29:58,580:INFO:Uploading model into container now
2024-07-18 11:29:58,580:INFO:_master_model_container: 11
2024-07-18 11:29:58,580:INFO:_display_container: 2
2024-07-18 11:29:58,581:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:29:58,581:INFO:create_model() successfully completed......................................
2024-07-18 11:29:58,645:INFO:SubProcess create_model() end ==================================
2024-07-18 11:29:58,645:INFO:Creating metrics dataframe
2024-07-18 11:29:58,650:INFO:Initializing Extra Trees Classifier
2024-07-18 11:29:58,650:INFO:Total runtime is 0.8825500806172689 minutes
2024-07-18 11:29:58,652:INFO:SubProcess create_model() called ==================================
2024-07-18 11:29:58,653:INFO:Initializing create_model()
2024-07-18 11:29:58,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:29:58,653:INFO:Checking exceptions
2024-07-18 11:29:58,653:INFO:Importing libraries
2024-07-18 11:29:58,653:INFO:Copying training dataset
2024-07-18 11:29:58,655:INFO:Defining folds
2024-07-18 11:29:58,656:INFO:Declaring metric variables
2024-07-18 11:29:58,658:INFO:Importing untrained model
2024-07-18 11:29:58,659:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:29:58,663:INFO:Starting cross validation
2024-07-18 11:29:58,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:02,724:INFO:Calculating mean and std
2024-07-18 11:30:02,724:INFO:Creating metrics dataframe
2024-07-18 11:30:03,216:INFO:Uploading results into container
2024-07-18 11:30:03,216:INFO:Uploading model into container now
2024-07-18 11:30:03,216:INFO:_master_model_container: 12
2024-07-18 11:30:03,216:INFO:_display_container: 2
2024-07-18 11:30:03,216:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7173, verbose=0, warm_start=False)
2024-07-18 11:30:03,216:INFO:create_model() successfully completed......................................
2024-07-18 11:30:03,279:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:03,279:INFO:Creating metrics dataframe
2024-07-18 11:30:03,294:INFO:Initializing Extreme Gradient Boosting
2024-07-18 11:30:03,294:INFO:Total runtime is 0.9599473516146342 minutes
2024-07-18 11:30:03,294:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:03,294:INFO:Initializing create_model()
2024-07-18 11:30:03,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:03,294:INFO:Checking exceptions
2024-07-18 11:30:03,294:INFO:Importing libraries
2024-07-18 11:30:03,294:INFO:Copying training dataset
2024-07-18 11:30:03,294:INFO:Defining folds
2024-07-18 11:30:03,294:INFO:Declaring metric variables
2024-07-18 11:30:03,294:INFO:Importing untrained model
2024-07-18 11:30:03,294:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:30:03,294:INFO:Starting cross validation
2024-07-18 11:30:03,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:07,193:INFO:Calculating mean and std
2024-07-18 11:30:07,193:INFO:Creating metrics dataframe
2024-07-18 11:30:07,678:INFO:Uploading results into container
2024-07-18 11:30:07,678:INFO:Uploading model into container now
2024-07-18 11:30:07,678:INFO:_master_model_container: 13
2024-07-18 11:30:07,678:INFO:_display_container: 2
2024-07-18 11:30:07,678:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:30:07,678:INFO:create_model() successfully completed......................................
2024-07-18 11:30:07,752:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:07,752:INFO:Creating metrics dataframe
2024-07-18 11:30:07,757:INFO:Initializing Light Gradient Boosting Machine
2024-07-18 11:30:07,757:INFO:Total runtime is 1.0343239784240723 minutes
2024-07-18 11:30:07,757:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:07,757:INFO:Initializing create_model()
2024-07-18 11:30:07,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:07,757:INFO:Checking exceptions
2024-07-18 11:30:07,757:INFO:Importing libraries
2024-07-18 11:30:07,757:INFO:Copying training dataset
2024-07-18 11:30:07,757:INFO:Defining folds
2024-07-18 11:30:07,757:INFO:Declaring metric variables
2024-07-18 11:30:07,757:INFO:Importing untrained model
2024-07-18 11:30:07,757:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:30:07,757:INFO:Starting cross validation
2024-07-18 11:30:07,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:12,305:INFO:Calculating mean and std
2024-07-18 11:30:12,305:INFO:Creating metrics dataframe
2024-07-18 11:30:12,786:INFO:Uploading results into container
2024-07-18 11:30:12,786:INFO:Uploading model into container now
2024-07-18 11:30:12,786:INFO:_master_model_container: 14
2024-07-18 11:30:12,786:INFO:_display_container: 2
2024-07-18 11:30:12,801:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7173, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:30:12,801:INFO:create_model() successfully completed......................................
2024-07-18 11:30:12,860:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:12,860:INFO:Creating metrics dataframe
2024-07-18 11:30:12,860:INFO:Initializing CatBoost Classifier
2024-07-18 11:30:12,860:INFO:Total runtime is 1.1193745374679567 minutes
2024-07-18 11:30:12,860:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:12,860:INFO:Initializing create_model()
2024-07-18 11:30:12,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2041050>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:12,860:INFO:Checking exceptions
2024-07-18 11:30:12,860:INFO:Importing libraries
2024-07-18 11:30:12,860:INFO:Copying training dataset
2024-07-18 11:30:12,860:INFO:Defining folds
2024-07-18 11:30:12,860:INFO:Declaring metric variables
2024-07-18 11:30:12,860:INFO:Importing untrained model
2024-07-18 11:30:12,875:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:30:12,875:INFO:Starting cross validation
2024-07-18 11:30:12,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:18,815:INFO:Calculating mean and std
2024-07-18 11:30:18,816:INFO:Creating metrics dataframe
2024-07-18 11:30:19,320:INFO:Uploading results into container
2024-07-18 11:30:19,321:INFO:Uploading model into container now
2024-07-18 11:30:19,321:INFO:_master_model_container: 15
2024-07-18 11:30:19,321:INFO:_display_container: 2
2024-07-18 11:30:19,321:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DAB7AFF10>
2024-07-18 11:30:19,321:INFO:create_model() successfully completed......................................
2024-07-18 11:30:19,382:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:19,382:INFO:Creating metrics dataframe
2024-07-18 11:30:19,388:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-18 11:30:19,393:INFO:Initializing create_model()
2024-07-18 11:30:19,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:19,393:INFO:Checking exceptions
2024-07-18 11:30:19,394:INFO:Importing libraries
2024-07-18 11:30:19,394:INFO:Copying training dataset
2024-07-18 11:30:19,397:INFO:Defining folds
2024-07-18 11:30:19,397:INFO:Declaring metric variables
2024-07-18 11:30:19,397:INFO:Importing untrained model
2024-07-18 11:30:19,397:INFO:Declaring custom model
2024-07-18 11:30:19,398:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:30:19,398:INFO:Cross validation set to False
2024-07-18 11:30:19,398:INFO:Fitting Model
2024-07-18 11:30:19,885:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:30:19,886:INFO:create_model() successfully completed......................................
2024-07-18 11:30:19,950:INFO:Initializing create_model()
2024-07-18 11:30:19,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7173, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:19,950:INFO:Checking exceptions
2024-07-18 11:30:19,951:INFO:Importing libraries
2024-07-18 11:30:19,951:INFO:Copying training dataset
2024-07-18 11:30:19,953:INFO:Defining folds
2024-07-18 11:30:19,953:INFO:Declaring metric variables
2024-07-18 11:30:19,953:INFO:Importing untrained model
2024-07-18 11:30:19,953:INFO:Declaring custom model
2024-07-18 11:30:19,954:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:30:19,954:INFO:Cross validation set to False
2024-07-18 11:30:19,954:INFO:Fitting Model
2024-07-18 11:30:19,963:INFO:[LightGBM] [Info] Number of positive: 931, number of negative: 737
2024-07-18 11:30:19,964:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000093 seconds.
2024-07-18 11:30:19,964:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-18 11:30:19,964:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:30:19,964:INFO:[LightGBM] [Info] Number of data points in the train set: 1668, number of used features: 3
2024-07-18 11:30:19,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.558153 -> initscore=0.233671
2024-07-18 11:30:19,964:INFO:[LightGBM] [Info] Start training from score 0.233671
2024-07-18 11:30:19,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:19,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:30:20,448:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7173, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:30:20,448:INFO:create_model() successfully completed......................................
2024-07-18 11:30:20,511:INFO:Initializing create_model()
2024-07-18 11:30:20,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:20,511:INFO:Checking exceptions
2024-07-18 11:30:20,512:INFO:Importing libraries
2024-07-18 11:30:20,513:INFO:Copying training dataset
2024-07-18 11:30:20,514:INFO:Defining folds
2024-07-18 11:30:20,514:INFO:Declaring metric variables
2024-07-18 11:30:20,514:INFO:Importing untrained model
2024-07-18 11:30:20,515:INFO:Declaring custom model
2024-07-18 11:30:20,515:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:30:20,515:INFO:Cross validation set to False
2024-07-18 11:30:20,515:INFO:Fitting Model
2024-07-18 11:30:20,934:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:30:20,934:INFO:create_model() successfully completed......................................
2024-07-18 11:30:20,999:INFO:Initializing create_model()
2024-07-18 11:30:20,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021DAB7AFF10>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:20,999:INFO:Checking exceptions
2024-07-18 11:30:21,000:INFO:Importing libraries
2024-07-18 11:30:21,000:INFO:Copying training dataset
2024-07-18 11:30:21,002:INFO:Defining folds
2024-07-18 11:30:21,002:INFO:Declaring metric variables
2024-07-18 11:30:21,002:INFO:Importing untrained model
2024-07-18 11:30:21,002:INFO:Declaring custom model
2024-07-18 11:30:21,002:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:30:21,002:INFO:Cross validation set to False
2024-07-18 11:30:21,003:INFO:Fitting Model
2024-07-18 11:30:22,525:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DAB8063D0>
2024-07-18 11:30:22,525:INFO:create_model() successfully completed......................................
2024-07-18 11:30:22,589:INFO:Initializing create_model()
2024-07-18 11:30:22,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7173, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:22,590:INFO:Checking exceptions
2024-07-18 11:30:22,591:INFO:Importing libraries
2024-07-18 11:30:22,591:INFO:Copying training dataset
2024-07-18 11:30:22,593:INFO:Defining folds
2024-07-18 11:30:22,593:INFO:Declaring metric variables
2024-07-18 11:30:22,593:INFO:Importing untrained model
2024-07-18 11:30:22,593:INFO:Declaring custom model
2024-07-18 11:30:22,593:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:30:22,594:INFO:Cross validation set to False
2024-07-18 11:30:22,594:INFO:Fitting Model
2024-07-18 11:30:23,082:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7173, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:30:23,083:INFO:create_model() successfully completed......................................
2024-07-18 11:30:23,147:INFO:Initializing create_model()
2024-07-18 11:30:23,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7173, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:23,147:INFO:Checking exceptions
2024-07-18 11:30:23,148:INFO:Importing libraries
2024-07-18 11:30:23,148:INFO:Copying training dataset
2024-07-18 11:30:23,150:INFO:Defining folds
2024-07-18 11:30:23,150:INFO:Declaring metric variables
2024-07-18 11:30:23,150:INFO:Importing untrained model
2024-07-18 11:30:23,150:INFO:Declaring custom model
2024-07-18 11:30:23,151:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:30:23,151:INFO:Cross validation set to False
2024-07-18 11:30:23,151:INFO:Fitting Model
2024-07-18 11:30:23,669:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7173, verbose=0, warm_start=False)
2024-07-18 11:30:23,669:INFO:create_model() successfully completed......................................
2024-07-18 11:30:23,733:INFO:Initializing create_model()
2024-07-18 11:30:23,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7173, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:23,733:INFO:Checking exceptions
2024-07-18 11:30:23,734:INFO:Importing libraries
2024-07-18 11:30:23,734:INFO:Copying training dataset
2024-07-18 11:30:23,736:INFO:Defining folds
2024-07-18 11:30:23,736:INFO:Declaring metric variables
2024-07-18 11:30:23,737:INFO:Importing untrained model
2024-07-18 11:30:23,737:INFO:Declaring custom model
2024-07-18 11:30:23,737:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:30:23,737:INFO:Cross validation set to False
2024-07-18 11:30:23,737:INFO:Fitting Model
2024-07-18 11:30:24,154:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7173, splitter='best')
2024-07-18 11:30:24,154:INFO:create_model() successfully completed......................................
2024-07-18 11:30:24,218:INFO:Initializing create_model()
2024-07-18 11:30:24,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7173), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:24,218:INFO:Checking exceptions
2024-07-18 11:30:24,219:INFO:Importing libraries
2024-07-18 11:30:24,219:INFO:Copying training dataset
2024-07-18 11:30:24,221:INFO:Defining folds
2024-07-18 11:30:24,221:INFO:Declaring metric variables
2024-07-18 11:30:24,221:INFO:Importing untrained model
2024-07-18 11:30:24,221:INFO:Declaring custom model
2024-07-18 11:30:24,221:INFO:str Imported successfully
2024-07-18 11:30:24,222:INFO:Cross validation set to False
2024-07-18 11:30:24,222:INFO:Fitting Model
2024-07-18 11:30:24,698:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7173)
2024-07-18 11:30:24,698:INFO:create_model() successfully completed......................................
2024-07-18 11:30:24,762:INFO:Initializing create_model()
2024-07-18 11:30:24,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7173, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:24,763:INFO:Checking exceptions
2024-07-18 11:30:24,763:INFO:Importing libraries
2024-07-18 11:30:24,763:INFO:Copying training dataset
2024-07-18 11:30:24,766:INFO:Defining folds
2024-07-18 11:30:24,766:INFO:Declaring metric variables
2024-07-18 11:30:24,766:INFO:Importing untrained model
2024-07-18 11:30:24,766:INFO:Declaring custom model
2024-07-18 11:30:24,767:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:30:24,767:INFO:Cross validation set to False
2024-07-18 11:30:24,767:INFO:Fitting Model
2024-07-18 11:30:25,257:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7173, verbose=0, warm_start=False)
2024-07-18 11:30:25,257:INFO:create_model() successfully completed......................................
2024-07-18 11:30:25,321:INFO:Initializing create_model()
2024-07-18 11:30:25,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:25,321:INFO:Checking exceptions
2024-07-18 11:30:25,323:INFO:Importing libraries
2024-07-18 11:30:25,323:INFO:Copying training dataset
2024-07-18 11:30:25,324:INFO:Defining folds
2024-07-18 11:30:25,324:INFO:Declaring metric variables
2024-07-18 11:30:25,324:INFO:Importing untrained model
2024-07-18 11:30:25,324:INFO:Declaring custom model
2024-07-18 11:30:25,325:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:30:25,325:INFO:Cross validation set to False
2024-07-18 11:30:25,325:INFO:Fitting Model
2024-07-18 11:30:25,744:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:30:25,744:INFO:create_model() successfully completed......................................
2024-07-18 11:30:25,808:INFO:Initializing create_model()
2024-07-18 11:30:25,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:25,808:INFO:Checking exceptions
2024-07-18 11:30:25,809:INFO:Importing libraries
2024-07-18 11:30:25,809:INFO:Copying training dataset
2024-07-18 11:30:25,811:INFO:Defining folds
2024-07-18 11:30:25,811:INFO:Declaring metric variables
2024-07-18 11:30:25,811:INFO:Importing untrained model
2024-07-18 11:30:25,811:INFO:Declaring custom model
2024-07-18 11:30:25,811:INFO:Naive Bayes Imported successfully
2024-07-18 11:30:25,812:INFO:Cross validation set to False
2024-07-18 11:30:25,812:INFO:Fitting Model
2024-07-18 11:30:26,228:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:30:26,228:INFO:create_model() successfully completed......................................
2024-07-18 11:30:26,292:INFO:Initializing create_model()
2024-07-18 11:30:26,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7173, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:26,292:INFO:Checking exceptions
2024-07-18 11:30:26,293:INFO:Importing libraries
2024-07-18 11:30:26,293:INFO:Copying training dataset
2024-07-18 11:30:26,295:INFO:Defining folds
2024-07-18 11:30:26,295:INFO:Declaring metric variables
2024-07-18 11:30:26,295:INFO:Importing untrained model
2024-07-18 11:30:26,295:INFO:Declaring custom model
2024-07-18 11:30:26,295:INFO:Logistic Regression Imported successfully
2024-07-18 11:30:26,296:INFO:Cross validation set to False
2024-07-18 11:30:26,296:INFO:Fitting Model
2024-07-18 11:30:26,716:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7173, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:30:26,716:INFO:create_model() successfully completed......................................
2024-07-18 11:30:26,778:INFO:Initializing create_model()
2024-07-18 11:30:26,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7173, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:26,778:INFO:Checking exceptions
2024-07-18 11:30:26,779:INFO:Importing libraries
2024-07-18 11:30:26,779:INFO:Copying training dataset
2024-07-18 11:30:26,781:INFO:Defining folds
2024-07-18 11:30:26,781:INFO:Declaring metric variables
2024-07-18 11:30:26,781:INFO:Importing untrained model
2024-07-18 11:30:26,781:INFO:Declaring custom model
2024-07-18 11:30:26,781:INFO:Ridge Classifier Imported successfully
2024-07-18 11:30:26,782:INFO:Cross validation set to False
2024-07-18 11:30:26,782:INFO:Fitting Model
2024-07-18 11:30:27,197:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7173, solver='auto',
                tol=0.0001)
2024-07-18 11:30:27,198:INFO:create_model() successfully completed......................................
2024-07-18 11:30:27,259:INFO:Initializing create_model()
2024-07-18 11:30:27,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:27,260:INFO:Checking exceptions
2024-07-18 11:30:27,261:INFO:Importing libraries
2024-07-18 11:30:27,261:INFO:Copying training dataset
2024-07-18 11:30:27,263:INFO:Defining folds
2024-07-18 11:30:27,263:INFO:Declaring metric variables
2024-07-18 11:30:27,263:INFO:Importing untrained model
2024-07-18 11:30:27,263:INFO:Declaring custom model
2024-07-18 11:30:27,263:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:30:27,264:INFO:Cross validation set to False
2024-07-18 11:30:27,264:INFO:Fitting Model
2024-07-18 11:30:27,684:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:30:27,684:INFO:create_model() successfully completed......................................
2024-07-18 11:30:27,749:INFO:Initializing create_model()
2024-07-18 11:30:27,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7173, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:27,749:INFO:Checking exceptions
2024-07-18 11:30:27,750:INFO:Importing libraries
2024-07-18 11:30:27,750:INFO:Copying training dataset
2024-07-18 11:30:27,752:INFO:Defining folds
2024-07-18 11:30:27,752:INFO:Declaring metric variables
2024-07-18 11:30:27,752:INFO:Importing untrained model
2024-07-18 11:30:27,752:INFO:Declaring custom model
2024-07-18 11:30:27,753:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:30:27,753:INFO:Cross validation set to False
2024-07-18 11:30:27,753:INFO:Fitting Model
2024-07-18 11:30:28,175:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7173, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:30:28,175:INFO:create_model() successfully completed......................................
2024-07-18 11:30:28,244:INFO:_master_model_container: 15
2024-07-18 11:30:28,244:INFO:_display_container: 2
2024-07-18 11:30:28,246:INFO:[XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7173, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), <catboost.core.CatBoostClassifier object at 0x0000021DAB8063D0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7173, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7173, verbose=0, warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7173, splitter='best'), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7173), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7173, verbose=0, warm_start=False), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7173, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7173, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7173, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-07-18 11:30:28,246:INFO:compare_models() successfully completed......................................
2024-07-18 11:30:28,267:INFO:Initializing compare_models()
2024-07-18 11:30:28,268:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-18 11:30:28,268:INFO:Checking exceptions
2024-07-18 11:30:28,268:INFO:Preparing display monitor
2024-07-18 11:30:28,280:INFO:Initializing Logistic Regression
2024-07-18 11:30:28,280:INFO:Total runtime is 0.0 minutes
2024-07-18 11:30:28,282:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:28,282:INFO:Initializing create_model()
2024-07-18 11:30:28,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:28,282:INFO:Checking exceptions
2024-07-18 11:30:28,282:INFO:Importing libraries
2024-07-18 11:30:28,282:INFO:Copying training dataset
2024-07-18 11:30:28,284:INFO:Defining folds
2024-07-18 11:30:28,284:INFO:Declaring metric variables
2024-07-18 11:30:28,286:INFO:Importing untrained model
2024-07-18 11:30:28,288:INFO:Logistic Regression Imported successfully
2024-07-18 11:30:28,292:INFO:Starting cross validation
2024-07-18 11:30:28,292:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:32,178:INFO:Calculating mean and std
2024-07-18 11:30:32,179:INFO:Creating metrics dataframe
2024-07-18 11:30:32,681:INFO:Uploading results into container
2024-07-18 11:30:32,682:INFO:Uploading model into container now
2024-07-18 11:30:32,682:INFO:_master_model_container: 16
2024-07-18 11:30:32,682:INFO:_display_container: 3
2024-07-18 11:30:32,682:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7173, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:30:32,683:INFO:create_model() successfully completed......................................
2024-07-18 11:30:32,742:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:32,742:INFO:Creating metrics dataframe
2024-07-18 11:30:32,746:INFO:Initializing K Neighbors Classifier
2024-07-18 11:30:32,746:INFO:Total runtime is 0.07443197568257649 minutes
2024-07-18 11:30:32,748:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:32,748:INFO:Initializing create_model()
2024-07-18 11:30:32,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:32,749:INFO:Checking exceptions
2024-07-18 11:30:32,749:INFO:Importing libraries
2024-07-18 11:30:32,749:INFO:Copying training dataset
2024-07-18 11:30:32,750:INFO:Defining folds
2024-07-18 11:30:32,750:INFO:Declaring metric variables
2024-07-18 11:30:32,752:INFO:Importing untrained model
2024-07-18 11:30:32,754:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:30:32,757:INFO:Starting cross validation
2024-07-18 11:30:32,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:36,673:INFO:Calculating mean and std
2024-07-18 11:30:36,673:INFO:Creating metrics dataframe
2024-07-18 11:30:37,174:INFO:Uploading results into container
2024-07-18 11:30:37,174:INFO:Uploading model into container now
2024-07-18 11:30:37,174:INFO:_master_model_container: 17
2024-07-18 11:30:37,174:INFO:_display_container: 3
2024-07-18 11:30:37,175:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:30:37,175:INFO:create_model() successfully completed......................................
2024-07-18 11:30:37,235:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:37,236:INFO:Creating metrics dataframe
2024-07-18 11:30:37,240:INFO:Initializing Naive Bayes
2024-07-18 11:30:37,240:INFO:Total runtime is 0.14933679898579916 minutes
2024-07-18 11:30:37,242:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:37,242:INFO:Initializing create_model()
2024-07-18 11:30:37,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:37,242:INFO:Checking exceptions
2024-07-18 11:30:37,242:INFO:Importing libraries
2024-07-18 11:30:37,242:INFO:Copying training dataset
2024-07-18 11:30:37,244:INFO:Defining folds
2024-07-18 11:30:37,244:INFO:Declaring metric variables
2024-07-18 11:30:37,246:INFO:Importing untrained model
2024-07-18 11:30:37,247:INFO:Naive Bayes Imported successfully
2024-07-18 11:30:37,252:INFO:Starting cross validation
2024-07-18 11:30:37,252:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:41,121:INFO:Calculating mean and std
2024-07-18 11:30:41,121:INFO:Creating metrics dataframe
2024-07-18 11:30:41,633:INFO:Uploading results into container
2024-07-18 11:30:41,633:INFO:Uploading model into container now
2024-07-18 11:30:41,633:INFO:_master_model_container: 18
2024-07-18 11:30:41,634:INFO:_display_container: 3
2024-07-18 11:30:41,634:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:30:41,634:INFO:create_model() successfully completed......................................
2024-07-18 11:30:41,697:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:41,697:INFO:Creating metrics dataframe
2024-07-18 11:30:41,701:INFO:Initializing Decision Tree Classifier
2024-07-18 11:30:41,702:INFO:Total runtime is 0.22368074655532838 minutes
2024-07-18 11:30:41,703:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:41,703:INFO:Initializing create_model()
2024-07-18 11:30:41,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:41,704:INFO:Checking exceptions
2024-07-18 11:30:41,704:INFO:Importing libraries
2024-07-18 11:30:41,704:INFO:Copying training dataset
2024-07-18 11:30:41,705:INFO:Defining folds
2024-07-18 11:30:41,705:INFO:Declaring metric variables
2024-07-18 11:30:41,707:INFO:Importing untrained model
2024-07-18 11:30:41,709:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:30:41,712:INFO:Starting cross validation
2024-07-18 11:30:41,713:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:45,583:INFO:Calculating mean and std
2024-07-18 11:30:45,584:INFO:Creating metrics dataframe
2024-07-18 11:30:46,119:INFO:Uploading results into container
2024-07-18 11:30:46,119:INFO:Uploading model into container now
2024-07-18 11:30:46,119:INFO:_master_model_container: 19
2024-07-18 11:30:46,119:INFO:_display_container: 3
2024-07-18 11:30:46,119:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7173, splitter='best')
2024-07-18 11:30:46,119:INFO:create_model() successfully completed......................................
2024-07-18 11:30:46,181:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:46,181:INFO:Creating metrics dataframe
2024-07-18 11:30:46,181:INFO:Initializing SVM - Linear Kernel
2024-07-18 11:30:46,181:INFO:Total runtime is 0.2983478864034017 minutes
2024-07-18 11:30:46,197:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:46,197:INFO:Initializing create_model()
2024-07-18 11:30:46,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:46,197:INFO:Checking exceptions
2024-07-18 11:30:46,197:INFO:Importing libraries
2024-07-18 11:30:46,197:INFO:Copying training dataset
2024-07-18 11:30:46,197:INFO:Defining folds
2024-07-18 11:30:46,197:INFO:Declaring metric variables
2024-07-18 11:30:46,197:INFO:Importing untrained model
2024-07-18 11:30:46,197:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:30:46,197:INFO:Starting cross validation
2024-07-18 11:30:46,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:46,238:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:46,238:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:46,244:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:46,244:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:46,244:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:46,248:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:46,248:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:46,248:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:46,248:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:46,248:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,166:INFO:Calculating mean and std
2024-07-18 11:30:50,166:INFO:Creating metrics dataframe
2024-07-18 11:30:50,672:INFO:Uploading results into container
2024-07-18 11:30:50,672:INFO:Uploading model into container now
2024-07-18 11:30:50,672:INFO:_master_model_container: 20
2024-07-18 11:30:50,672:INFO:_display_container: 3
2024-07-18 11:30:50,672:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7173, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:30:50,672:INFO:create_model() successfully completed......................................
2024-07-18 11:30:50,734:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:50,734:INFO:Creating metrics dataframe
2024-07-18 11:30:50,734:INFO:Initializing Ridge Classifier
2024-07-18 11:30:50,734:INFO:Total runtime is 0.37423243522644045 minutes
2024-07-18 11:30:50,734:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:50,734:INFO:Initializing create_model()
2024-07-18 11:30:50,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:50,734:INFO:Checking exceptions
2024-07-18 11:30:50,734:INFO:Importing libraries
2024-07-18 11:30:50,734:INFO:Copying training dataset
2024-07-18 11:30:50,750:INFO:Defining folds
2024-07-18 11:30:50,750:INFO:Declaring metric variables
2024-07-18 11:30:50,750:INFO:Importing untrained model
2024-07-18 11:30:50,750:INFO:Ridge Classifier Imported successfully
2024-07-18 11:30:50,750:INFO:Starting cross validation
2024-07-18 11:30:50,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:50,787:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,787:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,787:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,787:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,787:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,787:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,787:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,798:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,798:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:50,798:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:30:54,561:INFO:Calculating mean and std
2024-07-18 11:30:54,561:INFO:Creating metrics dataframe
2024-07-18 11:30:55,060:INFO:Uploading results into container
2024-07-18 11:30:55,060:INFO:Uploading model into container now
2024-07-18 11:30:55,060:INFO:_master_model_container: 21
2024-07-18 11:30:55,060:INFO:_display_container: 3
2024-07-18 11:30:55,060:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7173, solver='auto',
                tol=0.0001)
2024-07-18 11:30:55,060:INFO:create_model() successfully completed......................................
2024-07-18 11:30:55,135:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:55,136:INFO:Creating metrics dataframe
2024-07-18 11:30:55,140:INFO:Initializing Random Forest Classifier
2024-07-18 11:30:55,140:INFO:Total runtime is 0.4476653854052226 minutes
2024-07-18 11:30:55,142:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:55,142:INFO:Initializing create_model()
2024-07-18 11:30:55,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:55,142:INFO:Checking exceptions
2024-07-18 11:30:55,142:INFO:Importing libraries
2024-07-18 11:30:55,142:INFO:Copying training dataset
2024-07-18 11:30:55,144:INFO:Defining folds
2024-07-18 11:30:55,144:INFO:Declaring metric variables
2024-07-18 11:30:55,146:INFO:Importing untrained model
2024-07-18 11:30:55,147:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:30:55,147:INFO:Starting cross validation
2024-07-18 11:30:55,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:30:59,021:INFO:Calculating mean and std
2024-07-18 11:30:59,021:INFO:Creating metrics dataframe
2024-07-18 11:30:59,530:INFO:Uploading results into container
2024-07-18 11:30:59,530:INFO:Uploading model into container now
2024-07-18 11:30:59,543:INFO:_master_model_container: 22
2024-07-18 11:30:59,543:INFO:_display_container: 3
2024-07-18 11:30:59,544:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7173, verbose=0, warm_start=False)
2024-07-18 11:30:59,544:INFO:create_model() successfully completed......................................
2024-07-18 11:30:59,598:INFO:SubProcess create_model() end ==================================
2024-07-18 11:30:59,598:INFO:Creating metrics dataframe
2024-07-18 11:30:59,610:INFO:Initializing Quadratic Discriminant Analysis
2024-07-18 11:30:59,610:INFO:Total runtime is 0.5221647143363953 minutes
2024-07-18 11:30:59,610:INFO:SubProcess create_model() called ==================================
2024-07-18 11:30:59,610:INFO:Initializing create_model()
2024-07-18 11:30:59,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:30:59,610:INFO:Checking exceptions
2024-07-18 11:30:59,610:INFO:Importing libraries
2024-07-18 11:30:59,610:INFO:Copying training dataset
2024-07-18 11:30:59,610:INFO:Defining folds
2024-07-18 11:30:59,610:INFO:Declaring metric variables
2024-07-18 11:30:59,610:INFO:Importing untrained model
2024-07-18 11:30:59,610:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:30:59,610:INFO:Starting cross validation
2024-07-18 11:30:59,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:03,370:INFO:Calculating mean and std
2024-07-18 11:31:03,370:INFO:Creating metrics dataframe
2024-07-18 11:31:03,877:INFO:Uploading results into container
2024-07-18 11:31:03,877:INFO:Uploading model into container now
2024-07-18 11:31:03,877:INFO:_master_model_container: 23
2024-07-18 11:31:03,877:INFO:_display_container: 3
2024-07-18 11:31:03,877:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:31:03,877:INFO:create_model() successfully completed......................................
2024-07-18 11:31:03,943:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:03,943:INFO:Creating metrics dataframe
2024-07-18 11:31:03,943:INFO:Initializing Ada Boost Classifier
2024-07-18 11:31:03,943:INFO:Total runtime is 0.5943857113520306 minutes
2024-07-18 11:31:03,943:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:03,943:INFO:Initializing create_model()
2024-07-18 11:31:03,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:03,943:INFO:Checking exceptions
2024-07-18 11:31:03,943:INFO:Importing libraries
2024-07-18 11:31:03,943:INFO:Copying training dataset
2024-07-18 11:31:03,943:INFO:Defining folds
2024-07-18 11:31:03,943:INFO:Declaring metric variables
2024-07-18 11:31:03,960:INFO:Importing untrained model
2024-07-18 11:31:03,960:INFO:Ada Boost Classifier Imported successfully
2024-07-18 11:31:03,960:INFO:Starting cross validation
2024-07-18 11:31:03,960:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:07,845:INFO:Calculating mean and std
2024-07-18 11:31:07,845:INFO:Creating metrics dataframe
2024-07-18 11:31:08,359:INFO:Uploading results into container
2024-07-18 11:31:08,359:INFO:Uploading model into container now
2024-07-18 11:31:08,359:INFO:_master_model_container: 24
2024-07-18 11:31:08,359:INFO:_display_container: 3
2024-07-18 11:31:08,359:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7173)
2024-07-18 11:31:08,359:INFO:create_model() successfully completed......................................
2024-07-18 11:31:08,430:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:08,430:INFO:Creating metrics dataframe
2024-07-18 11:31:08,431:INFO:Initializing Gradient Boosting Classifier
2024-07-18 11:31:08,431:INFO:Total runtime is 0.6691777308781943 minutes
2024-07-18 11:31:08,431:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:08,431:INFO:Initializing create_model()
2024-07-18 11:31:08,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:08,431:INFO:Checking exceptions
2024-07-18 11:31:08,431:INFO:Importing libraries
2024-07-18 11:31:08,431:INFO:Copying training dataset
2024-07-18 11:31:08,431:INFO:Defining folds
2024-07-18 11:31:08,431:INFO:Declaring metric variables
2024-07-18 11:31:08,431:INFO:Importing untrained model
2024-07-18 11:31:08,431:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:31:08,447:INFO:Starting cross validation
2024-07-18 11:31:08,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:12,358:INFO:Calculating mean and std
2024-07-18 11:31:12,360:INFO:Creating metrics dataframe
2024-07-18 11:31:12,859:INFO:Uploading results into container
2024-07-18 11:31:12,859:INFO:Uploading model into container now
2024-07-18 11:31:12,859:INFO:_master_model_container: 25
2024-07-18 11:31:12,859:INFO:_display_container: 3
2024-07-18 11:31:12,859:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7173, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:31:12,859:INFO:create_model() successfully completed......................................
2024-07-18 11:31:12,926:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:12,926:INFO:Creating metrics dataframe
2024-07-18 11:31:12,926:INFO:Initializing Linear Discriminant Analysis
2024-07-18 11:31:12,926:INFO:Total runtime is 0.7440981547037762 minutes
2024-07-18 11:31:12,926:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:12,926:INFO:Initializing create_model()
2024-07-18 11:31:12,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:12,926:INFO:Checking exceptions
2024-07-18 11:31:12,926:INFO:Importing libraries
2024-07-18 11:31:12,926:INFO:Copying training dataset
2024-07-18 11:31:12,926:INFO:Defining folds
2024-07-18 11:31:12,926:INFO:Declaring metric variables
2024-07-18 11:31:12,926:INFO:Importing untrained model
2024-07-18 11:31:12,943:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:31:12,943:INFO:Starting cross validation
2024-07-18 11:31:12,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:16,668:INFO:Calculating mean and std
2024-07-18 11:31:16,668:INFO:Creating metrics dataframe
2024-07-18 11:31:17,160:INFO:Uploading results into container
2024-07-18 11:31:17,160:INFO:Uploading model into container now
2024-07-18 11:31:17,160:INFO:_master_model_container: 26
2024-07-18 11:31:17,160:INFO:_display_container: 3
2024-07-18 11:31:17,160:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:31:17,160:INFO:create_model() successfully completed......................................
2024-07-18 11:31:17,226:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:17,226:INFO:Creating metrics dataframe
2024-07-18 11:31:17,226:INFO:Initializing Extra Trees Classifier
2024-07-18 11:31:17,226:INFO:Total runtime is 0.8157702604929608 minutes
2024-07-18 11:31:17,243:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:17,243:INFO:Initializing create_model()
2024-07-18 11:31:17,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:17,243:INFO:Checking exceptions
2024-07-18 11:31:17,243:INFO:Importing libraries
2024-07-18 11:31:17,243:INFO:Copying training dataset
2024-07-18 11:31:17,243:INFO:Defining folds
2024-07-18 11:31:17,243:INFO:Declaring metric variables
2024-07-18 11:31:17,243:INFO:Importing untrained model
2024-07-18 11:31:17,243:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:31:17,243:INFO:Starting cross validation
2024-07-18 11:31:17,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:21,163:INFO:Calculating mean and std
2024-07-18 11:31:21,163:INFO:Creating metrics dataframe
2024-07-18 11:31:21,660:INFO:Uploading results into container
2024-07-18 11:31:21,660:INFO:Uploading model into container now
2024-07-18 11:31:21,660:INFO:_master_model_container: 27
2024-07-18 11:31:21,660:INFO:_display_container: 3
2024-07-18 11:31:21,675:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7173, verbose=0, warm_start=False)
2024-07-18 11:31:21,675:INFO:create_model() successfully completed......................................
2024-07-18 11:31:21,728:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:21,728:INFO:Creating metrics dataframe
2024-07-18 11:31:21,745:INFO:Initializing Extreme Gradient Boosting
2024-07-18 11:31:21,745:INFO:Total runtime is 0.8910718441009523 minutes
2024-07-18 11:31:21,746:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:21,746:INFO:Initializing create_model()
2024-07-18 11:31:21,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:21,746:INFO:Checking exceptions
2024-07-18 11:31:21,746:INFO:Importing libraries
2024-07-18 11:31:21,746:INFO:Copying training dataset
2024-07-18 11:31:21,746:INFO:Defining folds
2024-07-18 11:31:21,746:INFO:Declaring metric variables
2024-07-18 11:31:21,746:INFO:Importing untrained model
2024-07-18 11:31:21,746:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:31:21,746:INFO:Starting cross validation
2024-07-18 11:31:21,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:25,495:INFO:Calculating mean and std
2024-07-18 11:31:25,496:INFO:Creating metrics dataframe
2024-07-18 11:31:25,993:INFO:Uploading results into container
2024-07-18 11:31:25,993:INFO:Uploading model into container now
2024-07-18 11:31:25,993:INFO:_master_model_container: 28
2024-07-18 11:31:25,993:INFO:_display_container: 3
2024-07-18 11:31:25,993:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:31:25,993:INFO:create_model() successfully completed......................................
2024-07-18 11:31:26,072:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:26,072:INFO:Creating metrics dataframe
2024-07-18 11:31:26,076:INFO:Initializing Light Gradient Boosting Machine
2024-07-18 11:31:26,076:INFO:Total runtime is 0.9632631580034894 minutes
2024-07-18 11:31:26,076:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:26,076:INFO:Initializing create_model()
2024-07-18 11:31:26,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:26,076:INFO:Checking exceptions
2024-07-18 11:31:26,076:INFO:Importing libraries
2024-07-18 11:31:26,076:INFO:Copying training dataset
2024-07-18 11:31:26,076:INFO:Defining folds
2024-07-18 11:31:26,076:INFO:Declaring metric variables
2024-07-18 11:31:26,076:INFO:Importing untrained model
2024-07-18 11:31:26,076:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:31:26,076:INFO:Starting cross validation
2024-07-18 11:31:26,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:29,949:INFO:Calculating mean and std
2024-07-18 11:31:29,949:INFO:Creating metrics dataframe
2024-07-18 11:31:30,459:INFO:Uploading results into container
2024-07-18 11:31:30,459:INFO:Uploading model into container now
2024-07-18 11:31:30,459:INFO:_master_model_container: 29
2024-07-18 11:31:30,460:INFO:_display_container: 3
2024-07-18 11:31:30,460:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7173, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:31:30,460:INFO:create_model() successfully completed......................................
2024-07-18 11:31:30,530:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:30,531:INFO:Creating metrics dataframe
2024-07-18 11:31:30,536:INFO:Initializing CatBoost Classifier
2024-07-18 11:31:30,536:INFO:Total runtime is 1.0376031200091047 minutes
2024-07-18 11:31:30,538:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:30,539:INFO:Initializing create_model()
2024-07-18 11:31:30,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DA790EF50>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:30,539:INFO:Checking exceptions
2024-07-18 11:31:30,539:INFO:Importing libraries
2024-07-18 11:31:30,539:INFO:Copying training dataset
2024-07-18 11:31:30,540:INFO:Defining folds
2024-07-18 11:31:30,540:INFO:Declaring metric variables
2024-07-18 11:31:30,542:INFO:Importing untrained model
2024-07-18 11:31:30,544:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:31:30,547:INFO:Starting cross validation
2024-07-18 11:31:30,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:34,348:INFO:Calculating mean and std
2024-07-18 11:31:34,348:INFO:Creating metrics dataframe
2024-07-18 11:31:34,863:INFO:Uploading results into container
2024-07-18 11:31:34,863:INFO:Uploading model into container now
2024-07-18 11:31:34,863:INFO:_master_model_container: 30
2024-07-18 11:31:34,863:INFO:_display_container: 3
2024-07-18 11:31:34,864:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DAB796B90>
2024-07-18 11:31:34,864:INFO:create_model() successfully completed......................................
2024-07-18 11:31:34,926:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:34,926:INFO:Creating metrics dataframe
2024-07-18 11:31:34,926:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-18 11:31:34,926:INFO:Initializing create_model()
2024-07-18 11:31:34,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAAF83110>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:34,926:INFO:Checking exceptions
2024-07-18 11:31:34,942:INFO:Importing libraries
2024-07-18 11:31:34,942:INFO:Copying training dataset
2024-07-18 11:31:34,943:INFO:Defining folds
2024-07-18 11:31:34,943:INFO:Declaring metric variables
2024-07-18 11:31:34,943:INFO:Importing untrained model
2024-07-18 11:31:34,943:INFO:Declaring custom model
2024-07-18 11:31:34,943:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:31:34,943:INFO:Cross validation set to False
2024-07-18 11:31:34,943:INFO:Fitting Model
2024-07-18 11:31:35,443:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:31:35,443:INFO:create_model() successfully completed......................................
2024-07-18 11:31:35,531:INFO:_master_model_container: 30
2024-07-18 11:31:35,531:INFO:_display_container: 3
2024-07-18 11:31:35,531:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:31:35,531:INFO:compare_models() successfully completed......................................
2024-07-18 11:31:35,534:INFO:Initializing save_model()
2024-07-18 11:31:35,534:INFO:save_model(model=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), model_name=GPU_0_EPPD_ML_VALIDATION_7525/XGBClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:35,534:INFO:Adding model into prep_pipe
2024-07-18 11:31:35,539:INFO:GPU_0_EPPD_ML_VALIDATION_7525/XGBClassifier.pkl saved in current working directory
2024-07-18 11:31:35,545:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-07-18 11:31:35,545:INFO:save_model() successfully completed......................................
2024-07-18 11:31:36,041:INFO:Initializing save_model()
2024-07-18 11:31:36,041:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7173, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=GPU_0_EPPD_ML_VALIDATION_7525/LGBMClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:36,041:INFO:Adding model into prep_pipe
2024-07-18 11:31:36,050:INFO:GPU_0_EPPD_ML_VALIDATION_7525/LGBMClassifier.pkl saved in current working directory
2024-07-18 11:31:36,054:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=7173, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-18 11:31:36,054:INFO:save_model() successfully completed......................................
2024-07-18 11:31:36,530:INFO:Initializing save_model()
2024-07-18 11:31:36,530:INFO:save_model(model=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), model_name=GPU_0_EPPD_ML_VALIDATION_7525/KNeighborsClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:36,530:INFO:Adding model into prep_pipe
2024-07-18 11:31:36,532:INFO:GPU_0_EPPD_ML_VALIDATION_7525/KNeighborsClassifier.pkl saved in current working directory
2024-07-18 11:31:36,534:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False)
2024-07-18 11:31:36,534:INFO:save_model() successfully completed......................................
2024-07-18 11:31:37,021:INFO:Initializing save_model()
2024-07-18 11:31:37,021:INFO:save_model(model=<catboost.core.CatBoostClassifier object at 0x0000021DAB8063D0>, model_name=GPU_0_EPPD_ML_VALIDATION_7525/CatBoostClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:37,021:INFO:Adding model into prep_pipe
2024-07-18 11:31:37,024:INFO:GPU_0_EPPD_ML_VALIDATION_7525/CatBoostClassifier.pkl saved in current working directory
2024-07-18 11:31:37,026:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x0000021DAB8063D0>)],
         verbose=False)
2024-07-18 11:31:37,026:INFO:save_model() successfully completed......................................
2024-07-18 11:31:37,501:INFO:Initializing save_model()
2024-07-18 11:31:37,501:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7173, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_7525/GradientBoostingClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:37,501:INFO:Adding model into prep_pipe
2024-07-18 11:31:37,505:INFO:GPU_0_EPPD_ML_VALIDATION_7525/GradientBoostingClassifier.pkl saved in current working directory
2024-07-18 11:31:37,507:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=7173, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:31:37,507:INFO:save_model() successfully completed......................................
2024-07-18 11:31:37,984:INFO:Initializing save_model()
2024-07-18 11:31:37,984:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7173, verbose=0, warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_7525/RandomForestClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:37,984:INFO:Adding model into prep_pipe
2024-07-18 11:31:38,004:INFO:GPU_0_EPPD_ML_VALIDATION_7525/RandomForestClassifier.pkl saved in current working directory
2024-07-18 11:31:38,006:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=7173,
                                        verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:31:38,006:INFO:save_model() successfully completed......................................
2024-07-18 11:31:38,459:INFO:Initializing save_model()
2024-07-18 11:31:38,459:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7173, splitter='best'), model_name=GPU_0_EPPD_ML_VALIDATION_7525/DecisionTreeClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:38,459:INFO:Adding model into prep_pipe
2024-07-18 11:31:38,473:INFO:GPU_0_EPPD_ML_VALIDATION_7525/DecisionTreeClassifier.pkl saved in current working directory
2024-07-18 11:31:38,473:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=7173, splitter='best'))],
         verbose=False)
2024-07-18 11:31:38,473:INFO:save_model() successfully completed......................................
2024-07-18 11:31:38,942:INFO:Initializing save_model()
2024-07-18 11:31:38,942:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7173), model_name=GPU_0_EPPD_ML_VALIDATION_7525/AdaBoostClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:38,942:INFO:Adding model into prep_pipe
2024-07-18 11:31:38,952:INFO:GPU_0_EPPD_ML_VALIDATION_7525/AdaBoostClassifier.pkl saved in current working directory
2024-07-18 11:31:38,954:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=7173))],
         verbose=False)
2024-07-18 11:31:38,954:INFO:save_model() successfully completed......................................
2024-07-18 11:31:39,425:INFO:Initializing save_model()
2024-07-18 11:31:39,425:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7173, verbose=0, warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_7525/ExtraTreesClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:39,425:INFO:Adding model into prep_pipe
2024-07-18 11:31:39,445:INFO:GPU_0_EPPD_ML_VALIDATION_7525/ExtraTreesClassifier.pkl saved in current working directory
2024-07-18 11:31:39,448:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=7173,
                                      verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:31:39,448:INFO:save_model() successfully completed......................................
2024-07-18 11:31:39,932:INFO:Initializing save_model()
2024-07-18 11:31:39,933:INFO:save_model(model=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), model_name=GPU_0_EPPD_ML_VALIDATION_7525/QuadraticDiscriminantAnalysis, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:39,933:INFO:Adding model into prep_pipe
2024-07-18 11:31:39,935:INFO:GPU_0_EPPD_ML_VALIDATION_7525/QuadraticDiscriminantAnalysis.pkl saved in current working directory
2024-07-18 11:31:39,937:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False)
2024-07-18 11:31:39,937:INFO:save_model() successfully completed......................................
2024-07-18 11:31:40,409:INFO:Initializing save_model()
2024-07-18 11:31:40,409:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=GPU_0_EPPD_ML_VALIDATION_7525/GaussianNB, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:40,409:INFO:Adding model into prep_pipe
2024-07-18 11:31:40,409:INFO:GPU_0_EPPD_ML_VALIDATION_7525/GaussianNB.pkl saved in current working directory
2024-07-18 11:31:40,409:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2024-07-18 11:31:40,409:INFO:save_model() successfully completed......................................
2024-07-18 11:31:40,884:INFO:Initializing save_model()
2024-07-18 11:31:40,884:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7173, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_7525/LogisticRegression, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:40,884:INFO:Adding model into prep_pipe
2024-07-18 11:31:40,886:INFO:GPU_0_EPPD_ML_VALIDATION_7525/LogisticRegression.pkl saved in current working directory
2024-07-18 11:31:40,888:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=7173,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-07-18 11:31:40,888:INFO:save_model() successfully completed......................................
2024-07-18 11:31:41,350:INFO:Initializing save_model()
2024-07-18 11:31:41,350:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7173, solver='auto',
                tol=0.0001), model_name=GPU_0_EPPD_ML_VALIDATION_7525/RidgeClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:41,350:INFO:Adding model into prep_pipe
2024-07-18 11:31:41,352:INFO:GPU_0_EPPD_ML_VALIDATION_7525/RidgeClassifier.pkl saved in current working directory
2024-07-18 11:31:41,354:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=7173,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2024-07-18 11:31:41,354:INFO:save_model() successfully completed......................................
2024-07-18 11:31:41,822:INFO:Initializing save_model()
2024-07-18 11:31:41,822:INFO:save_model(model=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), model_name=GPU_0_EPPD_ML_VALIDATION_7525/LinearDiscriminantAnalysis, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:41,822:INFO:Adding model into prep_pipe
2024-07-18 11:31:41,824:INFO:GPU_0_EPPD_ML_VALIDATION_7525/LinearDiscriminantAnalysis.pkl saved in current working directory
2024-07-18 11:31:41,827:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2024-07-18 11:31:41,827:INFO:save_model() successfully completed......................................
2024-07-18 11:31:42,300:INFO:Initializing save_model()
2024-07-18 11:31:42,300:INFO:save_model(model=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7173, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_7525/SGDClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:31:42,300:INFO:Adding model into prep_pipe
2024-07-18 11:31:42,302:INFO:GPU_0_EPPD_ML_VALIDATION_7525/SGDClassifier.pkl saved in current working directory
2024-07-18 11:31:42,304:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=7173,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:31:42,304:INFO:save_model() successfully completed......................................
2024-07-18 11:31:42,759:WARNING:C:\Users\JAL\AppData\Local\Temp\ipykernel_17160\2873217847.py:105: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  best_model[best_model.select_dtypes(include=['number']).columns] *= 100

2024-07-18 11:31:43,547:INFO:PyCaret ClassificationExperiment
2024-07-18 11:31:43,547:INFO:Logging name: clf-default-name
2024-07-18 11:31:43,547:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-18 11:31:43,547:INFO:version 3.0.0
2024-07-18 11:31:43,547:INFO:Initializing setup()
2024-07-18 11:31:43,547:INFO:self.USI: 238c
2024-07-18 11:31:43,547:INFO:self._variable_keys: {'n_jobs_param', 'fix_imbalance', 'exp_id', 'y_test', 'is_multiclass', '_ml_usecase', 'html_param', 'target_param', 'USI', 'gpu_param', 'log_plots_param', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'fold_generator', 'logging_param', 'y_train', 'fold_groups_param', 'seed', 'idx', 'X_test', 'X', 'data', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'y'}
2024-07-18 11:31:43,547:INFO:Checking environment
2024-07-18 11:31:43,547:INFO:python_version: 3.11.4
2024-07-18 11:31:43,547:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2024-07-18 11:31:43,547:INFO:machine: AMD64
2024-07-18 11:31:43,547:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-18 11:31:43,559:INFO:Memory: svmem(total=68659781632, available=47074803712, percent=31.4, used=21584977920, free=47074803712)
2024-07-18 11:31:43,559:INFO:Physical Core: 16
2024-07-18 11:31:43,559:INFO:Logical Core: 32
2024-07-18 11:31:43,559:INFO:Checking libraries
2024-07-18 11:31:43,559:INFO:System:
2024-07-18 11:31:43,559:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2024-07-18 11:31:43,559:INFO:executable: c:\Users\JAL\AppData\Local\Programs\Python\Python311\python.exe
2024-07-18 11:31:43,559:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-18 11:31:43,559:INFO:PyCaret required dependencies:
2024-07-18 11:31:43,559:INFO:                 pip: 24.1.2
2024-07-18 11:31:43,559:INFO:          setuptools: 70.3.0
2024-07-18 11:31:43,559:INFO:             pycaret: 3.0.0
2024-07-18 11:31:43,559:INFO:             IPython: 8.15.0
2024-07-18 11:31:43,559:INFO:          ipywidgets: 8.1.3
2024-07-18 11:31:43,559:INFO:                tqdm: 4.66.4
2024-07-18 11:31:43,559:INFO:               numpy: 1.24.4
2024-07-18 11:31:43,559:INFO:              pandas: 2.2.2
2024-07-18 11:31:43,559:INFO:              jinja2: 3.1.4
2024-07-18 11:31:43,559:INFO:               scipy: 1.11.4
2024-07-18 11:31:43,559:INFO:              joblib: 1.3.2
2024-07-18 11:31:43,559:INFO:             sklearn: 1.3.0
2024-07-18 11:31:43,559:INFO:                pyod: 2.0.1
2024-07-18 11:31:43,559:INFO:            imblearn: 0.12.3
2024-07-18 11:31:43,559:INFO:   category_encoders: 2.6.3
2024-07-18 11:31:43,559:INFO:            lightgbm: 4.3.0
2024-07-18 11:31:43,559:INFO:               numba: 0.60.0
2024-07-18 11:31:43,559:INFO:            requests: 2.32.3
2024-07-18 11:31:43,559:INFO:          matplotlib: 3.7.5
2024-07-18 11:31:43,559:INFO:          scikitplot: 0.3.7
2024-07-18 11:31:43,559:INFO:         yellowbrick: 1.5
2024-07-18 11:31:43,559:INFO:              plotly: 5.22.0
2024-07-18 11:31:43,559:INFO:             kaleido: 0.2.1
2024-07-18 11:31:43,559:INFO:         statsmodels: 0.14.2
2024-07-18 11:31:43,559:INFO:              sktime: 0.26.0
2024-07-18 11:31:43,559:INFO:               tbats: 1.1.3
2024-07-18 11:31:43,559:INFO:            pmdarima: 2.0.4
2024-07-18 11:31:43,559:INFO:              psutil: 5.9.5
2024-07-18 11:31:43,559:INFO:PyCaret optional dependencies:
2024-07-18 11:31:43,559:INFO:                shap: Not installed
2024-07-18 11:31:43,559:INFO:           interpret: Not installed
2024-07-18 11:31:43,559:INFO:                umap: Not installed
2024-07-18 11:31:43,559:INFO:    pandas_profiling: Not installed
2024-07-18 11:31:43,559:INFO:  explainerdashboard: Not installed
2024-07-18 11:31:43,559:INFO:             autoviz: Not installed
2024-07-18 11:31:43,559:INFO:           fairlearn: Not installed
2024-07-18 11:31:43,559:INFO:             xgboost: 2.0.3
2024-07-18 11:31:43,559:INFO:            catboost: 1.2.5
2024-07-18 11:31:43,559:INFO:              kmodes: Not installed
2024-07-18 11:31:43,559:INFO:             mlxtend: Not installed
2024-07-18 11:31:43,559:INFO:       statsforecast: 1.4.0
2024-07-18 11:31:43,559:INFO:        tune_sklearn: Not installed
2024-07-18 11:31:43,559:INFO:                 ray: 2.10.0
2024-07-18 11:31:43,559:INFO:            hyperopt: 0.2.7
2024-07-18 11:31:43,559:INFO:              optuna: Not installed
2024-07-18 11:31:43,559:INFO:               skopt: Not installed
2024-07-18 11:31:43,559:INFO:              mlflow: Not installed
2024-07-18 11:31:43,559:INFO:              gradio: Not installed
2024-07-18 11:31:43,559:INFO:             fastapi: Not installed
2024-07-18 11:31:43,559:INFO:             uvicorn: Not installed
2024-07-18 11:31:43,559:INFO:              m2cgen: Not installed
2024-07-18 11:31:43,559:INFO:           evidently: Not installed
2024-07-18 11:31:43,559:INFO:               fugue: Not installed
2024-07-18 11:31:43,559:INFO:           streamlit: 1.31.0
2024-07-18 11:31:43,559:INFO:             prophet: Not installed
2024-07-18 11:31:43,559:INFO:None
2024-07-18 11:31:43,559:INFO:Set up data.
2024-07-18 11:31:43,562:INFO:Set up train/test split.
2024-07-18 11:31:43,562:INFO:Set up index.
2024-07-18 11:31:43,562:INFO:Set up folding strategy.
2024-07-18 11:31:43,562:INFO:Assigning column types.
2024-07-18 11:31:43,562:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-18 11:31:43,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 11:31:43,592:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:31:43,609:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:31:43,609:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:31:43,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-18 11:31:43,642:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:31:43,659:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:31:43,659:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:31:43,659:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-18 11:31:43,691:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:31:43,709:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:31:43,709:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:31:43,726:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-18 11:31:43,757:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:31:43,759:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:31:43,759:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-18 11:31:43,805:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:31:43,807:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:31:43,855:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:31:43,857:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:31:43,858:INFO:Preparing preprocessing pipeline...
2024-07-18 11:31:43,858:INFO:Set up simple imputation.
2024-07-18 11:31:43,867:INFO:Finished creating preprocessing pipeline.
2024-07-18 11:31:43,868:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-18 11:31:43,868:INFO:Creating final display dataframe.
2024-07-18 11:31:43,896:INFO:Setup _display_container:                     Description             Value
0                    Session id              7665
1                        Target       PlacedOrNot
2                   Target type            Binary
3           Original data shape         (2966, 4)
4        Transformed data shape         (2966, 4)
5   Transformed train set shape         (2076, 4)
6    Transformed test set shape          (890, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              238c
2024-07-18 11:31:43,945:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:31:43,947:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:31:43,994:INFO:Soft dependency imported: xgboost: 2.0.3
2024-07-18 11:31:43,994:INFO:Soft dependency imported: catboost: 1.2.5
2024-07-18 11:31:43,994:INFO:setup() successfully completed in 0.83s...............
2024-07-18 11:31:43,994:INFO:Initializing compare_models()
2024-07-18 11:31:43,994:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-18 11:31:43,994:INFO:Checking exceptions
2024-07-18 11:31:43,994:INFO:Preparing display monitor
2024-07-18 11:31:43,994:INFO:Initializing Logistic Regression
2024-07-18 11:31:43,994:INFO:Total runtime is 0.0 minutes
2024-07-18 11:31:44,010:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:44,010:INFO:Initializing create_model()
2024-07-18 11:31:44,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:44,011:INFO:Checking exceptions
2024-07-18 11:31:44,011:INFO:Importing libraries
2024-07-18 11:31:44,011:INFO:Copying training dataset
2024-07-18 11:31:44,011:INFO:Defining folds
2024-07-18 11:31:44,011:INFO:Declaring metric variables
2024-07-18 11:31:44,011:INFO:Importing untrained model
2024-07-18 11:31:44,011:INFO:Logistic Regression Imported successfully
2024-07-18 11:31:44,019:INFO:Starting cross validation
2024-07-18 11:31:44,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:47,785:INFO:Calculating mean and std
2024-07-18 11:31:47,785:INFO:Creating metrics dataframe
2024-07-18 11:31:48,276:INFO:Uploading results into container
2024-07-18 11:31:48,276:INFO:Uploading model into container now
2024-07-18 11:31:48,276:INFO:_master_model_container: 1
2024-07-18 11:31:48,276:INFO:_display_container: 2
2024-07-18 11:31:48,276:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7665, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:31:48,276:INFO:create_model() successfully completed......................................
2024-07-18 11:31:48,342:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:48,342:INFO:Creating metrics dataframe
2024-07-18 11:31:48,342:INFO:Initializing K Neighbors Classifier
2024-07-18 11:31:48,342:INFO:Total runtime is 0.0724802295366923 minutes
2024-07-18 11:31:48,342:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:48,342:INFO:Initializing create_model()
2024-07-18 11:31:48,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:48,342:INFO:Checking exceptions
2024-07-18 11:31:48,342:INFO:Importing libraries
2024-07-18 11:31:48,342:INFO:Copying training dataset
2024-07-18 11:31:48,342:INFO:Defining folds
2024-07-18 11:31:48,342:INFO:Declaring metric variables
2024-07-18 11:31:48,359:INFO:Importing untrained model
2024-07-18 11:31:48,359:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:31:48,359:INFO:Starting cross validation
2024-07-18 11:31:48,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:52,142:INFO:Calculating mean and std
2024-07-18 11:31:52,142:INFO:Creating metrics dataframe
2024-07-18 11:31:52,655:INFO:Uploading results into container
2024-07-18 11:31:52,656:INFO:Uploading model into container now
2024-07-18 11:31:52,656:INFO:_master_model_container: 2
2024-07-18 11:31:52,656:INFO:_display_container: 2
2024-07-18 11:31:52,656:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:31:52,657:INFO:create_model() successfully completed......................................
2024-07-18 11:31:52,722:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:52,722:INFO:Creating metrics dataframe
2024-07-18 11:31:52,726:INFO:Initializing Naive Bayes
2024-07-18 11:31:52,727:INFO:Total runtime is 0.14555352528889973 minutes
2024-07-18 11:31:52,728:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:52,729:INFO:Initializing create_model()
2024-07-18 11:31:52,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:52,729:INFO:Checking exceptions
2024-07-18 11:31:52,729:INFO:Importing libraries
2024-07-18 11:31:52,729:INFO:Copying training dataset
2024-07-18 11:31:52,730:INFO:Defining folds
2024-07-18 11:31:52,731:INFO:Declaring metric variables
2024-07-18 11:31:52,732:INFO:Importing untrained model
2024-07-18 11:31:52,734:INFO:Naive Bayes Imported successfully
2024-07-18 11:31:52,738:INFO:Starting cross validation
2024-07-18 11:31:52,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:31:56,508:INFO:Calculating mean and std
2024-07-18 11:31:56,509:INFO:Creating metrics dataframe
2024-07-18 11:31:57,009:INFO:Uploading results into container
2024-07-18 11:31:57,009:INFO:Uploading model into container now
2024-07-18 11:31:57,009:INFO:_master_model_container: 3
2024-07-18 11:31:57,009:INFO:_display_container: 2
2024-07-18 11:31:57,009:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:31:57,009:INFO:create_model() successfully completed......................................
2024-07-18 11:31:57,076:INFO:SubProcess create_model() end ==================================
2024-07-18 11:31:57,076:INFO:Creating metrics dataframe
2024-07-18 11:31:57,076:INFO:Initializing Decision Tree Classifier
2024-07-18 11:31:57,076:INFO:Total runtime is 0.21803350448608397 minutes
2024-07-18 11:31:57,076:INFO:SubProcess create_model() called ==================================
2024-07-18 11:31:57,076:INFO:Initializing create_model()
2024-07-18 11:31:57,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:31:57,076:INFO:Checking exceptions
2024-07-18 11:31:57,076:INFO:Importing libraries
2024-07-18 11:31:57,076:INFO:Copying training dataset
2024-07-18 11:31:57,076:INFO:Defining folds
2024-07-18 11:31:57,076:INFO:Declaring metric variables
2024-07-18 11:31:57,091:INFO:Importing untrained model
2024-07-18 11:31:57,092:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:31:57,097:INFO:Starting cross validation
2024-07-18 11:31:57,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:00,874:INFO:Calculating mean and std
2024-07-18 11:32:00,875:INFO:Creating metrics dataframe
2024-07-18 11:32:01,379:INFO:Uploading results into container
2024-07-18 11:32:01,379:INFO:Uploading model into container now
2024-07-18 11:32:01,379:INFO:_master_model_container: 4
2024-07-18 11:32:01,380:INFO:_display_container: 2
2024-07-18 11:32:01,380:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7665, splitter='best')
2024-07-18 11:32:01,380:INFO:create_model() successfully completed......................................
2024-07-18 11:32:01,441:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:01,441:INFO:Creating metrics dataframe
2024-07-18 11:32:01,442:INFO:Initializing SVM - Linear Kernel
2024-07-18 11:32:01,442:INFO:Total runtime is 0.290810219446818 minutes
2024-07-18 11:32:01,442:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:01,442:INFO:Initializing create_model()
2024-07-18 11:32:01,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:01,442:INFO:Checking exceptions
2024-07-18 11:32:01,442:INFO:Importing libraries
2024-07-18 11:32:01,442:INFO:Copying training dataset
2024-07-18 11:32:01,442:INFO:Defining folds
2024-07-18 11:32:01,442:INFO:Declaring metric variables
2024-07-18 11:32:01,442:INFO:Importing untrained model
2024-07-18 11:32:01,442:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:32:01,442:INFO:Starting cross validation
2024-07-18 11:32:01,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:01,493:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:01,494:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:01,494:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:01,495:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:01,496:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:01,498:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:01,498:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:01,498:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:01,498:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:01,510:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,234:INFO:Calculating mean and std
2024-07-18 11:32:05,235:INFO:Creating metrics dataframe
2024-07-18 11:32:05,741:INFO:Uploading results into container
2024-07-18 11:32:05,742:INFO:Uploading model into container now
2024-07-18 11:32:05,742:INFO:_master_model_container: 5
2024-07-18 11:32:05,742:INFO:_display_container: 2
2024-07-18 11:32:05,742:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7665, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:32:05,742:INFO:create_model() successfully completed......................................
2024-07-18 11:32:05,795:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:05,795:INFO:Creating metrics dataframe
2024-07-18 11:32:05,809:INFO:Initializing Ridge Classifier
2024-07-18 11:32:05,809:INFO:Total runtime is 0.3635860919952392 minutes
2024-07-18 11:32:05,809:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:05,809:INFO:Initializing create_model()
2024-07-18 11:32:05,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:05,809:INFO:Checking exceptions
2024-07-18 11:32:05,809:INFO:Importing libraries
2024-07-18 11:32:05,809:INFO:Copying training dataset
2024-07-18 11:32:05,809:INFO:Defining folds
2024-07-18 11:32:05,809:INFO:Declaring metric variables
2024-07-18 11:32:05,809:INFO:Importing untrained model
2024-07-18 11:32:05,809:INFO:Ridge Classifier Imported successfully
2024-07-18 11:32:05,809:INFO:Starting cross validation
2024-07-18 11:32:05,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:05,846:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,851:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,851:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,851:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,851:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,851:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,859:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,860:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,862:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:05,862:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:32:09,597:INFO:Calculating mean and std
2024-07-18 11:32:09,597:INFO:Creating metrics dataframe
2024-07-18 11:32:10,104:INFO:Uploading results into container
2024-07-18 11:32:10,104:INFO:Uploading model into container now
2024-07-18 11:32:10,104:INFO:_master_model_container: 6
2024-07-18 11:32:10,105:INFO:_display_container: 2
2024-07-18 11:32:10,105:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7665, solver='auto',
                tol=0.0001)
2024-07-18 11:32:10,105:INFO:create_model() successfully completed......................................
2024-07-18 11:32:10,167:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:10,167:INFO:Creating metrics dataframe
2024-07-18 11:32:10,171:INFO:Initializing Random Forest Classifier
2024-07-18 11:32:10,171:INFO:Total runtime is 0.4362962007522583 minutes
2024-07-18 11:32:10,173:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:10,173:INFO:Initializing create_model()
2024-07-18 11:32:10,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:10,173:INFO:Checking exceptions
2024-07-18 11:32:10,173:INFO:Importing libraries
2024-07-18 11:32:10,174:INFO:Copying training dataset
2024-07-18 11:32:10,175:INFO:Defining folds
2024-07-18 11:32:10,175:INFO:Declaring metric variables
2024-07-18 11:32:10,177:INFO:Importing untrained model
2024-07-18 11:32:10,179:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:32:10,183:INFO:Starting cross validation
2024-07-18 11:32:10,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:14,207:INFO:Calculating mean and std
2024-07-18 11:32:14,208:INFO:Creating metrics dataframe
2024-07-18 11:32:14,692:INFO:Uploading results into container
2024-07-18 11:32:14,692:INFO:Uploading model into container now
2024-07-18 11:32:14,708:INFO:_master_model_container: 7
2024-07-18 11:32:14,708:INFO:_display_container: 2
2024-07-18 11:32:14,708:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7665, verbose=0, warm_start=False)
2024-07-18 11:32:14,708:INFO:create_model() successfully completed......................................
2024-07-18 11:32:14,759:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:14,759:INFO:Creating metrics dataframe
2024-07-18 11:32:14,759:INFO:Initializing Quadratic Discriminant Analysis
2024-07-18 11:32:14,759:INFO:Total runtime is 0.5127508918444316 minutes
2024-07-18 11:32:14,775:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:14,775:INFO:Initializing create_model()
2024-07-18 11:32:14,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:14,775:INFO:Checking exceptions
2024-07-18 11:32:14,775:INFO:Importing libraries
2024-07-18 11:32:14,775:INFO:Copying training dataset
2024-07-18 11:32:14,777:INFO:Defining folds
2024-07-18 11:32:14,777:INFO:Declaring metric variables
2024-07-18 11:32:14,778:INFO:Importing untrained model
2024-07-18 11:32:14,778:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:32:14,778:INFO:Starting cross validation
2024-07-18 11:32:14,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:18,570:INFO:Calculating mean and std
2024-07-18 11:32:18,570:INFO:Creating metrics dataframe
2024-07-18 11:32:19,095:INFO:Uploading results into container
2024-07-18 11:32:19,095:INFO:Uploading model into container now
2024-07-18 11:32:19,095:INFO:_master_model_container: 8
2024-07-18 11:32:19,095:INFO:_display_container: 2
2024-07-18 11:32:19,095:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:32:19,095:INFO:create_model() successfully completed......................................
2024-07-18 11:32:19,160:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:19,161:INFO:Creating metrics dataframe
2024-07-18 11:32:19,166:INFO:Initializing Ada Boost Classifier
2024-07-18 11:32:19,166:INFO:Total runtime is 0.5862070719401041 minutes
2024-07-18 11:32:19,168:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:19,168:INFO:Initializing create_model()
2024-07-18 11:32:19,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:19,168:INFO:Checking exceptions
2024-07-18 11:32:19,168:INFO:Importing libraries
2024-07-18 11:32:19,168:INFO:Copying training dataset
2024-07-18 11:32:19,170:INFO:Defining folds
2024-07-18 11:32:19,170:INFO:Declaring metric variables
2024-07-18 11:32:19,172:INFO:Importing untrained model
2024-07-18 11:32:19,173:INFO:Ada Boost Classifier Imported successfully
2024-07-18 11:32:19,178:INFO:Starting cross validation
2024-07-18 11:32:19,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:23,060:INFO:Calculating mean and std
2024-07-18 11:32:23,061:INFO:Creating metrics dataframe
2024-07-18 11:32:23,571:INFO:Uploading results into container
2024-07-18 11:32:23,572:INFO:Uploading model into container now
2024-07-18 11:32:23,572:INFO:_master_model_container: 9
2024-07-18 11:32:23,572:INFO:_display_container: 2
2024-07-18 11:32:23,572:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7665)
2024-07-18 11:32:23,572:INFO:create_model() successfully completed......................................
2024-07-18 11:32:23,628:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:23,628:INFO:Creating metrics dataframe
2024-07-18 11:32:23,628:INFO:Initializing Gradient Boosting Classifier
2024-07-18 11:32:23,628:INFO:Total runtime is 0.6605691234270731 minutes
2024-07-18 11:32:23,642:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:23,642:INFO:Initializing create_model()
2024-07-18 11:32:23,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:23,642:INFO:Checking exceptions
2024-07-18 11:32:23,642:INFO:Importing libraries
2024-07-18 11:32:23,642:INFO:Copying training dataset
2024-07-18 11:32:23,642:INFO:Defining folds
2024-07-18 11:32:23,642:INFO:Declaring metric variables
2024-07-18 11:32:23,642:INFO:Importing untrained model
2024-07-18 11:32:23,642:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:32:23,642:INFO:Starting cross validation
2024-07-18 11:32:23,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:27,565:INFO:Calculating mean and std
2024-07-18 11:32:27,566:INFO:Creating metrics dataframe
2024-07-18 11:32:28,089:INFO:Uploading results into container
2024-07-18 11:32:28,090:INFO:Uploading model into container now
2024-07-18 11:32:28,090:INFO:_master_model_container: 10
2024-07-18 11:32:28,090:INFO:_display_container: 2
2024-07-18 11:32:28,090:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7665, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:32:28,090:INFO:create_model() successfully completed......................................
2024-07-18 11:32:28,154:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:28,154:INFO:Creating metrics dataframe
2024-07-18 11:32:28,160:INFO:Initializing Linear Discriminant Analysis
2024-07-18 11:32:28,160:INFO:Total runtime is 0.7361087163289387 minutes
2024-07-18 11:32:28,162:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:28,162:INFO:Initializing create_model()
2024-07-18 11:32:28,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:28,162:INFO:Checking exceptions
2024-07-18 11:32:28,162:INFO:Importing libraries
2024-07-18 11:32:28,162:INFO:Copying training dataset
2024-07-18 11:32:28,164:INFO:Defining folds
2024-07-18 11:32:28,164:INFO:Declaring metric variables
2024-07-18 11:32:28,165:INFO:Importing untrained model
2024-07-18 11:32:28,167:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:32:28,170:INFO:Starting cross validation
2024-07-18 11:32:28,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:31,990:INFO:Calculating mean and std
2024-07-18 11:32:31,990:INFO:Creating metrics dataframe
2024-07-18 11:32:32,506:INFO:Uploading results into container
2024-07-18 11:32:32,506:INFO:Uploading model into container now
2024-07-18 11:32:32,507:INFO:_master_model_container: 11
2024-07-18 11:32:32,507:INFO:_display_container: 2
2024-07-18 11:32:32,507:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:32:32,507:INFO:create_model() successfully completed......................................
2024-07-18 11:32:32,561:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:32,561:INFO:Creating metrics dataframe
2024-07-18 11:32:32,575:INFO:Initializing Extra Trees Classifier
2024-07-18 11:32:32,575:INFO:Total runtime is 0.809690769513448 minutes
2024-07-18 11:32:32,576:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:32,576:INFO:Initializing create_model()
2024-07-18 11:32:32,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:32,576:INFO:Checking exceptions
2024-07-18 11:32:32,576:INFO:Importing libraries
2024-07-18 11:32:32,576:INFO:Copying training dataset
2024-07-18 11:32:32,576:INFO:Defining folds
2024-07-18 11:32:32,576:INFO:Declaring metric variables
2024-07-18 11:32:32,576:INFO:Importing untrained model
2024-07-18 11:32:32,576:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:32:32,576:INFO:Starting cross validation
2024-07-18 11:32:32,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:36,553:INFO:Calculating mean and std
2024-07-18 11:32:36,553:INFO:Creating metrics dataframe
2024-07-18 11:32:37,060:INFO:Uploading results into container
2024-07-18 11:32:37,060:INFO:Uploading model into container now
2024-07-18 11:32:37,060:INFO:_master_model_container: 12
2024-07-18 11:32:37,060:INFO:_display_container: 2
2024-07-18 11:32:37,061:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7665, verbose=0, warm_start=False)
2024-07-18 11:32:37,061:INFO:create_model() successfully completed......................................
2024-07-18 11:32:37,121:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:37,121:INFO:Creating metrics dataframe
2024-07-18 11:32:37,125:INFO:Initializing Extreme Gradient Boosting
2024-07-18 11:32:37,125:INFO:Total runtime is 0.8855247338612874 minutes
2024-07-18 11:32:37,125:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:37,125:INFO:Initializing create_model()
2024-07-18 11:32:37,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:37,125:INFO:Checking exceptions
2024-07-18 11:32:37,125:INFO:Importing libraries
2024-07-18 11:32:37,125:INFO:Copying training dataset
2024-07-18 11:32:37,125:INFO:Defining folds
2024-07-18 11:32:37,125:INFO:Declaring metric variables
2024-07-18 11:32:37,125:INFO:Importing untrained model
2024-07-18 11:32:37,125:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:32:37,125:INFO:Starting cross validation
2024-07-18 11:32:37,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:40,929:INFO:Calculating mean and std
2024-07-18 11:32:40,929:INFO:Creating metrics dataframe
2024-07-18 11:32:41,427:INFO:Uploading results into container
2024-07-18 11:32:41,427:INFO:Uploading model into container now
2024-07-18 11:32:41,427:INFO:_master_model_container: 13
2024-07-18 11:32:41,427:INFO:_display_container: 2
2024-07-18 11:32:41,427:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:32:41,427:INFO:create_model() successfully completed......................................
2024-07-18 11:32:41,491:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:41,491:INFO:Creating metrics dataframe
2024-07-18 11:32:41,491:INFO:Initializing Light Gradient Boosting Machine
2024-07-18 11:32:41,491:INFO:Total runtime is 0.9582988778750101 minutes
2024-07-18 11:32:41,507:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:41,507:INFO:Initializing create_model()
2024-07-18 11:32:41,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:41,508:INFO:Checking exceptions
2024-07-18 11:32:41,508:INFO:Importing libraries
2024-07-18 11:32:41,508:INFO:Copying training dataset
2024-07-18 11:32:41,508:INFO:Defining folds
2024-07-18 11:32:41,508:INFO:Declaring metric variables
2024-07-18 11:32:41,508:INFO:Importing untrained model
2024-07-18 11:32:41,508:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:32:41,508:INFO:Starting cross validation
2024-07-18 11:32:41,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:46,059:INFO:Calculating mean and std
2024-07-18 11:32:46,059:INFO:Creating metrics dataframe
2024-07-18 11:32:46,575:INFO:Uploading results into container
2024-07-18 11:32:46,575:INFO:Uploading model into container now
2024-07-18 11:32:46,575:INFO:_master_model_container: 14
2024-07-18 11:32:46,575:INFO:_display_container: 2
2024-07-18 11:32:46,575:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7665, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:32:46,575:INFO:create_model() successfully completed......................................
2024-07-18 11:32:46,638:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:46,638:INFO:Creating metrics dataframe
2024-07-18 11:32:46,643:INFO:Initializing CatBoost Classifier
2024-07-18 11:32:46,643:INFO:Total runtime is 1.0441612283388773 minutes
2024-07-18 11:32:46,645:INFO:SubProcess create_model() called ==================================
2024-07-18 11:32:46,646:INFO:Initializing create_model()
2024-07-18 11:32:46,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB2033150>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:46,646:INFO:Checking exceptions
2024-07-18 11:32:46,646:INFO:Importing libraries
2024-07-18 11:32:46,646:INFO:Copying training dataset
2024-07-18 11:32:46,648:INFO:Defining folds
2024-07-18 11:32:46,648:INFO:Declaring metric variables
2024-07-18 11:32:46,649:INFO:Importing untrained model
2024-07-18 11:32:46,651:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:32:46,655:INFO:Starting cross validation
2024-07-18 11:32:46,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:32:52,370:INFO:Calculating mean and std
2024-07-18 11:32:52,371:INFO:Creating metrics dataframe
2024-07-18 11:32:52,891:INFO:Uploading results into container
2024-07-18 11:32:52,891:INFO:Uploading model into container now
2024-07-18 11:32:52,891:INFO:_master_model_container: 15
2024-07-18 11:32:52,891:INFO:_display_container: 2
2024-07-18 11:32:52,891:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DAB804D90>
2024-07-18 11:32:52,891:INFO:create_model() successfully completed......................................
2024-07-18 11:32:52,960:INFO:SubProcess create_model() end ==================================
2024-07-18 11:32:52,960:INFO:Creating metrics dataframe
2024-07-18 11:32:52,960:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-18 11:32:52,960:INFO:Initializing create_model()
2024-07-18 11:32:52,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7665, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:52,960:INFO:Checking exceptions
2024-07-18 11:32:52,960:INFO:Importing libraries
2024-07-18 11:32:52,960:INFO:Copying training dataset
2024-07-18 11:32:52,960:INFO:Defining folds
2024-07-18 11:32:52,960:INFO:Declaring metric variables
2024-07-18 11:32:52,960:INFO:Importing untrained model
2024-07-18 11:32:52,960:INFO:Declaring custom model
2024-07-18 11:32:52,960:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:32:52,974:INFO:Cross validation set to False
2024-07-18 11:32:52,975:INFO:Fitting Model
2024-07-18 11:32:53,457:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7665, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:32:53,458:INFO:create_model() successfully completed......................................
2024-07-18 11:32:53,525:INFO:Initializing create_model()
2024-07-18 11:32:53,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7665, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:53,525:INFO:Checking exceptions
2024-07-18 11:32:53,526:INFO:Importing libraries
2024-07-18 11:32:53,526:INFO:Copying training dataset
2024-07-18 11:32:53,528:INFO:Defining folds
2024-07-18 11:32:53,528:INFO:Declaring metric variables
2024-07-18 11:32:53,528:INFO:Importing untrained model
2024-07-18 11:32:53,528:INFO:Declaring custom model
2024-07-18 11:32:53,529:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:32:53,529:INFO:Cross validation set to False
2024-07-18 11:32:53,529:INFO:Fitting Model
2024-07-18 11:32:53,540:INFO:[LightGBM] [Info] Number of positive: 1147, number of negative: 929
2024-07-18 11:32:53,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000019 seconds.
2024-07-18 11:32:53,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-18 11:32:53,540:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-18 11:32:53,540:INFO:[LightGBM] [Info] Total Bins 20
2024-07-18 11:32:53,540:INFO:[LightGBM] [Info] Number of data points in the train set: 2076, number of used features: 3
2024-07-18 11:32:53,540:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.552505 -> initscore=0.210796
2024-07-18 11:32:53,540:INFO:[LightGBM] [Info] Start training from score 0.210796
2024-07-18 11:32:53,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:53,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-18 11:32:54,028:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7665, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:32:54,028:INFO:create_model() successfully completed......................................
2024-07-18 11:32:54,095:INFO:Initializing create_model()
2024-07-18 11:32:54,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:54,095:INFO:Checking exceptions
2024-07-18 11:32:54,096:INFO:Importing libraries
2024-07-18 11:32:54,096:INFO:Copying training dataset
2024-07-18 11:32:54,098:INFO:Defining folds
2024-07-18 11:32:54,098:INFO:Declaring metric variables
2024-07-18 11:32:54,098:INFO:Importing untrained model
2024-07-18 11:32:54,098:INFO:Declaring custom model
2024-07-18 11:32:54,099:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:32:54,099:INFO:Cross validation set to False
2024-07-18 11:32:54,099:INFO:Fitting Model
2024-07-18 11:32:54,575:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:32:54,576:INFO:create_model() successfully completed......................................
2024-07-18 11:32:54,640:INFO:Initializing create_model()
2024-07-18 11:32:54,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7665, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:54,640:INFO:Checking exceptions
2024-07-18 11:32:54,641:INFO:Importing libraries
2024-07-18 11:32:54,641:INFO:Copying training dataset
2024-07-18 11:32:54,643:INFO:Defining folds
2024-07-18 11:32:54,643:INFO:Declaring metric variables
2024-07-18 11:32:54,643:INFO:Importing untrained model
2024-07-18 11:32:54,643:INFO:Declaring custom model
2024-07-18 11:32:54,644:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:32:54,644:INFO:Cross validation set to False
2024-07-18 11:32:54,644:INFO:Fitting Model
2024-07-18 11:32:55,204:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7665, verbose=0, warm_start=False)
2024-07-18 11:32:55,204:INFO:create_model() successfully completed......................................
2024-07-18 11:32:55,271:INFO:Initializing create_model()
2024-07-18 11:32:55,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=<catboost.core.CatBoostClassifier object at 0x0000021DAB804D90>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:55,271:INFO:Checking exceptions
2024-07-18 11:32:55,272:INFO:Importing libraries
2024-07-18 11:32:55,272:INFO:Copying training dataset
2024-07-18 11:32:55,274:INFO:Defining folds
2024-07-18 11:32:55,274:INFO:Declaring metric variables
2024-07-18 11:32:55,274:INFO:Importing untrained model
2024-07-18 11:32:55,274:INFO:Declaring custom model
2024-07-18 11:32:55,274:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:32:55,274:INFO:Cross validation set to False
2024-07-18 11:32:55,274:INFO:Fitting Model
2024-07-18 11:32:56,901:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DB1EB08D0>
2024-07-18 11:32:56,901:INFO:create_model() successfully completed......................................
2024-07-18 11:32:56,959:INFO:Initializing create_model()
2024-07-18 11:32:56,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7665, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:56,959:INFO:Checking exceptions
2024-07-18 11:32:56,959:INFO:Importing libraries
2024-07-18 11:32:56,959:INFO:Copying training dataset
2024-07-18 11:32:56,959:INFO:Defining folds
2024-07-18 11:32:56,959:INFO:Declaring metric variables
2024-07-18 11:32:56,959:INFO:Importing untrained model
2024-07-18 11:32:56,959:INFO:Declaring custom model
2024-07-18 11:32:56,959:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:32:56,959:INFO:Cross validation set to False
2024-07-18 11:32:56,959:INFO:Fitting Model
2024-07-18 11:32:57,459:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7665, verbose=0, warm_start=False)
2024-07-18 11:32:57,459:INFO:create_model() successfully completed......................................
2024-07-18 11:32:57,531:INFO:Initializing create_model()
2024-07-18 11:32:57,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7665, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:57,531:INFO:Checking exceptions
2024-07-18 11:32:57,532:INFO:Importing libraries
2024-07-18 11:32:57,532:INFO:Copying training dataset
2024-07-18 11:32:57,534:INFO:Defining folds
2024-07-18 11:32:57,534:INFO:Declaring metric variables
2024-07-18 11:32:57,534:INFO:Importing untrained model
2024-07-18 11:32:57,534:INFO:Declaring custom model
2024-07-18 11:32:57,534:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:32:57,535:INFO:Cross validation set to False
2024-07-18 11:32:57,535:INFO:Fitting Model
2024-07-18 11:32:57,957:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7665, splitter='best')
2024-07-18 11:32:57,957:INFO:create_model() successfully completed......................................
2024-07-18 11:32:58,023:INFO:Initializing create_model()
2024-07-18 11:32:58,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7665), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:58,024:INFO:Checking exceptions
2024-07-18 11:32:58,025:INFO:Importing libraries
2024-07-18 11:32:58,025:INFO:Copying training dataset
2024-07-18 11:32:58,026:INFO:Defining folds
2024-07-18 11:32:58,026:INFO:Declaring metric variables
2024-07-18 11:32:58,027:INFO:Importing untrained model
2024-07-18 11:32:58,027:INFO:Declaring custom model
2024-07-18 11:32:58,027:INFO:str Imported successfully
2024-07-18 11:32:58,027:INFO:Cross validation set to False
2024-07-18 11:32:58,027:INFO:Fitting Model
2024-07-18 11:32:58,499:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7665)
2024-07-18 11:32:58,499:INFO:create_model() successfully completed......................................
2024-07-18 11:32:58,561:INFO:Initializing create_model()
2024-07-18 11:32:58,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:58,561:INFO:Checking exceptions
2024-07-18 11:32:58,561:INFO:Importing libraries
2024-07-18 11:32:58,561:INFO:Copying training dataset
2024-07-18 11:32:58,561:INFO:Defining folds
2024-07-18 11:32:58,561:INFO:Declaring metric variables
2024-07-18 11:32:58,561:INFO:Importing untrained model
2024-07-18 11:32:58,561:INFO:Declaring custom model
2024-07-18 11:32:58,561:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:32:58,561:INFO:Cross validation set to False
2024-07-18 11:32:58,561:INFO:Fitting Model
2024-07-18 11:32:58,975:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:32:58,975:INFO:create_model() successfully completed......................................
2024-07-18 11:32:59,062:INFO:Initializing create_model()
2024-07-18 11:32:59,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:59,062:INFO:Checking exceptions
2024-07-18 11:32:59,063:INFO:Importing libraries
2024-07-18 11:32:59,063:INFO:Copying training dataset
2024-07-18 11:32:59,065:INFO:Defining folds
2024-07-18 11:32:59,065:INFO:Declaring metric variables
2024-07-18 11:32:59,065:INFO:Importing untrained model
2024-07-18 11:32:59,065:INFO:Declaring custom model
2024-07-18 11:32:59,066:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:32:59,066:INFO:Cross validation set to False
2024-07-18 11:32:59,066:INFO:Fitting Model
2024-07-18 11:32:59,476:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:32:59,476:INFO:create_model() successfully completed......................................
2024-07-18 11:32:59,543:INFO:Initializing create_model()
2024-07-18 11:32:59,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:32:59,544:INFO:Checking exceptions
2024-07-18 11:32:59,544:INFO:Importing libraries
2024-07-18 11:32:59,544:INFO:Copying training dataset
2024-07-18 11:32:59,546:INFO:Defining folds
2024-07-18 11:32:59,546:INFO:Declaring metric variables
2024-07-18 11:32:59,546:INFO:Importing untrained model
2024-07-18 11:32:59,546:INFO:Declaring custom model
2024-07-18 11:32:59,547:INFO:Naive Bayes Imported successfully
2024-07-18 11:32:59,547:INFO:Cross validation set to False
2024-07-18 11:32:59,547:INFO:Fitting Model
2024-07-18 11:32:59,963:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:32:59,963:INFO:create_model() successfully completed......................................
2024-07-18 11:33:00,033:INFO:Initializing create_model()
2024-07-18 11:33:00,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7665, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:00,033:INFO:Checking exceptions
2024-07-18 11:33:00,034:INFO:Importing libraries
2024-07-18 11:33:00,034:INFO:Copying training dataset
2024-07-18 11:33:00,036:INFO:Defining folds
2024-07-18 11:33:00,036:INFO:Declaring metric variables
2024-07-18 11:33:00,036:INFO:Importing untrained model
2024-07-18 11:33:00,036:INFO:Declaring custom model
2024-07-18 11:33:00,036:INFO:Ridge Classifier Imported successfully
2024-07-18 11:33:00,037:INFO:Cross validation set to False
2024-07-18 11:33:00,037:INFO:Fitting Model
2024-07-18 11:33:00,441:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7665, solver='auto',
                tol=0.0001)
2024-07-18 11:33:00,441:INFO:create_model() successfully completed......................................
2024-07-18 11:33:00,508:INFO:Initializing create_model()
2024-07-18 11:33:00,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:00,508:INFO:Checking exceptions
2024-07-18 11:33:00,508:INFO:Importing libraries
2024-07-18 11:33:00,508:INFO:Copying training dataset
2024-07-18 11:33:00,508:INFO:Defining folds
2024-07-18 11:33:00,508:INFO:Declaring metric variables
2024-07-18 11:33:00,508:INFO:Importing untrained model
2024-07-18 11:33:00,508:INFO:Declaring custom model
2024-07-18 11:33:00,508:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:33:00,508:INFO:Cross validation set to False
2024-07-18 11:33:00,508:INFO:Fitting Model
2024-07-18 11:33:00,908:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:33:00,908:INFO:create_model() successfully completed......................................
2024-07-18 11:33:00,974:INFO:Initializing create_model()
2024-07-18 11:33:00,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7665, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:00,974:INFO:Checking exceptions
2024-07-18 11:33:00,974:INFO:Importing libraries
2024-07-18 11:33:00,974:INFO:Copying training dataset
2024-07-18 11:33:00,974:INFO:Defining folds
2024-07-18 11:33:00,974:INFO:Declaring metric variables
2024-07-18 11:33:00,974:INFO:Importing untrained model
2024-07-18 11:33:00,974:INFO:Declaring custom model
2024-07-18 11:33:00,974:INFO:Logistic Regression Imported successfully
2024-07-18 11:33:00,974:INFO:Cross validation set to False
2024-07-18 11:33:00,974:INFO:Fitting Model
2024-07-18 11:33:01,404:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7665, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:33:01,404:INFO:create_model() successfully completed......................................
2024-07-18 11:33:01,458:INFO:Initializing create_model()
2024-07-18 11:33:01,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7665, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:01,458:INFO:Checking exceptions
2024-07-18 11:33:01,458:INFO:Importing libraries
2024-07-18 11:33:01,458:INFO:Copying training dataset
2024-07-18 11:33:01,474:INFO:Defining folds
2024-07-18 11:33:01,474:INFO:Declaring metric variables
2024-07-18 11:33:01,474:INFO:Importing untrained model
2024-07-18 11:33:01,474:INFO:Declaring custom model
2024-07-18 11:33:01,474:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:33:01,474:INFO:Cross validation set to False
2024-07-18 11:33:01,474:INFO:Fitting Model
2024-07-18 11:33:01,891:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7665, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:33:01,891:INFO:create_model() successfully completed......................................
2024-07-18 11:33:01,958:INFO:_master_model_container: 15
2024-07-18 11:33:01,958:INFO:_display_container: 2
2024-07-18 11:33:01,958:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7665, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7665, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7665, verbose=0, warm_start=False), <catboost.core.CatBoostClassifier object at 0x0000021DB1EB08D0>, ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7665, verbose=0, warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7665, splitter='best'), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7665), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7665, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7665, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7665, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-07-18 11:33:01,958:INFO:compare_models() successfully completed......................................
2024-07-18 11:33:01,986:INFO:Initializing compare_models()
2024-07-18 11:33:01,986:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, include=None, exclude=['dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, 'include': None, 'exclude': ['dummy'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-18 11:33:01,986:INFO:Checking exceptions
2024-07-18 11:33:01,987:INFO:Preparing display monitor
2024-07-18 11:33:01,999:INFO:Initializing Logistic Regression
2024-07-18 11:33:01,999:INFO:Total runtime is 0.0 minutes
2024-07-18 11:33:02,001:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:02,001:INFO:Initializing create_model()
2024-07-18 11:33:02,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:02,001:INFO:Checking exceptions
2024-07-18 11:33:02,001:INFO:Importing libraries
2024-07-18 11:33:02,001:INFO:Copying training dataset
2024-07-18 11:33:02,003:INFO:Defining folds
2024-07-18 11:33:02,003:INFO:Declaring metric variables
2024-07-18 11:33:02,005:INFO:Importing untrained model
2024-07-18 11:33:02,007:INFO:Logistic Regression Imported successfully
2024-07-18 11:33:02,010:INFO:Starting cross validation
2024-07-18 11:33:02,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:05,850:INFO:Calculating mean and std
2024-07-18 11:33:05,850:INFO:Creating metrics dataframe
2024-07-18 11:33:06,374:INFO:Uploading results into container
2024-07-18 11:33:06,374:INFO:Uploading model into container now
2024-07-18 11:33:06,374:INFO:_master_model_container: 16
2024-07-18 11:33:06,374:INFO:_display_container: 3
2024-07-18 11:33:06,374:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7665, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-18 11:33:06,374:INFO:create_model() successfully completed......................................
2024-07-18 11:33:06,436:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:06,436:INFO:Creating metrics dataframe
2024-07-18 11:33:06,440:INFO:Initializing K Neighbors Classifier
2024-07-18 11:33:06,441:INFO:Total runtime is 0.07403396368026734 minutes
2024-07-18 11:33:06,442:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:06,442:INFO:Initializing create_model()
2024-07-18 11:33:06,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:06,443:INFO:Checking exceptions
2024-07-18 11:33:06,443:INFO:Importing libraries
2024-07-18 11:33:06,443:INFO:Copying training dataset
2024-07-18 11:33:06,445:INFO:Defining folds
2024-07-18 11:33:06,445:INFO:Declaring metric variables
2024-07-18 11:33:06,446:INFO:Importing untrained model
2024-07-18 11:33:06,448:INFO:K Neighbors Classifier Imported successfully
2024-07-18 11:33:06,452:INFO:Starting cross validation
2024-07-18 11:33:06,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:10,350:INFO:Calculating mean and std
2024-07-18 11:33:10,350:INFO:Creating metrics dataframe
2024-07-18 11:33:10,913:INFO:Uploading results into container
2024-07-18 11:33:10,914:INFO:Uploading model into container now
2024-07-18 11:33:10,914:INFO:_master_model_container: 17
2024-07-18 11:33:10,914:INFO:_display_container: 3
2024-07-18 11:33:10,914:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-18 11:33:10,914:INFO:create_model() successfully completed......................................
2024-07-18 11:33:10,991:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:10,991:INFO:Creating metrics dataframe
2024-07-18 11:33:10,996:INFO:Initializing Naive Bayes
2024-07-18 11:33:10,996:INFO:Total runtime is 0.1499490261077881 minutes
2024-07-18 11:33:10,997:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:10,998:INFO:Initializing create_model()
2024-07-18 11:33:10,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:10,998:INFO:Checking exceptions
2024-07-18 11:33:10,998:INFO:Importing libraries
2024-07-18 11:33:10,998:INFO:Copying training dataset
2024-07-18 11:33:11,000:INFO:Defining folds
2024-07-18 11:33:11,000:INFO:Declaring metric variables
2024-07-18 11:33:11,002:INFO:Importing untrained model
2024-07-18 11:33:11,004:INFO:Naive Bayes Imported successfully
2024-07-18 11:33:11,007:INFO:Starting cross validation
2024-07-18 11:33:11,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:14,887:INFO:Calculating mean and std
2024-07-18 11:33:14,887:INFO:Creating metrics dataframe
2024-07-18 11:33:15,409:INFO:Uploading results into container
2024-07-18 11:33:15,410:INFO:Uploading model into container now
2024-07-18 11:33:15,410:INFO:_master_model_container: 18
2024-07-18 11:33:15,410:INFO:_display_container: 3
2024-07-18 11:33:15,410:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-18 11:33:15,410:INFO:create_model() successfully completed......................................
2024-07-18 11:33:15,475:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:15,475:INFO:Creating metrics dataframe
2024-07-18 11:33:15,479:INFO:Initializing Decision Tree Classifier
2024-07-18 11:33:15,479:INFO:Total runtime is 0.2246654192606608 minutes
2024-07-18 11:33:15,481:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:15,482:INFO:Initializing create_model()
2024-07-18 11:33:15,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:15,482:INFO:Checking exceptions
2024-07-18 11:33:15,482:INFO:Importing libraries
2024-07-18 11:33:15,482:INFO:Copying training dataset
2024-07-18 11:33:15,484:INFO:Defining folds
2024-07-18 11:33:15,484:INFO:Declaring metric variables
2024-07-18 11:33:15,486:INFO:Importing untrained model
2024-07-18 11:33:15,488:INFO:Decision Tree Classifier Imported successfully
2024-07-18 11:33:15,491:INFO:Starting cross validation
2024-07-18 11:33:15,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:19,338:INFO:Calculating mean and std
2024-07-18 11:33:19,338:INFO:Creating metrics dataframe
2024-07-18 11:33:19,841:INFO:Uploading results into container
2024-07-18 11:33:19,841:INFO:Uploading model into container now
2024-07-18 11:33:19,841:INFO:_master_model_container: 19
2024-07-18 11:33:19,841:INFO:_display_container: 3
2024-07-18 11:33:19,841:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7665, splitter='best')
2024-07-18 11:33:19,841:INFO:create_model() successfully completed......................................
2024-07-18 11:33:19,909:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:19,909:INFO:Creating metrics dataframe
2024-07-18 11:33:19,924:INFO:Initializing SVM - Linear Kernel
2024-07-18 11:33:19,924:INFO:Total runtime is 0.29875856240590415 minutes
2024-07-18 11:33:19,924:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:19,924:INFO:Initializing create_model()
2024-07-18 11:33:19,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:19,924:INFO:Checking exceptions
2024-07-18 11:33:19,924:INFO:Importing libraries
2024-07-18 11:33:19,924:INFO:Copying training dataset
2024-07-18 11:33:19,924:INFO:Defining folds
2024-07-18 11:33:19,924:INFO:Declaring metric variables
2024-07-18 11:33:19,924:INFO:Importing untrained model
2024-07-18 11:33:19,924:INFO:SVM - Linear Kernel Imported successfully
2024-07-18 11:33:19,940:INFO:Starting cross validation
2024-07-18 11:33:19,940:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:19,975:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:19,976:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:19,977:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:19,977:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:19,977:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:19,977:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:19,981:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:19,981:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:19,981:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:19,981:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:23,743:INFO:Calculating mean and std
2024-07-18 11:33:23,743:INFO:Creating metrics dataframe
2024-07-18 11:33:24,256:INFO:Uploading results into container
2024-07-18 11:33:24,256:INFO:Uploading model into container now
2024-07-18 11:33:24,256:INFO:_master_model_container: 20
2024-07-18 11:33:24,256:INFO:_display_container: 3
2024-07-18 11:33:24,256:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7665, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-18 11:33:24,256:INFO:create_model() successfully completed......................................
2024-07-18 11:33:24,310:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:24,310:INFO:Creating metrics dataframe
2024-07-18 11:33:24,310:INFO:Initializing Ridge Classifier
2024-07-18 11:33:24,310:INFO:Total runtime is 0.37185901403427124 minutes
2024-07-18 11:33:24,326:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:24,326:INFO:Initializing create_model()
2024-07-18 11:33:24,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:24,326:INFO:Checking exceptions
2024-07-18 11:33:24,326:INFO:Importing libraries
2024-07-18 11:33:24,326:INFO:Copying training dataset
2024-07-18 11:33:24,326:INFO:Defining folds
2024-07-18 11:33:24,326:INFO:Declaring metric variables
2024-07-18 11:33:24,326:INFO:Importing untrained model
2024-07-18 11:33:24,326:INFO:Ridge Classifier Imported successfully
2024-07-18 11:33:24,326:INFO:Starting cross validation
2024-07-18 11:33:24,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:24,362:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:24,364:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:24,364:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:24,364:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:24,364:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:24,364:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:24,364:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:24,364:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:24,374:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:24,376:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\JAL\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-07-18 11:33:28,305:INFO:Calculating mean and std
2024-07-18 11:33:28,305:INFO:Creating metrics dataframe
2024-07-18 11:33:28,832:INFO:Uploading results into container
2024-07-18 11:33:28,833:INFO:Uploading model into container now
2024-07-18 11:33:28,833:INFO:_master_model_container: 21
2024-07-18 11:33:28,833:INFO:_display_container: 3
2024-07-18 11:33:28,833:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7665, solver='auto',
                tol=0.0001)
2024-07-18 11:33:28,834:INFO:create_model() successfully completed......................................
2024-07-18 11:33:28,901:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:28,901:INFO:Creating metrics dataframe
2024-07-18 11:33:28,905:INFO:Initializing Random Forest Classifier
2024-07-18 11:33:28,905:INFO:Total runtime is 0.4484362800916036 minutes
2024-07-18 11:33:28,907:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:28,908:INFO:Initializing create_model()
2024-07-18 11:33:28,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:28,908:INFO:Checking exceptions
2024-07-18 11:33:28,908:INFO:Importing libraries
2024-07-18 11:33:28,908:INFO:Copying training dataset
2024-07-18 11:33:28,910:INFO:Defining folds
2024-07-18 11:33:28,910:INFO:Declaring metric variables
2024-07-18 11:33:28,911:INFO:Importing untrained model
2024-07-18 11:33:28,913:INFO:Random Forest Classifier Imported successfully
2024-07-18 11:33:28,917:INFO:Starting cross validation
2024-07-18 11:33:28,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:32,854:INFO:Calculating mean and std
2024-07-18 11:33:32,854:INFO:Creating metrics dataframe
2024-07-18 11:33:33,356:INFO:Uploading results into container
2024-07-18 11:33:33,356:INFO:Uploading model into container now
2024-07-18 11:33:33,356:INFO:_master_model_container: 22
2024-07-18 11:33:33,356:INFO:_display_container: 3
2024-07-18 11:33:33,356:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7665, verbose=0, warm_start=False)
2024-07-18 11:33:33,356:INFO:create_model() successfully completed......................................
2024-07-18 11:33:33,437:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:33,437:INFO:Creating metrics dataframe
2024-07-18 11:33:33,438:INFO:Initializing Quadratic Discriminant Analysis
2024-07-18 11:33:33,438:INFO:Total runtime is 0.5239902774492899 minutes
2024-07-18 11:33:33,438:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:33,438:INFO:Initializing create_model()
2024-07-18 11:33:33,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:33,438:INFO:Checking exceptions
2024-07-18 11:33:33,438:INFO:Importing libraries
2024-07-18 11:33:33,438:INFO:Copying training dataset
2024-07-18 11:33:33,438:INFO:Defining folds
2024-07-18 11:33:33,438:INFO:Declaring metric variables
2024-07-18 11:33:33,438:INFO:Importing untrained model
2024-07-18 11:33:33,438:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-18 11:33:33,438:INFO:Starting cross validation
2024-07-18 11:33:33,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:37,254:INFO:Calculating mean and std
2024-07-18 11:33:37,255:INFO:Creating metrics dataframe
2024-07-18 11:33:37,770:INFO:Uploading results into container
2024-07-18 11:33:37,770:INFO:Uploading model into container now
2024-07-18 11:33:37,771:INFO:_master_model_container: 23
2024-07-18 11:33:37,771:INFO:_display_container: 3
2024-07-18 11:33:37,771:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-18 11:33:37,771:INFO:create_model() successfully completed......................................
2024-07-18 11:33:37,833:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:37,833:INFO:Creating metrics dataframe
2024-07-18 11:33:37,838:INFO:Initializing Ada Boost Classifier
2024-07-18 11:33:37,838:INFO:Total runtime is 0.5973273714383442 minutes
2024-07-18 11:33:37,840:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:37,840:INFO:Initializing create_model()
2024-07-18 11:33:37,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:37,840:INFO:Checking exceptions
2024-07-18 11:33:37,840:INFO:Importing libraries
2024-07-18 11:33:37,840:INFO:Copying training dataset
2024-07-18 11:33:37,842:INFO:Defining folds
2024-07-18 11:33:37,842:INFO:Declaring metric variables
2024-07-18 11:33:37,844:INFO:Importing untrained model
2024-07-18 11:33:37,845:INFO:Ada Boost Classifier Imported successfully
2024-07-18 11:33:37,849:INFO:Starting cross validation
2024-07-18 11:33:37,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:41,815:INFO:Calculating mean and std
2024-07-18 11:33:41,815:INFO:Creating metrics dataframe
2024-07-18 11:33:42,334:INFO:Uploading results into container
2024-07-18 11:33:42,335:INFO:Uploading model into container now
2024-07-18 11:33:42,335:INFO:_master_model_container: 24
2024-07-18 11:33:42,335:INFO:_display_container: 3
2024-07-18 11:33:42,335:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7665)
2024-07-18 11:33:42,335:INFO:create_model() successfully completed......................................
2024-07-18 11:33:42,393:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:42,393:INFO:Creating metrics dataframe
2024-07-18 11:33:42,393:INFO:Initializing Gradient Boosting Classifier
2024-07-18 11:33:42,393:INFO:Total runtime is 0.6732322851816812 minutes
2024-07-18 11:33:42,408:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:42,408:INFO:Initializing create_model()
2024-07-18 11:33:42,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:42,408:INFO:Checking exceptions
2024-07-18 11:33:42,408:INFO:Importing libraries
2024-07-18 11:33:42,408:INFO:Copying training dataset
2024-07-18 11:33:42,410:INFO:Defining folds
2024-07-18 11:33:42,410:INFO:Declaring metric variables
2024-07-18 11:33:42,412:INFO:Importing untrained model
2024-07-18 11:33:42,414:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:33:42,417:INFO:Starting cross validation
2024-07-18 11:33:42,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:46,348:INFO:Calculating mean and std
2024-07-18 11:33:46,349:INFO:Creating metrics dataframe
2024-07-18 11:33:46,856:INFO:Uploading results into container
2024-07-18 11:33:46,856:INFO:Uploading model into container now
2024-07-18 11:33:46,856:INFO:_master_model_container: 25
2024-07-18 11:33:46,856:INFO:_display_container: 3
2024-07-18 11:33:46,856:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7665, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:33:46,856:INFO:create_model() successfully completed......................................
2024-07-18 11:33:46,924:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:46,924:INFO:Creating metrics dataframe
2024-07-18 11:33:46,924:INFO:Initializing Linear Discriminant Analysis
2024-07-18 11:33:46,924:INFO:Total runtime is 0.7487542748451232 minutes
2024-07-18 11:33:46,924:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:46,924:INFO:Initializing create_model()
2024-07-18 11:33:46,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:46,924:INFO:Checking exceptions
2024-07-18 11:33:46,924:INFO:Importing libraries
2024-07-18 11:33:46,924:INFO:Copying training dataset
2024-07-18 11:33:46,924:INFO:Defining folds
2024-07-18 11:33:46,924:INFO:Declaring metric variables
2024-07-18 11:33:46,940:INFO:Importing untrained model
2024-07-18 11:33:46,940:INFO:Linear Discriminant Analysis Imported successfully
2024-07-18 11:33:46,940:INFO:Starting cross validation
2024-07-18 11:33:46,940:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:50,716:INFO:Calculating mean and std
2024-07-18 11:33:50,716:INFO:Creating metrics dataframe
2024-07-18 11:33:51,227:INFO:Uploading results into container
2024-07-18 11:33:51,227:INFO:Uploading model into container now
2024-07-18 11:33:51,227:INFO:_master_model_container: 26
2024-07-18 11:33:51,227:INFO:_display_container: 3
2024-07-18 11:33:51,227:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-18 11:33:51,227:INFO:create_model() successfully completed......................................
2024-07-18 11:33:51,290:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:51,290:INFO:Creating metrics dataframe
2024-07-18 11:33:51,290:INFO:Initializing Extra Trees Classifier
2024-07-18 11:33:51,290:INFO:Total runtime is 0.8215216358502706 minutes
2024-07-18 11:33:51,290:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:51,290:INFO:Initializing create_model()
2024-07-18 11:33:51,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:51,290:INFO:Checking exceptions
2024-07-18 11:33:51,290:INFO:Importing libraries
2024-07-18 11:33:51,290:INFO:Copying training dataset
2024-07-18 11:33:51,290:INFO:Defining folds
2024-07-18 11:33:51,290:INFO:Declaring metric variables
2024-07-18 11:33:51,290:INFO:Importing untrained model
2024-07-18 11:33:51,306:INFO:Extra Trees Classifier Imported successfully
2024-07-18 11:33:51,306:INFO:Starting cross validation
2024-07-18 11:33:51,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:55,263:INFO:Calculating mean and std
2024-07-18 11:33:55,263:INFO:Creating metrics dataframe
2024-07-18 11:33:55,780:INFO:Uploading results into container
2024-07-18 11:33:55,782:INFO:Uploading model into container now
2024-07-18 11:33:55,782:INFO:_master_model_container: 27
2024-07-18 11:33:55,782:INFO:_display_container: 3
2024-07-18 11:33:55,783:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7665, verbose=0, warm_start=False)
2024-07-18 11:33:55,783:INFO:create_model() successfully completed......................................
2024-07-18 11:33:55,845:INFO:SubProcess create_model() end ==================================
2024-07-18 11:33:55,845:INFO:Creating metrics dataframe
2024-07-18 11:33:55,851:INFO:Initializing Extreme Gradient Boosting
2024-07-18 11:33:55,851:INFO:Total runtime is 0.8975367267926534 minutes
2024-07-18 11:33:55,853:INFO:SubProcess create_model() called ==================================
2024-07-18 11:33:55,853:INFO:Initializing create_model()
2024-07-18 11:33:55,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:33:55,853:INFO:Checking exceptions
2024-07-18 11:33:55,853:INFO:Importing libraries
2024-07-18 11:33:55,853:INFO:Copying training dataset
2024-07-18 11:33:55,855:INFO:Defining folds
2024-07-18 11:33:55,855:INFO:Declaring metric variables
2024-07-18 11:33:55,857:INFO:Importing untrained model
2024-07-18 11:33:55,857:INFO:Extreme Gradient Boosting Imported successfully
2024-07-18 11:33:55,857:INFO:Starting cross validation
2024-07-18 11:33:55,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:33:59,694:INFO:Calculating mean and std
2024-07-18 11:33:59,694:INFO:Creating metrics dataframe
2024-07-18 11:34:00,226:INFO:Uploading results into container
2024-07-18 11:34:00,226:INFO:Uploading model into container now
2024-07-18 11:34:00,226:INFO:_master_model_container: 28
2024-07-18 11:34:00,227:INFO:_display_container: 3
2024-07-18 11:34:00,227:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-07-18 11:34:00,227:INFO:create_model() successfully completed......................................
2024-07-18 11:34:00,289:INFO:SubProcess create_model() end ==================================
2024-07-18 11:34:00,289:INFO:Creating metrics dataframe
2024-07-18 11:34:00,297:INFO:Initializing Light Gradient Boosting Machine
2024-07-18 11:34:00,297:INFO:Total runtime is 0.9716438174247741 minutes
2024-07-18 11:34:00,299:INFO:SubProcess create_model() called ==================================
2024-07-18 11:34:00,299:INFO:Initializing create_model()
2024-07-18 11:34:00,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:34:00,299:INFO:Checking exceptions
2024-07-18 11:34:00,299:INFO:Importing libraries
2024-07-18 11:34:00,299:INFO:Copying training dataset
2024-07-18 11:34:00,302:INFO:Defining folds
2024-07-18 11:34:00,302:INFO:Declaring metric variables
2024-07-18 11:34:00,303:INFO:Importing untrained model
2024-07-18 11:34:00,305:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-18 11:34:00,308:INFO:Starting cross validation
2024-07-18 11:34:00,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:34:04,262:INFO:Calculating mean and std
2024-07-18 11:34:04,263:INFO:Creating metrics dataframe
2024-07-18 11:34:04,785:INFO:Uploading results into container
2024-07-18 11:34:04,785:INFO:Uploading model into container now
2024-07-18 11:34:04,786:INFO:_master_model_container: 29
2024-07-18 11:34:04,786:INFO:_display_container: 3
2024-07-18 11:34:04,786:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7665, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-18 11:34:04,786:INFO:create_model() successfully completed......................................
2024-07-18 11:34:04,860:INFO:SubProcess create_model() end ==================================
2024-07-18 11:34:04,860:INFO:Creating metrics dataframe
2024-07-18 11:34:04,866:INFO:Initializing CatBoost Classifier
2024-07-18 11:34:04,867:INFO:Total runtime is 1.0477836887041727 minutes
2024-07-18 11:34:04,868:INFO:SubProcess create_model() called ==================================
2024-07-18 11:34:04,869:INFO:Initializing create_model()
2024-07-18 11:34:04,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021DB1E25CD0>, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:34:04,869:INFO:Checking exceptions
2024-07-18 11:34:04,869:INFO:Importing libraries
2024-07-18 11:34:04,869:INFO:Copying training dataset
2024-07-18 11:34:04,871:INFO:Defining folds
2024-07-18 11:34:04,871:INFO:Declaring metric variables
2024-07-18 11:34:04,872:INFO:Importing untrained model
2024-07-18 11:34:04,874:INFO:CatBoost Classifier Imported successfully
2024-07-18 11:34:04,877:INFO:Starting cross validation
2024-07-18 11:34:04,878:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-18 11:34:08,780:INFO:Calculating mean and std
2024-07-18 11:34:08,780:INFO:Creating metrics dataframe
2024-07-18 11:34:09,306:INFO:Uploading results into container
2024-07-18 11:34:09,306:INFO:Uploading model into container now
2024-07-18 11:34:09,306:INFO:_master_model_container: 30
2024-07-18 11:34:09,306:INFO:_display_container: 3
2024-07-18 11:34:09,306:INFO:<catboost.core.CatBoostClassifier object at 0x0000021DAB945ED0>
2024-07-18 11:34:09,306:INFO:create_model() successfully completed......................................
2024-07-18 11:34:09,373:INFO:SubProcess create_model() end ==================================
2024-07-18 11:34:09,374:INFO:Creating metrics dataframe
2024-07-18 11:34:09,380:WARNING:C:\Users\JAL\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:335: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-18 11:34:09,384:INFO:Initializing create_model()
2024-07-18 11:34:09,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021DAB957190>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7665, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-07-18 11:34:09,384:INFO:Checking exceptions
2024-07-18 11:34:09,385:INFO:Importing libraries
2024-07-18 11:34:09,385:INFO:Copying training dataset
2024-07-18 11:34:09,387:INFO:Defining folds
2024-07-18 11:34:09,387:INFO:Declaring metric variables
2024-07-18 11:34:09,387:INFO:Importing untrained model
2024-07-18 11:34:09,387:INFO:Declaring custom model
2024-07-18 11:34:09,387:INFO:Gradient Boosting Classifier Imported successfully
2024-07-18 11:34:09,388:INFO:Cross validation set to False
2024-07-18 11:34:09,388:INFO:Fitting Model
2024-07-18 11:34:09,856:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7665, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:34:09,856:INFO:create_model() successfully completed......................................
2024-07-18 11:34:09,924:INFO:_master_model_container: 30
2024-07-18 11:34:09,924:INFO:_display_container: 3
2024-07-18 11:34:09,924:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7665, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-18 11:34:09,924:INFO:compare_models() successfully completed......................................
2024-07-18 11:34:09,941:INFO:Initializing save_model()
2024-07-18 11:34:09,941:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7665, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/GradientBoostingClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:09,941:INFO:Adding model into prep_pipe
2024-07-18 11:34:09,945:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/GradientBoostingClassifier.pkl saved in current working directory
2024-07-18 11:34:09,947:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=7665, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:34:09,947:INFO:save_model() successfully completed......................................
2024-07-18 11:34:10,408:INFO:Initializing save_model()
2024-07-18 11:34:10,408:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7665, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/LGBMClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:10,408:INFO:Adding model into prep_pipe
2024-07-18 11:34:10,408:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/LGBMClassifier.pkl saved in current working directory
2024-07-18 11:34:10,408:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=7665, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-07-18 11:34:10,408:INFO:save_model() successfully completed......................................
2024-07-18 11:34:10,903:INFO:Initializing save_model()
2024-07-18 11:34:10,903:INFO:save_model(model=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/XGBClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:10,903:INFO:Adding model into prep_pipe
2024-07-18 11:34:10,903:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/XGBClassifier.pkl saved in current working directory
2024-07-18 11:34:10,903:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-07-18 11:34:10,903:INFO:save_model() successfully completed......................................
2024-07-18 11:34:11,390:INFO:Initializing save_model()
2024-07-18 11:34:11,390:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=7665, verbose=0, warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/RandomForestClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:11,390:INFO:Adding model into prep_pipe
2024-07-18 11:34:11,421:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/RandomForestClassifier.pkl saved in current working directory
2024-07-18 11:34:11,421:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=7665,
                                        verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:34:11,421:INFO:save_model() successfully completed......................................
2024-07-18 11:34:11,890:INFO:Initializing save_model()
2024-07-18 11:34:11,890:INFO:save_model(model=<catboost.core.CatBoostClassifier object at 0x0000021DB1EB08D0>, model_name=GPU_0_EPPD_ML_VALIDATION_kfold/CatBoostClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:11,890:INFO:Adding model into prep_pipe
2024-07-18 11:34:11,892:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/CatBoostClassifier.pkl saved in current working directory
2024-07-18 11:34:11,893:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x0000021DB1EB08D0>)],
         verbose=False)
2024-07-18 11:34:11,893:INFO:save_model() successfully completed......................................
2024-07-18 11:34:12,361:INFO:Initializing save_model()
2024-07-18 11:34:12,361:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=7665, verbose=0, warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/ExtraTreesClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:12,361:INFO:Adding model into prep_pipe
2024-07-18 11:34:12,381:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/ExtraTreesClassifier.pkl saved in current working directory
2024-07-18 11:34:12,383:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=7665,
                                      verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:34:12,383:INFO:save_model() successfully completed......................................
2024-07-18 11:34:12,841:INFO:Initializing save_model()
2024-07-18 11:34:12,841:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=7665, splitter='best'), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/DecisionTreeClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:12,841:INFO:Adding model into prep_pipe
2024-07-18 11:34:12,841:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/DecisionTreeClassifier.pkl saved in current working directory
2024-07-18 11:34:12,841:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=7665, splitter='best'))],
         verbose=False)
2024-07-18 11:34:12,841:INFO:save_model() successfully completed......................................
2024-07-18 11:34:13,305:INFO:Initializing save_model()
2024-07-18 11:34:13,305:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=7665), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/AdaBoostClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:13,305:INFO:Adding model into prep_pipe
2024-07-18 11:34:13,320:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/AdaBoostClassifier.pkl saved in current working directory
2024-07-18 11:34:13,320:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=7665))],
         verbose=False)
2024-07-18 11:34:13,320:INFO:save_model() successfully completed......................................
2024-07-18 11:34:13,800:INFO:Initializing save_model()
2024-07-18 11:34:13,800:INFO:save_model(model=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/QuadraticDiscriminantAnalysis, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:13,800:INFO:Adding model into prep_pipe
2024-07-18 11:34:13,803:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/QuadraticDiscriminantAnalysis.pkl saved in current working directory
2024-07-18 11:34:13,805:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False)
2024-07-18 11:34:13,805:INFO:save_model() successfully completed......................................
2024-07-18 11:34:14,275:INFO:Initializing save_model()
2024-07-18 11:34:14,275:INFO:save_model(model=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/KNeighborsClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:14,276:INFO:Adding model into prep_pipe
2024-07-18 11:34:14,276:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/KNeighborsClassifier.pkl saved in current working directory
2024-07-18 11:34:14,276:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False)
2024-07-18 11:34:14,276:INFO:save_model() successfully completed......................................
2024-07-18 11:34:14,740:INFO:Initializing save_model()
2024-07-18 11:34:14,740:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/GaussianNB, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:14,740:INFO:Adding model into prep_pipe
2024-07-18 11:34:14,740:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/GaussianNB.pkl saved in current working directory
2024-07-18 11:34:14,740:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2024-07-18 11:34:14,740:INFO:save_model() successfully completed......................................
2024-07-18 11:34:15,201:INFO:Initializing save_model()
2024-07-18 11:34:15,201:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7665, solver='auto',
                tol=0.0001), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/RidgeClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:15,201:INFO:Adding model into prep_pipe
2024-07-18 11:34:15,203:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/RidgeClassifier.pkl saved in current working directory
2024-07-18 11:34:15,205:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=7665,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2024-07-18 11:34:15,205:INFO:save_model() successfully completed......................................
2024-07-18 11:34:15,668:INFO:Initializing save_model()
2024-07-18 11:34:15,668:INFO:save_model(model=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/LinearDiscriminantAnalysis, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:15,668:INFO:Adding model into prep_pipe
2024-07-18 11:34:15,671:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/LinearDiscriminantAnalysis.pkl saved in current working directory
2024-07-18 11:34:15,673:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2024-07-18 11:34:15,673:INFO:save_model() successfully completed......................................
2024-07-18 11:34:16,139:INFO:Initializing save_model()
2024-07-18 11:34:16,139:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7665, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/LogisticRegression, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:16,139:INFO:Adding model into prep_pipe
2024-07-18 11:34:16,139:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/LogisticRegression.pkl saved in current working directory
2024-07-18 11:34:16,139:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=7665,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-07-18 11:34:16,139:INFO:save_model() successfully completed......................................
2024-07-18 11:34:16,611:INFO:Initializing save_model()
2024-07-18 11:34:16,611:INFO:save_model(model=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7665, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), model_name=GPU_0_EPPD_ML_VALIDATION_kfold/SGDClassifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-18 11:34:16,611:INFO:Adding model into prep_pipe
2024-07-18 11:34:16,613:INFO:GPU_0_EPPD_ML_VALIDATION_kfold/SGDClassifier.pkl saved in current working directory
2024-07-18 11:34:16,615:INFO:Pipeline(memory=FastMemory(location=C:\Users\JAL\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Internships', 'CGPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=7665,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False)
2024-07-18 11:34:16,615:INFO:save_model() successfully completed......................................
2024-07-18 11:34:17,073:WARNING:C:\Users\JAL\AppData\Local\Temp\ipykernel_17160\2873217847.py:105: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  best_model[best_model.select_dtypes(include=['number']).columns] *= 100

